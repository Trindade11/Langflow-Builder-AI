{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Webhook",
            "id": "CustomComponent-DDTxa",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-PefPe",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-DDTxa{œdataTypeœ:œWebhookœ,œidœ:œCustomComponent-DDTxaœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-ParseData-PefPe{œfieldNameœ:œdataœ,œidœ:œParseData-PefPeœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-DDTxa",
        "sourceHandle": "{œdataTypeœ:œWebhookœ,œidœ:œCustomComponent-DDTxaœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-PefPe",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-PefPeœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "AzureOpenAIModel",
            "id": "AzureOpenAIModel-P8Rf9",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm",
            "id": "StructuredOutput-78c4L",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__AzureOpenAIModel-P8Rf9{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-P8Rf9œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-StructuredOutput-78c4L{œfieldNameœ:œllmœ,œidœ:œStructuredOutput-78c4Lœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "AzureOpenAIModel-P8Rf9",
        "sourceHandle": "{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-P8Rf9œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "StructuredOutput-78c4L",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œStructuredOutput-78c4Lœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-PefPe",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "pergunta",
            "id": "Prompt-CznQH",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-PefPe{œdataTypeœ:œParseDataœ,œidœ:œParseData-PefPeœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-CznQH{œfieldNameœ:œperguntaœ,œidœ:œPrompt-CznQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-PefPe",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-PefPeœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-CznQH",
        "targetHandle": "{œfieldNameœ:œperguntaœ,œidœ:œPrompt-CznQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-CznQH",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "StructuredOutput-78c4L",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-CznQH{œdataTypeœ:œPromptœ,œidœ:œPrompt-CznQHœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-StructuredOutput-78c4L{œfieldNameœ:œinput_valueœ,œidœ:œStructuredOutput-78c4Lœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-CznQH",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-CznQHœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "StructuredOutput-78c4L",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œStructuredOutput-78c4Lœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Webhook",
            "id": "CustomComponent-DDTxa",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-XS2ZQ",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-DDTxa{œdataTypeœ:œWebhookœ,œidœ:œCustomComponent-DDTxaœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-ParseData-XS2ZQ{œfieldNameœ:œdataœ,œidœ:œParseData-XS2ZQœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-DDTxa",
        "sourceHandle": "{œdataTypeœ:œWebhookœ,œidœ:œCustomComponent-DDTxaœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-XS2ZQ",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-XS2ZQœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-XS2ZQ",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_query",
            "id": "CustomComponent-M0wft",
            "inputTypes": [
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseData-XS2ZQ{œdataTypeœ:œParseDataœ,œidœ:œParseData-XS2ZQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-M0wft{œfieldNameœ:œsearch_queryœ,œidœ:œCustomComponent-M0wftœ,œinputTypesœ:[œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseData-XS2ZQ",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-XS2ZQœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-M0wft",
        "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œCustomComponent-M0wftœ,œinputTypesœ:[œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MongoTextSearch",
            "id": "CustomComponent-M0wft",
            "name": "results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "CustomComponent-QqOeU",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-M0wft{œdataTypeœ:œMongoTextSearchœ,œidœ:œCustomComponent-M0wftœ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}-CustomComponent-QqOeU{œfieldNameœ:œinput_valueœ,œidœ:œCustomComponent-QqOeUœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-M0wft",
        "sourceHandle": "{œdataTypeœ:œMongoTextSearchœ,œidœ:œCustomComponent-M0wftœ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-QqOeU",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œCustomComponent-QqOeUœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseJSONData",
            "id": "CustomComponent-QqOeU",
            "name": "filtered_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-4jo5N",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-QqOeU{œdataTypeœ:œParseJSONDataœ,œidœ:œCustomComponent-QqOeUœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-4jo5N{œfieldNameœ:œdataœ,œidœ:œParseData-4jo5Nœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-QqOeU",
        "sourceHandle": "{œdataTypeœ:œParseJSONDataœ,œidœ:œCustomComponent-QqOeUœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-4jo5N",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-4jo5Nœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MongoTextSearch",
            "id": "MongoTextSearch-vLX80",
            "name": "results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ParseJSONData-9XOVm",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__MongoTextSearch-vLX80{œdataTypeœ:œMongoTextSearchœ,œidœ:œMongoTextSearch-vLX80œ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}-ParseJSONData-9XOVm{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-9XOVmœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "MongoTextSearch-vLX80",
        "sourceHandle": "{œdataTypeœ:œMongoTextSearchœ,œidœ:œMongoTextSearch-vLX80œ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseJSONData-9XOVm",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-9XOVmœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseJSONData",
            "id": "ParseJSONData-9XOVm",
            "name": "filtered_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-H9PdB",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseJSONData-9XOVm{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-9XOVmœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-H9PdB{œfieldNameœ:œdataœ,œidœ:œParseData-H9PdBœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseJSONData-9XOVm",
        "sourceHandle": "{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-9XOVmœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-H9PdB",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-H9PdBœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-vDvHD",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "payload",
            "id": "CustomComponent-DDTxa",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-vDvHD{œdataTypeœ:œTextInputœ,œidœ:œTextInput-vDvHDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-DDTxa{œfieldNameœ:œpayloadœ,œidœ:œCustomComponent-DDTxaœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-vDvHD",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-vDvHDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-DDTxa",
        "targetHandle": "{œfieldNameœ:œpayloadœ,œidœ:œCustomComponent-DDTxaœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MongoTextSearch",
            "id": "CustomComponent-M0wft",
            "name": "results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ParseJSONData-Un65E",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-M0wft{œdataTypeœ:œMongoTextSearchœ,œidœ:œCustomComponent-M0wftœ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}-ParseJSONData-Un65E{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-Un65Eœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-M0wft",
        "sourceHandle": "{œdataTypeœ:œMongoTextSearchœ,œidœ:œCustomComponent-M0wftœ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseJSONData-Un65E",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-Un65Eœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseJSONData",
            "id": "ParseJSONData-Un65E",
            "name": "filtered_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-4Lwmh",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseJSONData-Un65E{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-Un65Eœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-4Lwmh{œfieldNameœ:œdataœ,œidœ:œParseData-4Lwmhœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseJSONData-Un65E",
        "sourceHandle": "{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-Un65Eœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-4Lwmh",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-4Lwmhœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-4jo5N",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "persona",
            "id": "Prompt-CznQH",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-4jo5N{œdataTypeœ:œParseDataœ,œidœ:œParseData-4jo5Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-CznQH{œfieldNameœ:œpersonaœ,œidœ:œPrompt-CznQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-4jo5N",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-4jo5Nœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-CznQH",
        "targetHandle": "{œfieldNameœ:œpersonaœ,œidœ:œPrompt-CznQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-H9PdB",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "contexto",
            "id": "Prompt-CznQH",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-H9PdB{œdataTypeœ:œParseDataœ,œidœ:œParseData-H9PdBœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-CznQH{œfieldNameœ:œcontextoœ,œidœ:œPrompt-CznQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-H9PdB",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-H9PdBœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-CznQH",
        "targetHandle": "{œfieldNameœ:œcontextoœ,œidœ:œPrompt-CznQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-4Lwmh",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_query",
            "id": "MongoTextSearch-vLX80",
            "inputTypes": [
              "Message",
              "str",
              "list"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseData-4Lwmh{œdataTypeœ:œParseDataœ,œidœ:œParseData-4Lwmhœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-MongoTextSearch-vLX80{œfieldNameœ:œsearch_queryœ,œidœ:œMongoTextSearch-vLX80œ,œinputTypesœ:[œMessageœ,œstrœ,œlistœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseData-4Lwmh",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-4Lwmhœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MongoTextSearch-vLX80",
        "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œMongoTextSearch-vLX80œ,œinputTypesœ:[œMessageœ,œstrœ,œlistœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MongoTextSearch",
            "id": "CustomComponent-M0wft",
            "name": "results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ParseJSONData-JNcoF",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-M0wft{œdataTypeœ:œMongoTextSearchœ,œidœ:œCustomComponent-M0wftœ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}-ParseJSONData-JNcoF{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-JNcoFœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-M0wft",
        "sourceHandle": "{œdataTypeœ:œMongoTextSearchœ,œidœ:œCustomComponent-M0wftœ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseJSONData-JNcoF",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-JNcoFœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseJSONData",
            "id": "ParseJSONData-JNcoF",
            "name": "filtered_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-Z3oxH",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseJSONData-JNcoF{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-JNcoFœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-Z3oxH{œfieldNameœ:œdataœ,œidœ:œParseData-Z3oxHœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseJSONData-JNcoF",
        "sourceHandle": "{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-JNcoFœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-Z3oxH",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-Z3oxHœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "AzureOpenAIEmbeddings",
            "id": "AzureOpenAIEmbeddings-SO8Kb",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding",
            "id": "MongoDBAtlasVector-3QyXY",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__AzureOpenAIEmbeddings-SO8Kb{œdataTypeœ:œAzureOpenAIEmbeddingsœ,œidœ:œAzureOpenAIEmbeddings-SO8Kbœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-MongoDBAtlasVector-3QyXY{œfieldNameœ:œembeddingœ,œidœ:œMongoDBAtlasVector-3QyXYœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "AzureOpenAIEmbeddings-SO8Kb",
        "sourceHandle": "{œdataTypeœ:œAzureOpenAIEmbeddingsœ,œidœ:œAzureOpenAIEmbeddings-SO8Kbœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "MongoDBAtlasVector-3QyXY",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œMongoDBAtlasVector-3QyXYœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MongoDBAtlasVector",
            "id": "MongoDBAtlasVector-3QyXY",
            "name": "search_results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "semantic_chunks",
            "id": "CustomComponent-3EZEi",
            "inputTypes": [
              "list",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__MongoDBAtlasVector-3QyXY{œdataTypeœ:œMongoDBAtlasVectorœ,œidœ:œMongoDBAtlasVector-3QyXYœ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}-CustomComponent-3EZEi{œfieldNameœ:œsemantic_chunksœ,œidœ:œCustomComponent-3EZEiœ,œinputTypesœ:[œlistœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "MongoDBAtlasVector-3QyXY",
        "sourceHandle": "{œdataTypeœ:œMongoDBAtlasVectorœ,œidœ:œMongoDBAtlasVector-3QyXYœ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-3EZEi",
        "targetHandle": "{œfieldNameœ:œsemantic_chunksœ,œidœ:œCustomComponent-3EZEiœ,œinputTypesœ:[œlistœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "AzureOpenAIModel",
            "id": "AzureOpenAIModel-UVu9j",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm",
            "id": "CustomComponent-3EZEi",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__AzureOpenAIModel-UVu9j{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-UVu9jœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CustomComponent-3EZEi{œfieldNameœ:œllmœ,œidœ:œCustomComponent-3EZEiœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "AzureOpenAIModel-UVu9j",
        "sourceHandle": "{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-UVu9jœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "CustomComponent-3EZEi",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œCustomComponent-3EZEiœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Pass",
            "id": "Pass-9TQz2",
            "name": "output_message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "regras",
            "id": "Prompt-CznQH",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Pass-9TQz2{œdataTypeœ:œPassœ,œidœ:œPass-9TQz2œ,œnameœ:œoutput_messageœ,œoutput_typesœ:[œMessageœ]}-Prompt-CznQH{œfieldNameœ:œregrasœ,œidœ:œPrompt-CznQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Pass-9TQz2",
        "sourceHandle": "{œdataTypeœ:œPassœ,œidœ:œPass-9TQz2œ,œnameœ:œoutput_messageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-CznQH",
        "targetHandle": "{œfieldNameœ:œregrasœ,œidœ:œPrompt-CznQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CurrentDate",
            "id": "CurrentDate-4E5Rw",
            "name": "current_date",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "data_atual",
            "id": "Prompt-CznQH",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__CurrentDate-4E5Rw{œdataTypeœ:œCurrentDateœ,œidœ:œCurrentDate-4E5Rwœ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}-Prompt-CznQH{œfieldNameœ:œdata_atualœ,œidœ:œPrompt-CznQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CurrentDate-4E5Rw",
        "sourceHandle": "{œdataTypeœ:œCurrentDateœ,œidœ:œCurrentDate-4E5Rwœ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-CznQH",
        "targetHandle": "{œfieldNameœ:œdata_atualœ,œidœ:œPrompt-CznQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseDataFrame",
            "id": "CustomComponent-h2GUm",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "RegexExtractorComponent-Wj6qw",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__CustomComponent-h2GUm{œdataTypeœ:œParseDataFrameœ,œidœ:œCustomComponent-h2GUmœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-RegexExtractorComponent-Wj6qw{œfieldNameœ:œinput_textœ,œidœ:œRegexExtractorComponent-Wj6qwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CustomComponent-h2GUm",
        "sourceHandle": "{œdataTypeœ:œParseDataFrameœ,œidœ:œCustomComponent-h2GUmœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "RegexExtractorComponent-Wj6qw",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œRegexExtractorComponent-Wj6qwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CombineJSON",
            "id": "CustomComponent-65zBN",
            "name": "combined_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ParseJSONData-MxMyx",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-65zBN{œdataTypeœ:œCombineJSONœ,œidœ:œCustomComponent-65zBNœ,œnameœ:œcombined_dataœ,œoutput_typesœ:[œDataœ]}-ParseJSONData-MxMyx{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-MxMyxœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-65zBN",
        "sourceHandle": "{œdataTypeœ:œCombineJSONœ,œidœ:œCustomComponent-65zBNœ,œnameœ:œcombined_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseJSONData-MxMyx",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-MxMyxœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseJSONData",
            "id": "ParseJSONData-MxMyx",
            "name": "filtered_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-YKrQX",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseJSONData-MxMyx{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-MxMyxœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-YKrQX{œfieldNameœ:œdataœ,œidœ:œParseData-YKrQXœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseJSONData-MxMyx",
        "sourceHandle": "{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-MxMyxœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-YKrQX",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-YKrQXœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-YKrQX",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-q4F9z",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-YKrQX{œdataTypeœ:œParseDataœ,œidœ:œParseData-YKrQXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-q4F9z{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-q4F9zœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-YKrQX",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-YKrQXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-q4F9z",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-q4F9zœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CombineJSON",
            "id": "CustomComponent-65zBN",
            "name": "combined_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "ConditionalRouter-q4F9z",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-65zBN{œdataTypeœ:œCombineJSONœ,œidœ:œCustomComponent-65zBNœ,œnameœ:œcombined_dataœ,œoutput_typesœ:[œDataœ]}-ConditionalRouter-q4F9z{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-q4F9zœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-65zBN",
        "sourceHandle": "{œdataTypeœ:œCombineJSONœ,œidœ:œCustomComponent-65zBNœ,œnameœ:œcombined_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ConditionalRouter-q4F9z",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-q4F9zœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-q4F9z",
            "name": "true_result",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ParseJSONData-Kuu6E",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ConditionalRouter-q4F9z{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-q4F9zœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}-ParseJSONData-Kuu6E{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-Kuu6Eœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-q4F9z",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-q4F9zœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseJSONData-Kuu6E",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-Kuu6Eœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-q4F9z",
            "name": "true_result",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ParseJSONData-dT6Xk",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ConditionalRouter-q4F9z{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-q4F9zœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}-ParseJSONData-dT6Xk{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-dT6Xkœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-q4F9z",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-q4F9zœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseJSONData-dT6Xk",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-dT6Xkœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-Z3oxH",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "CustomComponent-65zBN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-Z3oxH{œdataTypeœ:œParseDataœ,œidœ:œParseData-Z3oxHœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-65zBN{œfieldNameœ:œmessageœ,œidœ:œCustomComponent-65zBNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-Z3oxH",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-Z3oxHœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-65zBN",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œCustomComponent-65zBNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseJSONData",
            "id": "ParseJSONData-dT6Xk",
            "name": "filtered_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-flHTD",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseJSONData-dT6Xk{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-dT6Xkœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-flHTD{œfieldNameœ:œdataœ,œidœ:œParseData-flHTDœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseJSONData-dT6Xk",
        "sourceHandle": "{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-dT6Xkœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-flHTD",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-flHTDœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseJSONData",
            "id": "ParseJSONData-Kuu6E",
            "name": "filtered_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-UgBdh",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseJSONData-Kuu6E{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-Kuu6Eœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-UgBdh{œfieldNameœ:œdataœ,œidœ:œParseData-UgBdhœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseJSONData-Kuu6E",
        "sourceHandle": "{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-Kuu6Eœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-UgBdh",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-UgBdhœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-UgBdh",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_query",
            "id": "MongoDBAtlasVector-3QyXY",
            "inputTypes": [
              "Message"
            ],
            "type": "query"
          }
        },
        "id": "xy-edge__ParseData-UgBdh{œdataTypeœ:œParseDataœ,œidœ:œParseData-UgBdhœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-MongoDBAtlasVector-3QyXY{œfieldNameœ:œsearch_queryœ,œidœ:œMongoDBAtlasVector-3QyXYœ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}",
        "selected": false,
        "source": "ParseData-UgBdh",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-UgBdhœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MongoDBAtlasVector-3QyXY",
        "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œMongoDBAtlasVector-3QyXYœ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-flHTD",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "setores",
            "id": "MongoDBAtlasVector-3QyXY",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-flHTD{œdataTypeœ:œParseDataœ,œidœ:œParseData-flHTDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-MongoDBAtlasVector-3QyXY{œfieldNameœ:œsetoresœ,œidœ:œMongoDBAtlasVector-3QyXYœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-flHTD",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-flHTDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MongoDBAtlasVector-3QyXY",
        "targetHandle": "{œfieldNameœ:œsetoresœ,œidœ:œMongoDBAtlasVector-3QyXYœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-UgBdh",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "question",
            "id": "CustomComponent-3EZEi",
            "inputTypes": [
              "str",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseData-UgBdh{œdataTypeœ:œParseDataœ,œidœ:œParseData-UgBdhœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-3EZEi{œfieldNameœ:œquestionœ,œidœ:œCustomComponent-3EZEiœ,œinputTypesœ:[œstrœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseData-UgBdh",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-UgBdhœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-3EZEi",
        "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œCustomComponent-3EZEiœ,œinputTypesœ:[œstrœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Pass",
            "id": "Pass-QARhb",
            "name": "output_message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "llm_field_mapping",
            "id": "Prompt-CznQH",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Pass-QARhb{œdataTypeœ:œPassœ,œidœ:œPass-QARhbœ,œnameœ:œoutput_messageœ,œoutput_typesœ:[œMessageœ]}-Prompt-CznQH{œfieldNameœ:œllm_field_mappingœ,œidœ:œPrompt-CznQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Pass-QARhb",
        "sourceHandle": "{œdataTypeœ:œPassœ,œidœ:œPass-QARhbœ,œnameœ:œoutput_messageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-CznQH",
        "targetHandle": "{œfieldNameœ:œllm_field_mappingœ,œidœ:œPrompt-CznQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-flHTD",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "user_sector",
            "id": "CustomComponent-H8pi8",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-flHTD{œdataTypeœ:œParseDataœ,œidœ:œParseData-flHTDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-H8pi8{œfieldNameœ:œuser_sectorœ,œidœ:œCustomComponent-H8pi8œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-flHTD",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-flHTDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-H8pi8",
        "targetHandle": "{œfieldNameœ:œuser_sectorœ,œidœ:œCustomComponent-H8pi8œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RegexExtractorComponent",
            "id": "RegexExtractorComponent-Wj6qw",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_message",
            "id": "CustomComponent-eqGYB",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__RegexExtractorComponent-Wj6qw{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-Wj6qwœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-eqGYB{œfieldNameœ:œinput_messageœ,œidœ:œCustomComponent-eqGYBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "RegexExtractorComponent-Wj6qw",
        "sourceHandle": "{œdataTypeœ:œRegexExtractorComponentœ,œidœ:œRegexExtractorComponent-Wj6qwœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-eqGYB",
        "targetHandle": "{œfieldNameœ:œinput_messageœ,œidœ:œCustomComponent-eqGYBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ProcessEscapedJsonSafe",
            "id": "CustomComponent-eqGYB",
            "name": "data_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "json_data",
            "id": "CustomComponent-65zBN",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-eqGYB{œdataTypeœ:œProcessEscapedJsonSafeœ,œidœ:œCustomComponent-eqGYBœ,œnameœ:œdata_outputœ,œoutput_typesœ:[œDataœ]}-CustomComponent-65zBN{œfieldNameœ:œjson_dataœ,œidœ:œCustomComponent-65zBNœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-eqGYB",
        "sourceHandle": "{œdataTypeœ:œProcessEscapedJsonSafeœ,œidœ:œCustomComponent-eqGYBœ,œnameœ:œdata_outputœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-65zBN",
        "targetHandle": "{œfieldNameœ:œjson_dataœ,œidœ:œCustomComponent-65zBNœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-q4F9z",
            "name": "true_result",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data_object",
            "id": "CustomComponent-fDgbO",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ConditionalRouter-q4F9z{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-q4F9zœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}-CustomComponent-fDgbO{œfieldNameœ:œinput_data_objectœ,œidœ:œCustomComponent-fDgbOœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-q4F9z",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-q4F9zœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-fDgbO",
        "targetHandle": "{œfieldNameœ:œinput_data_objectœ,œidœ:œCustomComponent-fDgbOœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ExtractSearchInstruction",
            "id": "CustomComponent-fDgbO",
            "name": "search_instruction_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "search_instruction_data",
            "id": "CustomComponent-H8pi8",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-fDgbO{œdataTypeœ:œExtractSearchInstructionœ,œidœ:œCustomComponent-fDgbOœ,œnameœ:œsearch_instruction_outputœ,œoutput_typesœ:[œDataœ]}-CustomComponent-H8pi8{œfieldNameœ:œsearch_instruction_dataœ,œidœ:œCustomComponent-H8pi8œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-fDgbO",
        "sourceHandle": "{œdataTypeœ:œExtractSearchInstructionœ,œidœ:œCustomComponent-fDgbOœ,œnameœ:œsearch_instruction_outputœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-H8pi8",
        "targetHandle": "{œfieldNameœ:œsearch_instruction_dataœ,œidœ:œCustomComponent-H8pi8œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-q4F9z",
            "name": "true_result",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ParseJSONData-D4BeZ",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ConditionalRouter-q4F9z{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-q4F9zœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}-ParseJSONData-D4BeZ{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-D4BeZœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-q4F9z",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-q4F9zœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseJSONData-D4BeZ",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-D4BeZœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MongoAtlasSearchWithFilters",
            "id": "CustomComponent-H8pi8",
            "name": "results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_chunks",
            "id": "CustomComponent-IzLd7",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-H8pi8{œdataTypeœ:œMongoAtlasSearchWithFiltersœ,œidœ:œCustomComponent-H8pi8œ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}-CustomComponent-IzLd7{œfieldNameœ:œinput_chunksœ,œidœ:œCustomComponent-IzLd7œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-H8pi8",
        "sourceHandle": "{œdataTypeœ:œMongoAtlasSearchWithFiltersœ,œidœ:œCustomComponent-H8pi8œ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-IzLd7",
        "targetHandle": "{œfieldNameœ:œinput_chunksœ,œidœ:œCustomComponent-IzLd7œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseJSONData",
            "id": "ParseJSONData-D4BeZ",
            "name": "filtered_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "temporal_constraints",
            "id": "CustomComponent-IzLd7",
            "inputTypes": [
              "Data",
              "str"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseJSONData-D4BeZ{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-D4BeZœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-CustomComponent-IzLd7{œfieldNameœ:œtemporal_constraintsœ,œidœ:œCustomComponent-IzLd7œ,œinputTypesœ:[œDataœ,œstrœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseJSONData-D4BeZ",
        "sourceHandle": "{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-D4BeZœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-IzLd7",
        "targetHandle": "{œfieldNameœ:œtemporal_constraintsœ,œidœ:œCustomComponent-IzLd7œ,œinputTypesœ:[œDataœ,œstrœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CurrentDate",
            "id": "CurrentDate-4E5Rw",
            "name": "current_date",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "current_date",
            "id": "CustomComponent-IzLd7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__CurrentDate-4E5Rw{œdataTypeœ:œCurrentDateœ,œidœ:œCurrentDate-4E5Rwœ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-IzLd7{œfieldNameœ:œcurrent_dateœ,œidœ:œCustomComponent-IzLd7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CurrentDate-4E5Rw",
        "sourceHandle": "{œdataTypeœ:œCurrentDateœ,œidœ:œCurrentDate-4E5Rwœ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-IzLd7",
        "targetHandle": "{œfieldNameœ:œcurrent_dateœ,œidœ:œCustomComponent-IzLd7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "AzureOpenAIModel",
            "id": "AzureOpenAIModel-ivZA3",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm_model",
            "id": "CustomComponent-IzLd7",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__AzureOpenAIModel-ivZA3{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-ivZA3œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CustomComponent-IzLd7{œfieldNameœ:œllm_modelœ,œidœ:œCustomComponent-IzLd7œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "AzureOpenAIModel-ivZA3",
        "sourceHandle": "{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-ivZA3œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "CustomComponent-IzLd7",
        "targetHandle": "{œfieldNameœ:œllm_modelœ,œidœ:œCustomComponent-IzLd7œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TemporalFilterLLM",
            "id": "CustomComponent-IzLd7",
            "name": "filtered_chunks",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "lexical_chunks",
            "id": "CustomComponent-3EZEi",
            "inputTypes": [
              "list",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-IzLd7{œdataTypeœ:œTemporalFilterLLMœ,œidœ:œCustomComponent-IzLd7œ,œnameœ:œfiltered_chunksœ,œoutput_typesœ:[œDataœ]}-CustomComponent-3EZEi{œfieldNameœ:œlexical_chunksœ,œidœ:œCustomComponent-3EZEiœ,œinputTypesœ:[œlistœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-IzLd7",
        "sourceHandle": "{œdataTypeœ:œTemporalFilterLLMœ,œidœ:œCustomComponent-IzLd7œ,œnameœ:œfiltered_chunksœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-3EZEi",
        "targetHandle": "{œfieldNameœ:œlexical_chunksœ,œidœ:œCustomComponent-3EZEiœ,œinputTypesœ:[œlistœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-q4F9z",
            "name": "true_result",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ParseJSONData-hQK9Q",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ConditionalRouter-q4F9z{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-q4F9zœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}-ParseJSONData-hQK9Q{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-hQK9Qœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-q4F9z",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-q4F9zœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseJSONData-hQK9Q",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-hQK9Qœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseJSONData",
            "id": "ParseJSONData-hQK9Q",
            "name": "filtered_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "rerank_pesos",
            "id": "CustomComponent-3EZEi",
            "inputTypes": [
              "dict",
              "Data",
              "str"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseJSONData-hQK9Q{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-hQK9Qœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-CustomComponent-3EZEi{œfieldNameœ:œrerank_pesosœ,œidœ:œCustomComponent-3EZEiœ,œinputTypesœ:[œdictœ,œDataœ,œstrœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseJSONData-hQK9Q",
        "sourceHandle": "{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-hQK9Qœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-3EZEi",
        "targetHandle": "{œfieldNameœ:œrerank_pesosœ,œidœ:œCustomComponent-3EZEiœ,œinputTypesœ:[œdictœ,œDataœ,œstrœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "StructuredOutput",
            "id": "StructuredOutput-78c4L",
            "name": "structured_output_dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "CustomComponent-h2GUm",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__StructuredOutput-78c4L{œdataTypeœ:œStructuredOutputœ,œidœ:œStructuredOutput-78c4Lœ,œnameœ:œstructured_output_dataframeœ,œoutput_typesœ:[œDataFrameœ]}-CustomComponent-h2GUm{œfieldNameœ:œdfœ,œidœ:œCustomComponent-h2GUmœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "StructuredOutput-78c4L",
        "sourceHandle": "{œdataTypeœ:œStructuredOutputœ,œidœ:œStructuredOutput-78c4Lœ,œnameœ:œstructured_output_dataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "CustomComponent-h2GUm",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œCustomComponent-h2GUmœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-YKrQX",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-PZSld",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-YKrQX{œdataTypeœ:œParseDataœ,œidœ:œParseData-YKrQXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-PZSld{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-PZSldœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-YKrQX",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-YKrQXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-PZSld",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-PZSldœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-PefPe",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "ConditionalRouter-PZSld",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-PefPe{œdataTypeœ:œParseDataœ,œidœ:œParseData-PefPeœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-PZSld{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-PZSldœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-PefPe",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-PefPeœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-PZSld",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-PZSldœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CombineJSON",
            "id": "CustomComponent-65zBN",
            "name": "combined_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "ConditionalRouter-Lys4Y",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-65zBN{œdataTypeœ:œCombineJSONœ,œidœ:œCustomComponent-65zBNœ,œnameœ:œcombined_dataœ,œoutput_typesœ:[œDataœ]}-ConditionalRouter-Lys4Y{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-Lys4Yœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-65zBN",
        "sourceHandle": "{œdataTypeœ:œCombineJSONœ,œidœ:œCustomComponent-65zBNœ,œnameœ:œcombined_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ConditionalRouter-Lys4Y",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-Lys4Yœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-YKrQX",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-Lys4Y",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-YKrQX{œdataTypeœ:œParseDataœ,œidœ:œParseData-YKrQXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-Lys4Y{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-Lys4Yœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-YKrQX",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-YKrQXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-Lys4Y",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-Lys4Yœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-Lys4Y",
            "name": "true_result",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ParseJSONData-s00MM",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ConditionalRouter-Lys4Y{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-Lys4Yœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}-ParseJSONData-s00MM{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-s00MMœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-Lys4Y",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-Lys4Yœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseJSONData-s00MM",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-s00MMœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-Lys4Y",
            "name": "true_result",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ParseJSONData-bWJwa",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ConditionalRouter-Lys4Y{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-Lys4Yœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}-ParseJSONData-bWJwa{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-bWJwaœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-Lys4Y",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-Lys4Yœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseJSONData-bWJwa",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-bWJwaœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-Lys4Y",
            "name": "true_result",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ParseJSONData-4eZ9F",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ConditionalRouter-Lys4Y{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-Lys4Yœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}-ParseJSONData-4eZ9F{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-4eZ9Fœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-Lys4Y",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-Lys4Yœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseJSONData-4eZ9F",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-4eZ9Fœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-Lys4Y",
            "name": "true_result",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ParseJSONData-LerBu",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ConditionalRouter-Lys4Y{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-Lys4Yœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}-ParseJSONData-LerBu{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-LerBuœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-Lys4Y",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-Lys4Yœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseJSONData-LerBu",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-LerBuœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "AzureOpenAIEmbeddings",
            "id": "AzureOpenAIEmbeddings-kd4A2",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding",
            "id": "MongoDBAtlasVector-QN8Qg",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-AzureOpenAIEmbeddings-kd4A2{œdataTypeœ:œAzureOpenAIEmbeddingsœ,œidœ:œAzureOpenAIEmbeddings-kd4A2œ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-MongoDBAtlasVector-QN8Qg{œfieldNameœ:œembeddingœ,œidœ:œMongoDBAtlasVector-QN8Qgœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "AzureOpenAIEmbeddings-kd4A2",
        "sourceHandle": "{œdataTypeœ:œAzureOpenAIEmbeddingsœ,œidœ:œAzureOpenAIEmbeddings-kd4A2œ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "MongoDBAtlasVector-QN8Qg",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œMongoDBAtlasVector-QN8Qgœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MongoDBAtlasVector",
            "id": "MongoDBAtlasVector-QN8Qg",
            "name": "search_results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "semantic_chunks",
            "id": "LLMRerankComponent-oHU1v",
            "inputTypes": [
              "list",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-MongoDBAtlasVector-QN8Qg{œdataTypeœ:œMongoDBAtlasVectorœ,œidœ:œMongoDBAtlasVector-QN8Qgœ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}-LLMRerankComponent-oHU1v{œfieldNameœ:œsemantic_chunksœ,œidœ:œLLMRerankComponent-oHU1vœ,œinputTypesœ:[œlistœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "MongoDBAtlasVector-QN8Qg",
        "sourceHandle": "{œdataTypeœ:œMongoDBAtlasVectorœ,œidœ:œMongoDBAtlasVector-QN8Qgœ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}",
        "target": "LLMRerankComponent-oHU1v",
        "targetHandle": "{œfieldNameœ:œsemantic_chunksœ,œidœ:œLLMRerankComponent-oHU1vœ,œinputTypesœ:[œlistœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "AzureOpenAIModel",
            "id": "AzureOpenAIModel-w8Sks",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm",
            "id": "LLMRerankComponent-oHU1v",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-AzureOpenAIModel-w8Sks{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-w8Sksœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-LLMRerankComponent-oHU1v{œfieldNameœ:œllmœ,œidœ:œLLMRerankComponent-oHU1vœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "AzureOpenAIModel-w8Sks",
        "sourceHandle": "{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-w8Sksœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "LLMRerankComponent-oHU1v",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMRerankComponent-oHU1vœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-oI0jS",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_query",
            "id": "MongoDBAtlasVector-QN8Qg",
            "inputTypes": [
              "Message"
            ],
            "type": "query"
          }
        },
        "id": "reactflow__edge-ParseData-oI0jS{œdataTypeœ:œParseDataœ,œidœ:œParseData-oI0jSœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-MongoDBAtlasVector-QN8Qg{œfieldNameœ:œsearch_queryœ,œidœ:œMongoDBAtlasVector-QN8Qgœ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}",
        "selected": false,
        "source": "ParseData-oI0jS",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-oI0jSœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MongoDBAtlasVector-QN8Qg",
        "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œMongoDBAtlasVector-QN8Qgœ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-v6AgH",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "setores",
            "id": "MongoDBAtlasVector-QN8Qg",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParseData-v6AgH{œdataTypeœ:œParseDataœ,œidœ:œParseData-v6AgHœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-MongoDBAtlasVector-QN8Qg{œfieldNameœ:œsetoresœ,œidœ:œMongoDBAtlasVector-QN8Qgœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-v6AgH",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-v6AgHœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MongoDBAtlasVector-QN8Qg",
        "targetHandle": "{œfieldNameœ:œsetoresœ,œidœ:œMongoDBAtlasVector-QN8Qgœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-oI0jS",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "question",
            "id": "LLMRerankComponent-oHU1v",
            "inputTypes": [
              "str",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ParseData-oI0jS{œdataTypeœ:œParseDataœ,œidœ:œParseData-oI0jSœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-LLMRerankComponent-oHU1v{œfieldNameœ:œquestionœ,œidœ:œLLMRerankComponent-oHU1vœ,œinputTypesœ:[œstrœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseData-oI0jS",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-oI0jSœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "LLMRerankComponent-oHU1v",
        "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œLLMRerankComponent-oHU1vœ,œinputTypesœ:[œstrœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-v6AgH",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "user_sector",
            "id": "MongoAtlasSearchWithFilters-K0wOa",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParseData-v6AgH{œdataTypeœ:œParseDataœ,œidœ:œParseData-v6AgHœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-MongoAtlasSearchWithFilters-K0wOa{œfieldNameœ:œuser_sectorœ,œidœ:œMongoAtlasSearchWithFilters-K0wOaœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-v6AgH",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-v6AgHœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MongoAtlasSearchWithFilters-K0wOa",
        "targetHandle": "{œfieldNameœ:œuser_sectorœ,œidœ:œMongoAtlasSearchWithFilters-K0wOaœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ExtractSearchInstruction",
            "id": "ExtractSearchInstruction-3iWsp",
            "name": "search_instruction_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "search_instruction_data",
            "id": "MongoAtlasSearchWithFilters-K0wOa",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ExtractSearchInstruction-3iWsp{œdataTypeœ:œExtractSearchInstructionœ,œidœ:œExtractSearchInstruction-3iWspœ,œnameœ:œsearch_instruction_outputœ,œoutput_typesœ:[œDataœ]}-MongoAtlasSearchWithFilters-K0wOa{œfieldNameœ:œsearch_instruction_dataœ,œidœ:œMongoAtlasSearchWithFilters-K0wOaœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ExtractSearchInstruction-3iWsp",
        "sourceHandle": "{œdataTypeœ:œExtractSearchInstructionœ,œidœ:œExtractSearchInstruction-3iWspœ,œnameœ:œsearch_instruction_outputœ,œoutput_typesœ:[œDataœ]}",
        "target": "MongoAtlasSearchWithFilters-K0wOa",
        "targetHandle": "{œfieldNameœ:œsearch_instruction_dataœ,œidœ:œMongoAtlasSearchWithFilters-K0wOaœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MongoAtlasSearchWithFilters",
            "id": "MongoAtlasSearchWithFilters-K0wOa",
            "name": "results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_chunks",
            "id": "TemporalFilterLLM-IWHmL",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-MongoAtlasSearchWithFilters-K0wOa{œdataTypeœ:œMongoAtlasSearchWithFiltersœ,œidœ:œMongoAtlasSearchWithFilters-K0wOaœ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}-TemporalFilterLLM-IWHmL{œfieldNameœ:œinput_chunksœ,œidœ:œTemporalFilterLLM-IWHmLœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "MongoAtlasSearchWithFilters-K0wOa",
        "sourceHandle": "{œdataTypeœ:œMongoAtlasSearchWithFiltersœ,œidœ:œMongoAtlasSearchWithFilters-K0wOaœ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}",
        "target": "TemporalFilterLLM-IWHmL",
        "targetHandle": "{œfieldNameœ:œinput_chunksœ,œidœ:œTemporalFilterLLM-IWHmLœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "AzureOpenAIModel",
            "id": "AzureOpenAIModel-PWCK6",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm_model",
            "id": "TemporalFilterLLM-IWHmL",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-AzureOpenAIModel-PWCK6{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-PWCK6œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-TemporalFilterLLM-IWHmL{œfieldNameœ:œllm_modelœ,œidœ:œTemporalFilterLLM-IWHmLœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "AzureOpenAIModel-PWCK6",
        "sourceHandle": "{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-PWCK6œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "TemporalFilterLLM-IWHmL",
        "targetHandle": "{œfieldNameœ:œllm_modelœ,œidœ:œTemporalFilterLLM-IWHmLœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TemporalFilterLLM",
            "id": "TemporalFilterLLM-IWHmL",
            "name": "filtered_chunks",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "lexical_chunks",
            "id": "LLMRerankComponent-oHU1v",
            "inputTypes": [
              "list",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-TemporalFilterLLM-IWHmL{œdataTypeœ:œTemporalFilterLLMœ,œidœ:œTemporalFilterLLM-IWHmLœ,œnameœ:œfiltered_chunksœ,œoutput_typesœ:[œDataœ]}-LLMRerankComponent-oHU1v{œfieldNameœ:œlexical_chunksœ,œidœ:œLLMRerankComponent-oHU1vœ,œinputTypesœ:[œlistœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "TemporalFilterLLM-IWHmL",
        "sourceHandle": "{œdataTypeœ:œTemporalFilterLLMœ,œidœ:œTemporalFilterLLM-IWHmLœ,œnameœ:œfiltered_chunksœ,œoutput_typesœ:[œDataœ]}",
        "target": "LLMRerankComponent-oHU1v",
        "targetHandle": "{œfieldNameœ:œlexical_chunksœ,œidœ:œLLMRerankComponent-oHU1vœ,œinputTypesœ:[œlistœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-Lys4Y",
            "name": "true_result",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data_object",
            "id": "ExtractSearchInstruction-3iWsp",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ConditionalRouter-Lys4Y{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-Lys4Yœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}-ExtractSearchInstruction-3iWsp{œfieldNameœ:œinput_data_objectœ,œidœ:œExtractSearchInstruction-3iWspœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-Lys4Y",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-Lys4Yœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}",
        "target": "ExtractSearchInstruction-3iWsp",
        "targetHandle": "{œfieldNameœ:œinput_data_objectœ,œidœ:œExtractSearchInstruction-3iWspœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseJSONData",
            "id": "ParseJSONData-LerBu",
            "name": "filtered_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-oI0jS",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseJSONData-LerBu{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-LerBuœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-oI0jS{œfieldNameœ:œdataœ,œidœ:œParseData-oI0jSœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseJSONData-LerBu",
        "sourceHandle": "{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-LerBuœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-oI0jS",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-oI0jSœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseJSONData",
            "id": "ParseJSONData-4eZ9F",
            "name": "filtered_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-v6AgH",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseJSONData-4eZ9F{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-4eZ9Fœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-v6AgH{œfieldNameœ:œdataœ,œidœ:œParseData-v6AgHœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseJSONData-4eZ9F",
        "sourceHandle": "{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-4eZ9Fœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-v6AgH",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-v6AgHœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseJSONData",
            "id": "ParseJSONData-bWJwa",
            "name": "filtered_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "temporal_constraints",
            "id": "TemporalFilterLLM-IWHmL",
            "inputTypes": [
              "Data",
              "str"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseJSONData-bWJwa{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-bWJwaœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-TemporalFilterLLM-IWHmL{œfieldNameœ:œtemporal_constraintsœ,œidœ:œTemporalFilterLLM-IWHmLœ,œinputTypesœ:[œDataœ,œstrœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseJSONData-bWJwa",
        "sourceHandle": "{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-bWJwaœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "TemporalFilterLLM-IWHmL",
        "targetHandle": "{œfieldNameœ:œtemporal_constraintsœ,œidœ:œTemporalFilterLLM-IWHmLœ,œinputTypesœ:[œDataœ,œstrœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseJSONData",
            "id": "ParseJSONData-s00MM",
            "name": "filtered_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "rerank_pesos",
            "id": "LLMRerankComponent-oHU1v",
            "inputTypes": [
              "dict",
              "Data",
              "str"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseJSONData-s00MM{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-s00MMœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-LLMRerankComponent-oHU1v{œfieldNameœ:œrerank_pesosœ,œidœ:œLLMRerankComponent-oHU1vœ,œinputTypesœ:[œdictœ,œDataœ,œstrœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseJSONData-s00MM",
        "sourceHandle": "{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-s00MMœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "LLMRerankComponent-oHU1v",
        "targetHandle": "{œfieldNameœ:œrerank_pesosœ,œidœ:œLLMRerankComponent-oHU1vœ,œinputTypesœ:[œdictœ,œDataœ,œstrœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CurrentDate",
            "id": "CurrentDate-4E5Rw",
            "name": "current_date",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "current_date",
            "id": "TemporalFilterLLM-IWHmL",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__CurrentDate-4E5Rw{œdataTypeœ:œCurrentDateœ,œidœ:œCurrentDate-4E5Rwœ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}-TemporalFilterLLM-IWHmL{œfieldNameœ:œcurrent_dateœ,œidœ:œTemporalFilterLLM-IWHmLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CurrentDate-4E5Rw",
        "sourceHandle": "{œdataTypeœ:œCurrentDateœ,œidœ:œCurrentDate-4E5Rwœ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TemporalFilterLLM-IWHmL",
        "targetHandle": "{œfieldNameœ:œcurrent_dateœ,œidœ:œTemporalFilterLLM-IWHmLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-YKrQX",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-7VfJ6",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-YKrQX{œdataTypeœ:œParseDataœ,œidœ:œParseData-YKrQXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-7VfJ6{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-7VfJ6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-YKrQX",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-YKrQXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-7VfJ6",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-7VfJ6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-YKrQX",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-xDxHu",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-YKrQX{œdataTypeœ:œParseDataœ,œidœ:œParseData-YKrQXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-xDxHu{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-xDxHuœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-YKrQX",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-YKrQXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-xDxHu",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-xDxHuœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-PZSld",
            "name": "true_result",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ParseJSONData-dspQ7",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ConditionalRouter-PZSld{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-PZSldœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}-ParseJSONData-dspQ7{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-dspQ7œ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-PZSld",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-PZSldœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseJSONData-dspQ7",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-dspQ7œ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseJSONData",
            "id": "ParseJSONData-dspQ7",
            "name": "filtered_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-2davv",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseJSONData-dspQ7{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-dspQ7œ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-2davv{œfieldNameœ:œdataœ,œidœ:œParseData-2davvœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseJSONData-dspQ7",
        "sourceHandle": "{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-dspQ7œ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-2davv",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-2davvœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-2davv",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "Prompt-IcIBA",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-2davv{œdataTypeœ:œParseDataœ,œidœ:œParseData-2davvœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-IcIBA{œfieldNameœ:œmessageœ,œidœ:œPrompt-IcIBAœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-2davv",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-2davvœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-IcIBA",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œPrompt-IcIBAœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-IcIBA",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Agent-RpAXn",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-IcIBA{œdataTypeœ:œPromptœ,œidœ:œPrompt-IcIBAœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Agent-RpAXn{œfieldNameœ:œinput_valueœ,œidœ:œAgent-RpAXnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-IcIBA",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-IcIBAœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-RpAXn",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAgent-RpAXnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MongoTextSearch",
            "id": "CustomComponent-M0wft",
            "name": "results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ParseJSONData-E1SZh",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-M0wft{œdataTypeœ:œMongoTextSearchœ,œidœ:œCustomComponent-M0wftœ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}-ParseJSONData-E1SZh{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-E1SZhœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-M0wft",
        "sourceHandle": "{œdataTypeœ:œMongoTextSearchœ,œidœ:œCustomComponent-M0wftœ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseJSONData-E1SZh",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œParseJSONData-E1SZhœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseJSONData",
            "id": "ParseJSONData-E1SZh",
            "name": "filtered_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-cR2Fj",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseJSONData-E1SZh{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-E1SZhœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-cR2Fj{œfieldNameœ:œdataœ,œidœ:œParseData-cR2Fjœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParseJSONData-E1SZh",
        "sourceHandle": "{œdataTypeœ:œParseJSONDataœ,œidœ:œParseJSONData-E1SZhœ,œnameœ:œfiltered_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-cR2Fj",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-cR2Fjœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-cR2Fj",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "user_name",
            "id": "Prompt-IcIBA",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-cR2Fj{œdataTypeœ:œParseDataœ,œidœ:œParseData-cR2Fjœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-IcIBA{œfieldNameœ:œuser_nameœ,œidœ:œPrompt-IcIBAœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-cR2Fj",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-cR2Fjœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-IcIBA",
        "targetHandle": "{œfieldNameœ:œuser_nameœ,œidœ:œPrompt-IcIBAœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Webhook",
            "id": "CustomComponent-DDTxa",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "CustomComponent-awk0s",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-DDTxa{œdataTypeœ:œWebhookœ,œidœ:œCustomComponent-DDTxaœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-CustomComponent-awk0s{œfieldNameœ:œdataœ,œidœ:œCustomComponent-awk0sœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-DDTxa",
        "sourceHandle": "{œdataTypeœ:œWebhookœ,œidœ:œCustomComponent-DDTxaœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-awk0s",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œCustomComponent-awk0sœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "CustomComponent-awk0s",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_message",
            "id": "CustomComponent-e0Euw",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__CustomComponent-awk0s{œdataTypeœ:œParseDataœ,œidœ:œCustomComponent-awk0sœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-e0Euw{œfieldNameœ:œinput_messageœ,œidœ:œCustomComponent-e0Euwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CustomComponent-awk0s",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œCustomComponent-awk0sœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-e0Euw",
        "targetHandle": "{œfieldNameœ:œinput_messageœ,œidœ:œCustomComponent-e0Euwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalPrefix",
            "id": "CustomComponent-e0Euw",
            "name": "output_message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "anexo",
            "id": "Prompt-CznQH",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__CustomComponent-e0Euw{œdataTypeœ:œConditionalPrefixœ,œidœ:œCustomComponent-e0Euwœ,œnameœ:œoutput_messageœ,œoutput_typesœ:[œMessageœ]}-Prompt-CznQH{œfieldNameœ:œanexoœ,œidœ:œPrompt-CznQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CustomComponent-e0Euw",
        "sourceHandle": "{œdataTypeœ:œConditionalPrefixœ,œidœ:œCustomComponent-e0Euwœ,œnameœ:œoutput_messageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-CznQH",
        "targetHandle": "{œfieldNameœ:œanexoœ,œidœ:œPrompt-CznQHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "CustomComponent-DDTxa",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Receives a JSON payload and emits a Data object.",
            "display_name": "Webhook",
            "documentation": "",
            "edited": true,
            "field_order": [
              "payload"
            ],
            "frozen": false,
            "icon": "webhook",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "hidden": false,
                "method": "build_data",
                "name": "data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\r\nimport tempfile\r\nfrom datetime import datetime\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import MultilineInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass WebhookComponent(Component):\r\n    display_name = \"Webhook\"\r\n    description = \"Receives a JSON payload and emits a Data object.\"\r\n    name = \"Webhook\"\r\n    icon = \"webhook\"\r\n\r\n    inputs = [\r\n        MultilineInput(\r\n            name=\"payload\",\r\n            display_name=\"Payload\",\r\n            info=\"Raw JSON text received via HTTP POST.\",\r\n        )\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Data\",\r\n            name=\"data\",\r\n            method=\"build_data\",\r\n            type=\"data\",      # emite Data, não Message\r\n        ),\r\n    ]\r\n\r\n    def build_data(self) -> Data:\r\n        raw = self.payload or \"\"\r\n        try:\r\n            payload = json.loads(raw)\r\n        except json.JSONDecodeError:\r\n            payload = {\"text\": raw}\r\n\r\n        # garante campo text para embeddings\r\n        if not payload.get(\"text\"):\r\n            nome = payload.get(\"nome\", \"\")\r\n            desc = payload.get(\"descricao\", \"\")\r\n            payload[\"text\"] = (f\"{nome} - {desc}\".strip() or raw)\r\n\r\n        self.status = f\"Data built with ID: {payload.get('id', 'N/A')}\"\r\n        return Data(data=payload)\r\n"
              },
              "payload": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Payload",
                "dynamic": false,
                "info": "Raw JSON text received via HTTP POST.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "payload",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Webhook"
        },
        "dragging": false,
        "id": "CustomComponent-DDTxa",
        "measured": {
          "height": 211,
          "width": 320
        },
        "position": {
          "x": -2903.453862771301,
          "y": 139.104063280812
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "StructuredOutput-78c4L",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Transforms LLM responses into **structured data formats**. Ideal for extracting specific information or creating consistent outputs.",
            "display_name": "Structured Output",
            "documentation": "",
            "edited": true,
            "field_order": [
              "llm",
              "input_value",
              "system_prompt",
              "schema_name",
              "output_schema",
              "multiple"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Structured Output",
                "hidden": false,
                "method": "build_structured_output",
                "name": "structured_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "hidden": false,
                "method": "as_dataframe",
                "name": "structured_output_dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from pydantic import BaseModel, Field, create_model\nfrom trustcall import create_extractor\n\nfrom langflow.base.models.chat_result import get_chat_result\nfrom langflow.custom import Component\nfrom langflow.helpers.base_model import build_model_from_schema\nfrom langflow.io import (\n    BoolInput,\n    HandleInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    TableInput,\n)\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.table import EditMode\n\n\nclass StructuredOutputComponent(Component):\n    display_name = \"Structured Output\"\n    description = (\n        \"Transforms LLM responses into **structured data formats**. Ideal for extracting specific information \"\n        \"or creating consistent outputs.\"\n    )\n    name = \"StructuredOutput\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"The language model to use to generate the structured output.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input Message\",\n            info=\"The input message to the language model.\",\n            tool_mode=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Format Instructions\",\n            info=\"The instructions to the language model for formatting the output.\",\n            value=(\n                \"You are an AI system designed to extract structured information from unstructured text.\"\n                \"Given the input_text, return a JSON object with predefined keys based on the expected structure.\"\n                \"Extract values accurately and format them according to the specified type \"\n                \"(e.g., string, integer, float, date).\"\n                \"If a value is missing or cannot be determined, return a default \"\n                \"(e.g., null, 0, or 'N/A').\"\n                \"If multiple instances of the expected structure exist within the input_text, \"\n                \"stream each as a separate JSON object.\"\n            ),\n            required=True,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"schema_name\",\n            display_name=\"Schema Name\",\n            info=\"Provide a name for the output data schema.\",\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=\"Define the structure and data types for the model's output.\",\n            required=True,\n            # TODO: remove deault value\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\n                        \"Indicate the data type of the output field (e.g., str, int, float, bool, list, dict).\"\n                    ),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"list\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"Multiple\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n            value=[\n                {\n                    \"name\": \"field\",\n                    \"description\": \"description of field\",\n                    \"type\": \"str\",\n                    \"multiple\": \"False\",\n                }\n            ],\n        ),\n        BoolInput(\n            name=\"multiple\",\n            advanced=True,\n            display_name=\"Generate Multiple\",\n            info=\"[Deplrecated] Always set to True\",\n            value=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            name=\"structured_output\",\n            display_name=\"Structured Output\",\n            method=\"build_structured_output\",\n        ),\n        Output(\n            name=\"structured_output_dataframe\",\n            display_name=\"DataFrame\",\n            method=\"as_dataframe\",\n        ),\n    ]\n\n    def build_structured_output_base(self) -> Data:\n        schema_name = self.schema_name or \"OutputModel\"\n\n        if not hasattr(self.llm, \"with_structured_output\"):\n            msg = \"Language model does not support structured output.\"\n            raise TypeError(msg)\n        if not self.output_schema:\n            msg = \"Output schema cannot be empty\"\n            raise ValueError(msg)\n\n        output_model_ = build_model_from_schema(self.output_schema)\n\n        output_model = create_model(\n            schema_name,\n            __doc__=f\"A list of {schema_name}.\",\n            objects=(list[output_model_], Field(description=f\"A list of {schema_name}.\")),  # type: ignore[valid-type]\n        )\n\n        try:\n            llm_with_structured_output = create_extractor(self.llm, tools=[output_model])\n        except NotImplementedError as exc:\n            msg = f\"{self.llm.__class__.__name__} does not support structured output.\"\n            raise TypeError(msg) from exc\n        config_dict = {\n            \"run_name\": self.display_name,\n            \"project_name\": self.get_project_name(),\n            \"callbacks\": self.get_langchain_callbacks(),\n        }\n        result = get_chat_result(\n            runnable=llm_with_structured_output,\n            system_message=self.system_prompt,\n            input_value=self.input_value,\n            config=config_dict,\n        )\n        if isinstance(result, BaseModel):\n            result = result.model_dump()\n        if responses := result.get(\"responses\"):\n            result = responses[0].model_dump()\n        if result and \"objects\" in result:\n            return result[\"objects\"]\n\n        return result\n\n    def build_structured_output(self) -> Data:\n        output = self.build_structured_output_base()\n\n        return Data(text_key=\"results\", data={\"results\": output})\n\n    def as_dataframe(self) -> DataFrame:\n        output = self.build_structured_output_base()\n        if isinstance(output, list):\n            return DataFrame(data=output)\n        return DataFrame(data=[output])\n"
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input Message",
                "dynamic": false,
                "info": "The input message to the language model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "llm": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "The language model to use to generate the structured output.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "llm",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "multiple": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Generate Multiple",
                "dynamic": false,
                "info": "[Deplrecated] Always set to True",
                "list": false,
                "list_add_label": "Add More",
                "name": "multiple",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "output_schema": {
                "_input_type": "TableInput",
                "advanced": false,
                "display_name": "Output Schema",
                "dynamic": false,
                "info": "Define the structure and data types for the model's output.",
                "is_list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_schema",
                "placeholder": "",
                "required": true,
                "show": true,
                "table_icon": "Table",
                "table_schema": {
                  "columns": [
                    {
                      "default": "field",
                      "description": "Specify the name of the output field.",
                      "disable_edit": false,
                      "display_name": "Name",
                      "edit_mode": "inline",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "name",
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": "description of field",
                      "description": "Describe the purpose of the output field.",
                      "disable_edit": false,
                      "display_name": "Description",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "description",
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": "str",
                      "description": "Indicate the data type of the output field (e.g., str, int, float, bool, list, dict).",
                      "disable_edit": false,
                      "display_name": "Type",
                      "edit_mode": "inline",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "type",
                      "options": [
                        "str",
                        "int",
                        "float",
                        "bool",
                        "list",
                        "dict"
                      ],
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": false,
                      "description": "Set to True if this output field should be a list of the specified type.",
                      "disable_edit": false,
                      "display_name": "Multiple",
                      "edit_mode": "inline",
                      "filterable": true,
                      "formatter": "boolean",
                      "hidden": false,
                      "name": "multiple",
                      "sortable": true,
                      "type": "boolean"
                    }
                  ]
                },
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": [
                  {
                    "description": "**Descrição:** Pergunta reescrita, clara e objetiva, considerando contexto e persona.\n**Tipo:** string (sempre presente)\n**Regras:**\n- Preserve nomes próprios, datas, números, siglas e termos técnicos.\n- Corrija ortografia e organize frases curtas.\n**Saída:** apenas a nova pergunta, nada mais.",
                    "multiple": false,
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "description": "**Descrição:** Classificação da pergunta segundo critérios de negócio.\n**Tipo:** array de strings (sempre presente, pode ser vazio)\n**Valores possíveis:** \"corporativo_global\", \"corporativo_local\", \"casual\", \"internet\", \"requer_esclarecimento\"\n**Regras:**\n- Sempre retorne um array JSON, mesmo que vazio.\n- Use apenas os valores permitidos.\n- **Critérios de classificação:**\n    - **corporativo_global**: Pergunta que exige análise do documento inteiro (ex: resumos, temas principais, sentimento geral). Geralmente envolve palavras como \"resuma\", \"quais os principais tópicos\", \"qual o sentimento geral\", \"visão geral\".\n    - **corporativo_local**: Pergunta que busca informações específicas ou trechos (ex: extração de dados, respostas factuais diretas). Geralmente envolve palavras como \"qual data\", \"quem disse\", \"quanto custou\", \"o que é X\".\n    - **corporativo**: Mantenha este como um fallback geral se a distinção entre global/local não for clara, ou para perguntas corporativas que não se encaixam perfeitamente.\n    - **casual**: Pergunta pessoal, educacional ou de cultura geral, sem ligação direta a dados corporativos.\n    - **internet**: Usuário pede explicitamente \"buscar na web\" ou solicita informações externas/tempo-real que provavelmente não constam no grafo interno.\n    - **requer_esclarecimento**: A pergunta do usuário está ambígua, incompleta ou incompreensível, necessitando de mais informações ou reformulação para ser processada adequadamente. Se presente, este deve ser o único valor no array.\n- Não inclua comentários, explicações ou campos extras neste array.",
                    "multiple": true,
                    "name": "classificador_pergunta",
                    "type": "str"
                  },
                  {
                    "description": "**Descrição:** Palavras-chave ou frase curta que indicam o foco principal da análise, especialmente para perguntas `corporativo_global`. Ajuda a direcionar o LLM a extrair as informações mais relevantes do documento completo.\n**Tipo:** string (opcional, pode ser uma string vazia se não aplicável ou se a pergunta já for muito específica)\n**Regras:**\n- Se a pergunta `corporativo_global` for genérica (ex: \"Analise este documento\"), o LLM deve inferir um foco (ex: \"principais pontos e conclusões\").\n- Se a pergunta já indicar um foco (ex: \"Resuma as decisões tomadas\"), este campo pode refletir isso (ex: \"decisões tomadas\").\n- Para perguntas `corporativo_local`, `casual` ou `internet`, este campo geralmente será uma string vazia.\n**Saída:** uma string concisa ou vazia.",
                    "multiple": false,
                    "name": "foco_analise",
                    "type": "str"
                  },
                  {
                    "description": "**Descrição:** Pesos sugeridos para o rerank dos resultados, conforme o tipo de pergunta.\n**Tipo:** objeto JSON com dois campos: `lexical` e `semantic` (ambos float, somando 1.0)\n**Regras:**\n- Sempre retorne ambos os campos (`lexical` e `semantic`), mesmo que um deles seja 0.0.\n- Os valores devem ser floats entre 0.0 e 1.0, somando exatamente 1.0.\n- Use ponto como separador decimal.\n- **Critérios para definição dos pesos:**\n    - Se a pergunta for objetiva, técnica ou buscar termos exatos, priorize `lexical` (ex: 0.7 lexical, 0.3 semantic).\n    - Se a pergunta for aberta, subjetiva ou de contexto amplo, priorize `semantic` (ex: 0.3 lexical, 0.7 semantic).\n    - Se não tiver certeza, use 0.5 para cada.\n- Não inclua campos extras neste objeto.\n",
                    "multiple": false,
                    "name": "rerank_pesos",
                    "type": "str"
                  },
                  {
                    "description": "**Descrição:** Objeto JSON contendo as instruções para a **busca lexical inicial** no MongoDB Atlas Search.\nEsta busca deve ser abrangente para recuperar candidatos lexicalmente relevantes. A filtragem temporal complexa será feita em uma etapa posterior por um LLM dedicado.\n\n**Tipo:** objeto JSON (sempre presente)\n\n**Regras Gerais para `search_instruction` (Busca Lexical Inicial):**\n- O LLM deve construir este objeto focado nos termos da pergunta, caminhos de busca e filtros não-temporais diretos (ex: `classificacao: \"reuniao\"`).\n- **Não inclua aqui filtros de data complexos (range para \"última semana\", etc.) ou lógica para \"última reunião\".** Isso será tratado pela etapa de Filtragem Temporal Inteligente.\n- `search_clause`: Deve conter as cláusulas `text`, `compound`, etc., para a busca lexical.\n- `sort_stage`: Pode incluir uma ordenação genérica, como `{\"atualizado_em\": -1}` para trazer documentos mais recentes primeiro, se aplicável de forma geral.\n- `limit`: Use um limite generoso (ex: `50` ou `100`) para garantir que a etapa de Filtragem Temporal Inteligente tenha material suficiente para trabalhar.\n- `min_score`: Opcional.\n- `filter_stages`: Opcional, para filtros $match simples após o $search.\n\n**Estrutura do Objeto `search_instruction`:**\n\n```json\n{\n  \"search_clause\": {\n    \"compound\": {\n      \"must\": [\n        {\n          \"compound\": {\n            \"should\": [\n              { \"text\": { \"query\": \"<termo1_chave_da_pergunta>\", \"path\": [\"text\"] } },\n              { \"text\": { \"query\": \"<termo2_chave_da_pergunta>\", \"path\": [\"text\"] } }\n            ],\n            \"minimumShouldMatch\": 1\n          }\n        },\n        {\n          \"equals\": {\n            \"path\": \"classificacao\",\n            \"value\": \"<valor_da_classificacao_inferida>\"\n          }\n        }\n      ]\n    }\n  },\n  \"min_score\": 0.1,\n  \"sort_stage\": { \"atualizado_em\": -1 },\n  \"limit\": 50\n}\n```\n\n**Exemplos de Preenchimento de `search_instruction`:**\n\n*   **Usuário:** \"Quais foram as ações discutidas na última ata da DNA Capital?\"\n    *   **LLM gera `search_instruction` (foco lexical):**\n        ```json\n        {\n          \"search_clause\": {\n            \"compound\": {\n              \"must\": [\n                {\n                  \"compound\": {\n                    \"should\": [\n                      { \"text\": { \"query\": \"ações\", \"path\": [\"text\"] } },\n                      { \"text\": { \"query\": \"DNA Capital\", \"path\": [\"text\"] } },\n                      { \"text\": { \"query\": \"ata\", \"path\": [\"text\"] } }\n                    ],\n                    \"minimumShouldMatch\": 1\n                  }\n                },\n                {\n                  \"equals\": {\n                    \"path\": \"classificacao\",\n                    \"value\": \"ata\"\n                  }\n                }\n              ]\n            }\n          },\n          \"sort_stage\": { \"atualizado_em\": -1 },\n          \"limit\": 50,\n          \"min_score\": 0.1\n        }\n        ```\n\n*   **Usuário:** \"Me fale sobre o Projeto Ômega.\" (Nenhuma classificação explícita)\n    *   **LLM gera `search_instruction` (foco lexical):**\n        ```json\n        {\n          \"search_clause\": {\n            \"compound\": {\n              \"must\": [\n                {\n                  \"compound\": {\n                    \"should\": [\n                      { \"text\": { \"query\": \"Projeto Ômega\", \"path\": [\"text\"] } }\n                    ],\n                    \"minimumShouldMatch\": 1\n                  }\n                }\n                // Nenhum filtro equals aqui, pois não há classificação específica inferida\n              ]\n            }\n          },\n          \"sort_stage\": { \"atualizado_em\": -1 },\n          \"limit\": 50,\n          \"min_score\": 0.1\n        }\n        ```",
                    "multiple": false,
                    "name": "search_instruction",
                    "type": "dict"
                  },
                  {
                    "description": "**Descrição:** Um texto detalhado e contextualizado que descreve as restrições e intenções temporais da pergunta do usuário. Este texto servirá como prompt/contexto principal para um LLM subsequente na etapa de \"Filtragem Temporal Inteligente\", que analisará os chunks recuperados pela busca lexical.\nO LLM que gera este campo DEVE utilizar a `{data_atual}` fornecida no prompt para resolver e contextualizar quaisquer referências temporais relativas (ex: \"semana passada\", \"últimos 3 meses\", \"ontem\").\n\n**Tipo:** string (sempre presente, pode ser um texto indicando \"Nenhuma restrição temporal específica identificada\" se for o caso)\n\n**Regras para `temporal_constraints`:**\n- O texto deve ser claro, abrangente e fornecer todo o contexto temporal necessário para o LLM da próxima etapa.\n- Deve explicitar a interpretação de termos como \"última\", \"mais recente\", \"período X\", etc.\n- Indicar quais campos dos documentos (chunks) são relevantes para a análise temporal (ex: `atualizado_em`, `classificacao`, `id` do evento/documento).\n- Se houver múltiplos critérios temporais, descrever como eles interagem.\n- Mencionar a `{data_atual}` usada para a interpretação.\n\n**Exemplos de Preenchimento de `temporal_constraints`:**\n\n*   **Usuário:** “Quais foram as ações discutidas na última reunião sobre o Projeto Alfa?” (Data Atual: 2024-08-22)\n    *   **LLM gera `temporal_constraints`:**\n        ```\n        Contexto Temporal da Pergunta (Data Atual de Referência: 2024-08-22):\n        - Intenção principal: Localizar informações sobre 'ações'.\n        - Evento chave: 'última reunião'. Isso se refere à instância mais recente de um evento com 'classificacao: \"reunião\"'.\n        - Tópico do evento: 'Projeto Alfa'.\n        - Objetivo da Filtragem Temporal: Dos chunks recuperados pela busca lexical que mencionam 'Projeto Alfa' e são classificados como 'reunião', identificar o conjunto de chunks que pertencem ao evento (identificado pelo campo 'id' do documento/evento) com a data 'atualizado_em' mais recente. Todos os chunks associados a este 'id' de evento mais recente devem ser selecionados.\n        ```\n\n*   **Usuário:** “Documentos sobre compliance de 15 de maio de 2024 até 30 de maio de 2024.” (Data Atual: 2024-08-22)\n    *   **LLM gera `temporal_constraints`:**\n        ```\n        Contexto Temporal da Pergunta (Data Atual de Referência: 2024-08-22):\n        - Intenção principal: Localizar 'documentos' sobre 'compliance'.\n        - Restrição temporal explícita: Um intervalo de datas específico.\n        - Objetivo da Filtragem Temporal: Selecionar todos os chunks cuja data 'atualizado_em' esteja entre 2024-05-15T00:00:00Z (inclusive) e 2024-05-30T23:59:59Z (inclusive).\n        ```\n\n*   **Usuário:** “O que aconteceu nas reuniões do setor de Risco nos últimos 2 meses?” (Data Atual: 2024-08-22)\n    *   **LLM gera `temporal_constraints`:**\n        ```\n        Contexto Temporal da Pergunta (Data Atual de Referência: 2024-08-22):\n        - Intenção principal: Informações gerais sobre eventos.\n        - Tipo de evento: 'reuniões' (documentos com 'classificacao: \"reunião\"').\n        - Filtro adicional: 'setor de Risco' (verificar campo 'setores' nos documentos).\n        - Restrição temporal relativa: 'últimos 2 meses'. Considerando a data atual (2024-08-22), isso corresponde aproximadamente ao período de 2024-06-22 a 2024-08-22.\n        - Objetivo da Filtragem Temporal: Selecionar todos os chunks classificados como 'reunião', pertencentes ao 'setor de Risco', e cuja data 'atualizado_em' caia dentro do período calculado de 'últimos 2 meses'.\n        ```\n\n*   **Usuário:** “Me fale sobre o projeto Omega.” (Data Atual: 2024-08-22)\n    *   **LLM gera `temporal_constraints`:**\n        ```\n        Contexto Temporal da Pergunta (Data Atual de Referência: 2024-08-22):\n        - Nenhuma restrição temporal específica foi identificada na pergunta. A busca deve focar na relevância do conteúdo para 'projeto Omega' sem filtros temporais adicionais nesta etapa.\n        ```",
                    "multiple": false,
                    "name": "temporal_constraints",
                    "type": "dict"
                  }
                ]
              },
              "schema_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Schema Name",
                "dynamic": false,
                "info": "Provide a name for the output data schema.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "schema_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Format Instructions",
                "dynamic": false,
                "info": "The instructions to the language model for formatting the output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are an AI system designed to extract structured information from unstructured text.Given the input_text, return a JSON object with predefined keys based on the expected structure.Extract values accurately and format them according to the specified type (e.g., string, integer, float, date).If a value is missing or cannot be determined, return a default (e.g., null, 0, or 'N/A').If multiple instances of the expected structure exist within the input_text, stream each as a separate JSON object."
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "StructuredOutput"
        },
        "dragging": false,
        "id": "StructuredOutput-78c4L",
        "measured": {
          "height": 445,
          "width": 320
        },
        "position": {
          "x": 1041.2678542222739,
          "y": -425.819232402848
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseData-PefPe",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{pergunta}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "dragging": false,
        "id": "ParseData-PefPe",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": -2476.4063155531976,
          "y": -15.38805487200679
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "AzureOpenAIModel-P8Rf9",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Azure OpenAI LLMs.",
            "display_name": "Azure OpenAI",
            "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "azure_endpoint",
              "azure_deployment",
              "api_key",
              "api_version",
              "temperature",
              "max_tokens"
            ],
            "frozen": false,
            "icon": "Azure",
            "key": "AzureOpenAIModel",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": false,
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [
                  "api_key",
                  "azure_deployment",
                  "azure_endpoint"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003924824467069744,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "api_version": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "API Version",
                "dynamic": false,
                "info": "",
                "name": "api_version",
                "options": [
                  "2024-10-01-preview",
                  "2024-09-01-preview",
                  "2024-08-01-preview",
                  "2024-07-01-preview",
                  "2024-06-01",
                  "2024-03-01-preview",
                  "2024-02-15-preview",
                  "2023-12-01-preview",
                  "2023-05-15"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "2024-06-01"
              },
              "azure_deployment": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Deployment Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "azure_deployment",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "name-gpt-4o-mini-aion"
              },
              "azure_endpoint": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Azure Endpoint",
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "azure_endpoint",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "endpoint-gpt-4o-mini-aion"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import AzureChatOpenAI\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import MessageTextInput\nfrom langflow.io import DropdownInput, IntInput, SecretStrInput, SliderInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2024-06-01\",\n        \"2024-07-01-preview\",\n        \"2024-08-01-preview\",\n        \"2024-09-01-preview\",\n        \"2024-10-01-preview\",\n        \"2023-05-15\",\n        \"2023-12-01-preview\",\n        \"2024-02-15-preview\",\n        \"2024-03-01-preview\",\n    ]\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\", required=True),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=sorted(AZURE_OPENAI_API_VERSIONS, reverse=True),\n            value=next(\n                (\n                    version\n                    for version in sorted(AZURE_OPENAI_API_VERSIONS, reverse=True)\n                    if not version.endswith(\"-preview\")\n                ),\n                AZURE_OPENAI_API_VERSIONS[0],\n            ),\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to AzureOpenAI API: {e}\"\n            raise ValueError(msg) from e\n\n        return output\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AzureOpenAIModel"
        },
        "dragging": false,
        "id": "AzureOpenAIModel-P8Rf9",
        "measured": {
          "height": 688,
          "width": 320
        },
        "position": {
          "x": 526.9110002197424,
          "y": -1232.2165443553931
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-RpAXn",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "agents",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "key": "Agent",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "hidden": false,
                "method": "message_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 1.1732828199964098e-19,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "input_types": [],
                "name": "agent_llm",
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Google Generative AI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "SambaNova",
                  "Custom"
                ],
                "options_metadata": [
                  {
                    "icon": "Amazon"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "Azure"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "Groq"
                  },
                  {
                    "icon": "NVIDIA"
                  },
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "SambaNova"
                  },
                  {
                    "icon": "brain"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Azure OpenAI"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "api_version": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "API Version",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "name": "api_version",
                "options": [
                  "2024-10-01-preview",
                  "2024-09-01-preview",
                  "2024-08-01-preview",
                  "2024-07-01-preview",
                  "2024-06-01",
                  "2024-03-01-preview",
                  "2024-02-15-preview",
                  "2023-12-01-preview",
                  "2023-05-15"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "2024-06-01"
              },
              "azure_deployment": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Deployment Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "azure_deployment",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "name-gpt-4o-mini-aion"
              },
              "azure_endpoint": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Azure Endpoint",
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "azure_endpoint",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "endpoint-gpt-4o-mini-aion"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())] + [{\"icon\": \"brain\"}],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n\n            # Validate tools\n            if not self.tools:\n                msg = \"Tools are required to run the agent. Please add at least one tool.\"\n                raise ValueError(msg)\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools,\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]\n                    + [{\"icon\": \"brain\"}],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n"
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "input_types": [],
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "input_types": [],
                "name": "sender",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "input_types": [],
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.7
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-RpAXn",
        "measured": {
          "height": 786,
          "width": 320
        },
        "position": {
          "x": 6547.451941904107,
          "y": 3553.85892393697
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-CznQH",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "pergunta",
                "anexo",
                "contexto",
                "persona",
                "data_atual",
                "llm_field_mapping",
                "regras"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": false,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "anexo": {
                "advanced": false,
                "display_name": "anexo",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "anexo",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "contexto": {
                "advanced": false,
                "display_name": "contexto",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "contexto",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "data_atual": {
                "advanced": false,
                "display_name": "data_atual",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "data_atual",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "llm_field_mapping": {
                "advanced": false,
                "display_name": "llm_field_mapping",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "llm_field_mapping",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "pergunta": {
                "advanced": false,
                "display_name": "pergunta",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "pergunta",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "persona": {
                "advanced": false,
                "display_name": "persona",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "persona",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "regras": {
                "advanced": false,
                "display_name": "regras",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "regras",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "# **Mensagem do usuário:**\n\n{pergunta}\n\n\n{anexo}\n\n---\n\n# **Contexto da Empresa:**\n\n{contexto}\n\n---\n\n# **Persona do usuário:**\n\n{persona}\n\n---\n\n# **Data atual:**\n\n{data_atual}\n\n---\n\n# **Mapeamento de Campos do Índice e Estrutura de Dados (para search_instruction):**\n\n{llm_field_mapping}\n\n---\n\n# **Regras:**\n\n{regras}\n\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-CznQH",
        "measured": {
          "height": 905,
          "width": 320
        },
        "position": {
          "x": 526.4228209570679,
          "y": -435.1081630596109
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-M0wft",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Faz busca textual em uma coleção MongoDB (sem embeddings)",
            "display_name": "Mongo Text Search",
            "documentation": "",
            "edited": true,
            "field_order": [
              "mongodb_uri",
              "db_name",
              "collection_name",
              "search_field",
              "search_query",
              "limit"
            ],
            "frozen": false,
            "icon": "MongoDB",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "hidden": false,
                "method": "search_documents",
                "name": "results",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from pymongo import MongoClient\r\nfrom langflow.custom import Component\r\nfrom langflow.inputs import SecretStrInput, StrInput, IntInput, HandleInput\r\nfrom langflow.schema import Data, Message\r\nfrom langflow.template import Output\r\n\r\n\r\nclass MongoTextSearch(Component):\r\n    display_name = \"Mongo Text Search\"\r\n    description = \"Faz busca textual em uma coleção MongoDB (sem embeddings)\"\r\n    icon = \"MongoDB\"\r\n\r\n    inputs = [\r\n        SecretStrInput(name=\"mongodb_uri\", display_name=\"MongoDB URI\", required=True),\r\n        StrInput(name=\"db_name\", display_name=\"Database\", required=True),\r\n        StrInput(name=\"collection_name\", display_name=\"Collection\", required=True),\r\n        StrInput(name=\"search_field\", display_name=\"Search Field\", value=\"text\", required=True),\r\n        HandleInput(name=\"search_query\", display_name=\"Search Query\", input_types=[\"Message\"]),\r\n        IntInput(name=\"limit\", display_name=\"Result Limit\", value=5),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(name=\"results\", display_name=\"Search Results\", method=\"search_documents\"),\r\n    ]\r\n\r\n    def search_documents(self) -> Data:\r\n        client = MongoClient(self.mongodb_uri)\r\n        collection = client[self.db_name][self.collection_name]\r\n\r\n        # ✅ Correção aqui: acessando .text\r\n        query_text = (\r\n            self.search_query.text if isinstance(self.search_query, Message) else str(self.search_query)\r\n        )\r\n        field_name = self.search_field\r\n\r\n        query = {field_name: {\"$regex\": query_text, \"$options\": \"i\"}}\r\n        self.log(f\"Running query: {query}\")\r\n\r\n        results = list(collection.find(query).limit(self.limit))\r\n        for r in results:\r\n            r[\"_id\"] = str(r[\"_id\"])\r\n\r\n        data = Data(data={\"results\": results})\r\n        self.status = f\"Found {len(results)} result(s)\"\r\n        return data\r\n"
              },
              "collection_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Collection",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "collection_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "knowledge_nodes"
              },
              "db_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Database",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "db_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "DeepContext"
              },
              "limit": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Result Limit",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "limit",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "mongodb_uri": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "MongoDB URI",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "mongodb_uri",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "search_field": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Search Field",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "search_field",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "email"
              },
              "search_query": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "search_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "MongoTextSearch"
        },
        "dragging": false,
        "id": "CustomComponent-M0wft",
        "measured": {
          "height": 622,
          "width": 320
        },
        "position": {
          "x": -2062.9423065593023,
          "y": 404.27885060535795
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseData-XS2ZQ",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{email}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "dragging": false,
        "id": "ParseData-XS2ZQ",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": -2460.655446872188,
          "y": 383.7719594135481
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-QqOeU",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields using jq queries.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\r\nfrom json import JSONDecodeError\r\n\r\nimport jq\r\nfrom json_repair import repair_json\r\nfrom loguru import logger\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.inputs import HandleInput, MessageTextInput\r\nfrom langflow.io import Output\r\nfrom langflow.schema import Data\r\nfrom langflow.schema.message import Message\r\n\r\n\r\nclass ParseJSONDataComponent(Component):\r\n    display_name = \"Parse JSON\"\r\n    description = \"Convert and extract JSON fields using jq queries.\"\r\n    icon = \"braces\"\r\n    name = \"ParseJSONData\"\r\n    legacy: bool = True\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"input_value\",\r\n            display_name=\"Input\",\r\n            info=\"Data object to filter.\",\r\n            required=True,\r\n            input_types=[\"Message\", \"Data\"],\r\n        ),\r\n        MessageTextInput(\r\n            name=\"query\",\r\n            display_name=\"JQ Query\",\r\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\r\n            required=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\r\n    ]\r\n\r\n    def _parse_data(self, input_value) -> str:\r\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\r\n            return input_value.text\r\n        if isinstance(input_value, Data):\r\n            return json.dumps(input_value.data, default=str)\r\n        return str(input_value)\r\n\r\n    def filter_data(self) -> list[Data]:\r\n        to_filter = self.input_value\r\n        if not to_filter:\r\n            return []\r\n\r\n        if isinstance(to_filter, list):\r\n            to_filter = [self._parse_data(f) for f in to_filter]\r\n        else:\r\n            to_filter = self._parse_data(to_filter)\r\n\r\n        if not isinstance(to_filter, list):\r\n            to_filter = repair_json(to_filter)\r\n            try:\r\n                to_filter_as_dict = json.loads(to_filter)\r\n            except JSONDecodeError:\r\n                try:\r\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\r\n                except JSONDecodeError as e:\r\n                    msg = f\"Invalid JSON: {e}\"\r\n                    raise ValueError(msg) from e\r\n        else:\r\n            to_filter = [repair_json(f) for f in to_filter]\r\n            to_filter_as_dict = []\r\n            for f in to_filter:\r\n                try:\r\n                    to_filter_as_dict.append(json.loads(f))\r\n                except JSONDecodeError:\r\n                    try:\r\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\r\n                    except JSONDecodeError as e:\r\n                        msg = f\"Invalid JSON: {e}\"\r\n                        raise ValueError(msg) from e\r\n            to_filter = to_filter_as_dict\r\n\r\n        full_filter_str = json.dumps(to_filter_as_dict, default=str)\r\n\r\n        logger.info(f\"to_filter: {full_filter_str}\")\r\n\r\n        results = jq.compile(self.query).input_text(full_filter_str).all()\r\n        logger.info(f\"results: {results}\")\r\n\r\n        return [\r\n            Data(data=value) if isinstance(value, dict) else Data(text=str(value))\r\n            for value in results\r\n        ]\r\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ Query to filter the data. The input is always a JSON list.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".results[] | {id, nome, tipo, setor, descricao, tipo_visao}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "CustomComponent-QqOeU",
        "measured": {
          "height": 293,
          "width": 320
        },
        "position": {
          "x": -1622.8273005659835,
          "y": 730.9864793381722
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseData-4jo5N",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "key": "ParseData",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "**Nome:** {nome}\n\n**Id:** {id}\n\n**Tipo:** {tipo}\n\n**Setor:** {setor}\n\n**Descrição:** {descricao}\n\n**Tipo de Visão:** {tipo_visao}\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "dragging": false,
        "id": "ParseData-4jo5N",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": -1226.154109516855,
          "y": 740.2537221039892
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseData-H9PdB",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "key": "ParseData",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Empresas: {text}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "dragging": false,
        "id": "ParseData-H9PdB",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": -31.220718750488345,
          "y": -638.4112151808794
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "MongoTextSearch-vLX80",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Busca textual em MongoDB (sem embeddings) com suporte a vários termos.",
            "display_name": "Mongo Text Search",
            "documentation": "",
            "edited": true,
            "field_order": [
              "mongodb_uri",
              "db_name",
              "collection_name",
              "search_field",
              "search_query",
              "limit"
            ],
            "frozen": false,
            "icon": "MongoDB",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "hidden": false,
                "method": "search_documents",
                "name": "results",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\r\nimport re\r\nfrom typing import List\r\n\r\nfrom pymongo import MongoClient\r\nfrom langflow.custom import Component\r\nfrom langflow.inputs import SecretStrInput, StrInput, IntInput, HandleInput\r\nfrom langflow.schema import Data, Message\r\nfrom langflow.template import Output\r\n\r\n\r\nclass MongoTextSearch(Component):\r\n    display_name = \"Mongo Text Search\"\r\n    description = \"Busca textual em MongoDB (sem embeddings) com suporte a vários termos.\"\r\n    icon = \"MongoDB\"\r\n    name = \"MongoTextSearch\"\r\n\r\n    # ------------------------------------------------------------------ #\r\n    # Inputs & outputs\r\n    # ------------------------------------------------------------------ #\r\n    inputs = [\r\n        SecretStrInput(name=\"mongodb_uri\",   display_name=\"MongoDB URI\", required=True),\r\n        StrInput(      name=\"db_name\",       display_name=\"Database\",    required=True),\r\n        StrInput(      name=\"collection_name\", display_name=\"Collection\", required=True),\r\n        StrInput(      name=\"search_field\",  display_name=\"Search Field\", value=\"text\", required=True),\r\n        HandleInput(   name=\"search_query\",  display_name=\"Search Query\", input_types=[\"Message\", \"str\", \"list\"]),\r\n        IntInput(      name=\"limit\",         display_name=\"Result Limit\", value=20),\r\n    ]\r\n    outputs = [\r\n        Output(name=\"results\", display_name=\"Search Results\", method=\"search_documents\"),\r\n    ]\r\n\r\n    # ------------------------------------------------------------------ #\r\n    # Helpers\r\n    # ------------------------------------------------------------------ #\r\n    @staticmethod\r\n    def _parse_terms(search_query) -> List[str]:\r\n        \"\"\"Converte Message/str/list em lista de termos.\"\"\"\r\n        # 1. Extrai texto cru\r\n        raw = search_query.text if isinstance(search_query, Message) else search_query\r\n\r\n        # 2. Tenta decodificar JSON (caso venha como string '[\\\"term1\\\", \\\"term2\\\"]')\r\n        if isinstance(raw, str):\r\n            try:\r\n                decoded = json.loads(raw)\r\n                raw = decoded\r\n            except (TypeError, ValueError):\r\n                # não é JSON: mantém string simples\r\n                pass\r\n\r\n        # 3. Garante lista\r\n        if isinstance(raw, list):\r\n            terms = raw\r\n        else:\r\n            # aceita string simples ou qualquer outro tipo; vira lista unitária\r\n            terms = [str(raw)]\r\n\r\n        # 4. Limpa espaços e remove vazios\r\n        return [t.strip() for t in terms if str(t).strip()]\r\n\r\n    # ------------------------------------------------------------------ #\r\n    # Main\r\n    # ------------------------------------------------------------------ #\r\n    def search_documents(self) -> Data:\r\n        terms = self._parse_terms(self.search_query)\r\n        if not terms:\r\n            self.status = \"No search terms provided\"\r\n            return Data(data={\"results\": []})\r\n\r\n        client = MongoClient(self.mongodb_uri)\r\n        collection = client[self.db_name][self.collection_name]\r\n        field = self.search_field\r\n\r\n        # Monta lista de cláusulas OR com regex case-insensitive escapado\r\n        or_clauses = [{field: {\"$regex\": re.escape(term), \"$options\": \"i\"}} for term in terms]\r\n        query = {\"$or\": or_clauses}\r\n\r\n        self.log(f\"Running query: {query}\")\r\n\r\n        results = list(collection.find(query).limit(self.limit))\r\n        for r in results:\r\n            r[\"_id\"] = str(r[\"_id\"])  # serializa ObjectId\r\n\r\n        self.status = f\"Found {len(results)} result(s) for {len(terms)} term(s)\"\r\n        return Data(data={\"results\": results})\r\n"
              },
              "collection_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Collection",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "collection_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "knowledge_nodes"
              },
              "db_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Database",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "db_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "DeepContext"
              },
              "limit": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Result Limit",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "limit",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 2
              },
              "mongodb_uri": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "MongoDB URI",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "mongodb_uri",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "search_field": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Search Field",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "search_field",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "nome"
              },
              "search_query": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message",
                  "str",
                  "list"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "search_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "MongoTextSearch"
        },
        "dragging": false,
        "id": "MongoTextSearch-vLX80",
        "measured": {
          "height": 622,
          "width": 320
        },
        "position": {
          "x": -797.6347793587398,
          "y": -901.7807546525385
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseJSONData-9XOVm",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields using jq queries.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\r\nfrom json import JSONDecodeError\r\n\r\nimport jq\r\nfrom json_repair import repair_json\r\nfrom loguru import logger\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.inputs import HandleInput, MessageTextInput\r\nfrom langflow.io import Output\r\nfrom langflow.schema import Data\r\nfrom langflow.schema.message import Message\r\n\r\n\r\nclass ParseJSONDataComponent(Component):\r\n    display_name = \"Parse JSON\"\r\n    description = \"Convert and extract JSON fields using jq queries.\"\r\n    icon = \"braces\"\r\n    name = \"ParseJSONData\"\r\n    legacy: bool = True\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"input_value\",\r\n            display_name=\"Input\",\r\n            info=\"Data object to filter.\",\r\n            required=True,\r\n            input_types=[\"Message\", \"Data\"],\r\n        ),\r\n        MessageTextInput(\r\n            name=\"query\",\r\n            display_name=\"JQ Query\",\r\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\r\n            required=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\r\n    ]\r\n\r\n    def _parse_data(self, input_value) -> str:\r\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\r\n            return input_value.text\r\n        if isinstance(input_value, Data):\r\n            return json.dumps(input_value.data, default=str)\r\n        return str(input_value)\r\n\r\n    def filter_data(self) -> list[Data]:\r\n        to_filter = self.input_value\r\n        if not to_filter:\r\n            return []\r\n\r\n        if isinstance(to_filter, list):\r\n            to_filter = [self._parse_data(f) for f in to_filter]\r\n        else:\r\n            to_filter = self._parse_data(to_filter)\r\n\r\n        if not isinstance(to_filter, list):\r\n            to_filter = repair_json(to_filter)\r\n            try:\r\n                to_filter_as_dict = json.loads(to_filter)\r\n            except JSONDecodeError:\r\n                try:\r\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\r\n                except JSONDecodeError as e:\r\n                    msg = f\"Invalid JSON: {e}\"\r\n                    raise ValueError(msg) from e\r\n        else:\r\n            to_filter = [repair_json(f) for f in to_filter]\r\n            to_filter_as_dict = []\r\n            for f in to_filter:\r\n                try:\r\n                    to_filter_as_dict.append(json.loads(f))\r\n                except JSONDecodeError:\r\n                    try:\r\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\r\n                    except JSONDecodeError as e:\r\n                        msg = f\"Invalid JSON: {e}\"\r\n                        raise ValueError(msg) from e\r\n            to_filter = to_filter_as_dict\r\n\r\n        full_filter_str = json.dumps(to_filter_as_dict, default=str)\r\n\r\n        logger.info(f\"to_filter: {full_filter_str}\")\r\n\r\n        results = jq.compile(self.query).input_text(full_filter_str).all()\r\n        logger.info(f\"results: {results}\")\r\n\r\n        return [\r\n            Data(data=value) if isinstance(value, dict) else Data(text=str(value))\r\n            for value in results\r\n        ]\r\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ Query to filter the data. The input is always a JSON list.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".results[].descricao"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "ParseJSONData-9XOVm",
        "measured": {
          "height": 293,
          "width": 320
        },
        "position": {
          "x": -410.97723751265596,
          "y": -608.3749232674952
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-vDvHD",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "inputs",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get text inputs from the Playground.",
            "display_name": "Text Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextInput",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0020353564437605998,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{\"atualizado_em\":\"2025-05-14T20:18:19.000Z\",\"classificacao\":\"entidade\",\"confidencialidade\":\"visão interna e externa\",\"criado_em\":\"2025-04-29T16:38:33.000Z\",\"descricao\":\"Profissional focado em melhorias de processos e interligência artificial. Usa power apps, na versão português que usa ;, para desenvolver soluções de frontend, langflow para estruturação de agentes de IA e MongoDB como banco de dados.\",\"email\":\"rodrigo.trindade@alocc.com.br\",\"id\":\"ent_ba95d6d1-7c07-48f7-8257-c04f37c0d3db\",\"nome\":\"Rodrigo Trindade\",\"setor\":[\"Sistemas\"],\"setores\":[\"Apoio\",\"Cadastro\",\"Operacional\",\"Risco\",\"Sistemas\"],\"status\":\"Ativo\",\"text\":\"Rodrigo Trindade - Profissional focado em melhorias de processos e interligência artificial. Usa power apps, na versão português que usa ;, para desenvolver soluções de frontend, langflow para estruturação de agentes de IA e MongoDB como banco de dados.\",\"tipo\":\"Colaborador\",\"tipo_visao\":[\"Operacional\",\"Tático\",\"Estratégico\"],\"pergunta\":\"Faça um resumo das últimas três reunião de fundos de investimentos\",\"anexo\":\"\"}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-vDvHD",
        "measured": {
          "height": 229,
          "width": 320
        },
        "position": {
          "x": -3297.907271702944,
          "y": 138.31772341952046
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseJSONData-Un65E",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields using jq queries.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\r\nfrom json import JSONDecodeError\r\nimport jq\r\nfrom json_repair import repair_json\r\nfrom loguru import logger\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.inputs import HandleInput, MessageTextInput\r\nfrom langflow.io import Output\r\nfrom langflow.schema import Data\r\nfrom langflow.schema.message import Message\r\n\r\n\r\nclass ParseJSONDataComponent(Component):\r\n    \"\"\"Parse JSON (or near‑JSON) and extract data via *jq* queries.\r\n\r\n    A pequena modificação nesta versão garante que **listas** retornadas pelo `jq` sejam\r\n    mantidas como estrutura JSON (em vez de serem convertidas para string), o que\r\n    permite repassá‑las intactas para outros componentes como o *Mongo Text Search*.\r\n    \"\"\"\r\n\r\n    display_name = \"Parse JSON\"\r\n    description = \"Convert and extract JSON fields using jq queries.\"\r\n    icon = \"braces\"\r\n    name = \"ParseJSONData\"\r\n    legacy = True\r\n\r\n    # ------------------------------------------------------------------\r\n    # Inputs & outputs\r\n    # ------------------------------------------------------------------\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"input_value\",\r\n            display_name=\"Input\",\r\n            info=\"Data object to filter.\",\r\n            required=True,\r\n            input_types=[\"Message\", \"Data\"],\r\n        ),\r\n        MessageTextInput(\r\n            name=\"query\",\r\n            display_name=\"JQ Query\",\r\n            info=\"JQ query to filter/transform the data.\",\r\n            required=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\r\n    ]\r\n\r\n    # ------------------------------------------------------------------\r\n    # Internal helpers\r\n    # ------------------------------------------------------------------\r\n    def _parse_data(self, input_value) -> str:\r\n        \"\"\"Coerce Message/Data/str into a JSON string suitable for `json.loads`.\"\"\"\r\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\r\n            return input_value.text\r\n        if isinstance(input_value, Data):\r\n            return json.dumps(input_value.data, default=str)\r\n        return str(input_value)\r\n\r\n    # ------------------------------------------------------------------\r\n    # Main method\r\n    # ------------------------------------------------------------------\r\n    def filter_data(self) -> list[Data]:\r\n        to_filter = self.input_value\r\n        if not to_filter:\r\n            return []\r\n\r\n        # Normaliza para lista de strings JSON reparáveis\r\n        if isinstance(to_filter, list):\r\n            to_filter = [self._parse_data(f) for f in to_filter]\r\n        else:\r\n            to_filter = self._parse_data(to_filter)\r\n\r\n        # Converte as strings em objetos Python\r\n        if not isinstance(to_filter, list):\r\n            to_filter = repair_json(to_filter)\r\n            try:\r\n                to_filter_as_dict = json.loads(to_filter)\r\n            except JSONDecodeError:\r\n                try:\r\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\r\n                except JSONDecodeError as e:\r\n                    raise ValueError(f\"Invalid JSON: {e}\") from e\r\n        else:\r\n            to_filter_as_dict = []\r\n            for f in to_filter:\r\n                f = repair_json(f)\r\n                try:\r\n                    to_filter_as_dict.append(json.loads(f))\r\n                except JSONDecodeError:\r\n                    try:\r\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\r\n                    except JSONDecodeError as e:\r\n                        raise ValueError(f\"Invalid JSON: {e}\") from e\r\n\r\n        full_filter_str = json.dumps(to_filter_as_dict, default=str)\r\n        logger.info(f\"to_filter: {full_filter_str}\")\r\n\r\n        results = jq.compile(self.query).input_text(full_filter_str).all()\r\n        logger.info(f\"results: {results}\")\r\n\r\n        # --------------------------------------------------------------\r\n        # CORREÇÃO chave: manter listas intocadas!\r\n        # --------------------------------------------------------------\r\n                # Se \"value\" é um dict → mantém como Data.data.\r\n        # Se é uma **lista** (ex.: [\"Foo\", \"Bar\"]) → serializa em JSON para manter\r\n        # a estrutura, mas evitar o erro de validação do Pydantic (Data espera dict).\r\n        # O JSON gerado (aspas duplas) será decodificado normalmente pelo próximo\r\n        # componente (Mongo Text Search) via json.loads().\r\n        return [\r\n            Data(data=value) if isinstance(value, dict) else\r\n            Data(text=json.dumps(value)) if isinstance(value, list) else\r\n            Data(text=str(value))\r\n            for value in results\r\n        ]\r\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ query to filter/transform the data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".results[].empresa"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "ParseJSONData-Un65E",
        "measured": {
          "height": 293,
          "width": 320
        },
        "position": {
          "x": -1544.648174027503,
          "y": -633.9965908293734
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseData-4Lwmh",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "key": "ParseData",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "dragging": false,
        "id": "ParseData-4Lwmh",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": -1177.363716966876,
          "y": -633.7153760705287
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseData-Z3oxH",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "hidden": false,
                "method": "parse_data_as_list",
                "name": "data_list",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "dragging": false,
        "id": "ParseData-Z3oxH",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": -1227.5929461302794,
          "y": 1131.4652068666655
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseJSONData-JNcoF",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields using jq queries.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\r\nfrom json import JSONDecodeError\r\nimport jq\r\nfrom json_repair import repair_json\r\nfrom loguru import logger\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.inputs import HandleInput, MessageTextInput\r\nfrom langflow.io import Output\r\nfrom langflow.schema import Data\r\nfrom langflow.schema.message import Message\r\n\r\n\r\nclass ParseJSONDataComponent(Component):\r\n    \"\"\"Parse JSON (or near‑JSON) and extract data via *jq* queries.\r\n\r\n    A pequena modificação nesta versão garante que **listas** retornadas pelo `jq` sejam\r\n    mantidas como estrutura JSON (em vez de serem convertidas para string), o que\r\n    permite repassá‑las intactas para outros componentes como o *Mongo Text Search*.\r\n    \"\"\"\r\n\r\n    display_name = \"Parse JSON\"\r\n    description = \"Convert and extract JSON fields using jq queries.\"\r\n    icon = \"braces\"\r\n    name = \"ParseJSONData\"\r\n    legacy = True\r\n\r\n    # ------------------------------------------------------------------\r\n    # Inputs & outputs\r\n    # ------------------------------------------------------------------\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"input_value\",\r\n            display_name=\"Input\",\r\n            info=\"Data object to filter.\",\r\n            required=True,\r\n            input_types=[\"Message\", \"Data\"],\r\n        ),\r\n        MessageTextInput(\r\n            name=\"query\",\r\n            display_name=\"JQ Query\",\r\n            info=\"JQ query to filter/transform the data.\",\r\n            required=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\r\n    ]\r\n\r\n    # ------------------------------------------------------------------\r\n    # Internal helpers\r\n    # ------------------------------------------------------------------\r\n    def _parse_data(self, input_value) -> str:\r\n        \"\"\"Coerce Message/Data/str into a JSON string suitable for `json.loads`.\"\"\"\r\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\r\n            return input_value.text\r\n        if isinstance(input_value, Data):\r\n            return json.dumps(input_value.data, default=str)\r\n        return str(input_value)\r\n\r\n    # ------------------------------------------------------------------\r\n    # Main method\r\n    # ------------------------------------------------------------------\r\n    def filter_data(self) -> list[Data]:\r\n        to_filter = self.input_value\r\n        if not to_filter:\r\n            return []\r\n\r\n        # Normaliza para lista de strings JSON reparáveis\r\n        if isinstance(to_filter, list):\r\n            to_filter = [self._parse_data(f) for f in to_filter]\r\n        else:\r\n            to_filter = self._parse_data(to_filter)\r\n\r\n        # Converte as strings em objetos Python\r\n        if not isinstance(to_filter, list):\r\n            to_filter = repair_json(to_filter)\r\n            try:\r\n                to_filter_as_dict = json.loads(to_filter)\r\n            except JSONDecodeError:\r\n                try:\r\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\r\n                except JSONDecodeError as e:\r\n                    raise ValueError(f\"Invalid JSON: {e}\") from e\r\n        else:\r\n            to_filter_as_dict = []\r\n            for f in to_filter:\r\n                f = repair_json(f)\r\n                try:\r\n                    to_filter_as_dict.append(json.loads(f))\r\n                except JSONDecodeError:\r\n                    try:\r\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\r\n                    except JSONDecodeError as e:\r\n                        raise ValueError(f\"Invalid JSON: {e}\") from e\r\n\r\n        full_filter_str = json.dumps(to_filter_as_dict, default=str)\r\n        logger.info(f\"to_filter: {full_filter_str}\")\r\n\r\n        results = jq.compile(self.query).input_text(full_filter_str).all()\r\n        logger.info(f\"results: {results}\")\r\n\r\n        # --------------------------------------------------------------\r\n        # CORREÇÃO chave: manter listas intocadas!\r\n        # --------------------------------------------------------------\r\n                # Se \"value\" é um dict → mantém como Data.data.\r\n        # Se é uma **lista** (ex.: [\"Foo\", \"Bar\"]) → serializa em JSON para manter\r\n        # a estrutura, mas evitar o erro de validação do Pydantic (Data espera dict).\r\n        # O JSON gerado (aspas duplas) será decodificado normalmente pelo próximo\r\n        # componente (Mongo Text Search) via json.loads().\r\n        return [\r\n            Data(data=value) if isinstance(value, dict) else\r\n            Data(text=json.dumps(value)) if isinstance(value, list) else\r\n            Data(text=str(value))\r\n            for value in results\r\n        ]\r\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ query to filter/transform the data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".results[].setores"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "ParseJSONData-JNcoF",
        "measured": {
          "height": 293,
          "width": 320
        },
        "position": {
          "x": -1593.9959006618578,
          "y": 1143.2536792359617
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "MongoDBAtlasVector-3QyXY",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "MongoDB Atlas Vector Store with search capabilities",
            "display_name": "MongoDB Atlas",
            "documentation": "",
            "edited": true,
            "field_order": [
              "mongodb_atlas_cluster_uri",
              "enable_mtls",
              "mongodb_atlas_client_cert",
              "db_name",
              "collection_name",
              "index_name",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "insert_mode",
              "embedding",
              "number_of_results",
              "setores",
              "min_similarity_score",
              "number_dimensions",
              "similarity",
              "quantization"
            ],
            "frozen": false,
            "icon": "MongoDB",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "hidden": false,
                "method": "search_documents",
                "name": "search_results",
                "options": null,
                "required_inputs": [
                  "collection_name",
                  "db_name",
                  "enable_mtls",
                  "index_name",
                  "mongodb_atlas_cluster_uri",
                  "number_dimensions"
                ],
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "hidden": null,
                "method": "as_dataframe",
                "name": "dataframe",
                "options": null,
                "required_inputs": [],
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import tempfile\r\nimport time\r\nfrom typing import Any, Dict, List, Optional\r\n\r\nimport certifi\r\nfrom bson.objectid import ObjectId\r\nfrom pymongo import MongoClient\r\nfrom pymongo.operations import SearchIndexModel\r\nfrom langchain_community.vectorstores import MongoDBAtlasVectorSearch\r\n\r\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\r\nfrom langflow.helpers.data import docs_to_data\r\nfrom langflow.io import (\r\n    BoolInput,\r\n    DropdownInput,\r\n    HandleInput,\r\n    IntInput,\r\n    SecretStrInput,\r\n    StrInput,\r\n)\r\nfrom langflow.schema import Data\r\n\r\n\r\nclass MongoVectorStoreComponent(LCVectorStoreComponent):\r\n    display_name = \"MongoDB Atlas\"\r\n    description = \"MongoDB Atlas Vector Store with search capabilities\"\r\n    name = \"MongoDBAtlasVector\"\r\n    icon = \"MongoDB\"\r\n    INSERT_MODES = [\"append\", \"overwrite\"]\r\n    SIMILARITY_OPTIONS = [\"cosine\", \"euclidean\", \"dotProduct\"]\r\n    QUANTIZATION_OPTIONS = [\"scalar\", \"binary\"]\r\n\r\n    inputs = [\r\n        SecretStrInput(\r\n            name=\"mongodb_atlas_cluster_uri\",\r\n            display_name=\"MongoDB Atlas Cluster URI\",\r\n            required=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"enable_mtls\",\r\n            display_name=\"Enable mTLS\",\r\n            value=False,\r\n            advanced=True,\r\n            required=True,\r\n        ),\r\n        SecretStrInput(\r\n            name=\"mongodb_atlas_client_cert\",\r\n            display_name=\"MongoDB Atlas Combined Client Certificate\",\r\n            required=False,\r\n            advanced=True,\r\n            info=\"Client certificate + private key PEM, if using mTLS.\",\r\n        ),\r\n        StrInput(name=\"db_name\", display_name=\"Database Name\", required=True),\r\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", required=True),\r\n        StrInput(\r\n            name=\"index_name\",\r\n            display_name=\"Index Name\",\r\n            required=True,\r\n            info=\"Name of the Atlas Search vector index.\",\r\n        ),\r\n        *LCVectorStoreComponent.inputs,\r\n        DropdownInput(\r\n            name=\"insert_mode\",\r\n            display_name=\"Insert Mode\",\r\n            options=INSERT_MODES,\r\n            value=INSERT_MODES[0],\r\n            advanced=True,\r\n            info=\"How to insert new documents (append or overwrite).\",\r\n        ),\r\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\r\n        IntInput(\r\n            name=\"number_of_results\",\r\n            display_name=\"Number of Results\",\r\n            value=20,\r\n            advanced=True,\r\n        ),\r\n        MultilineInput(\r\n            name=\"setores\",\r\n            display_name=\"Filtro por Setores\",\r\n            info=\"Lista de setores para filtrar (ex: ['Risco', 'Operacional']).\",\r\n            advanced=True,\r\n            required=False,\r\n        ),\r\n        StrInput(\r\n            name=\"min_similarity_score\",\r\n            display_name=\"Score Mínimo de Similaridade\",\r\n            info=\"Filtra resultados abaixo deste score (0.0-1.0).\",\r\n            advanced=True,\r\n            required=False,\r\n        ),\r\n        IntInput(\r\n            name=\"number_dimensions\",\r\n            display_name=\"Number of Dimensions\",\r\n            value=1536,\r\n            advanced=True,\r\n            required=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"similarity\",\r\n            display_name=\"Similarity\",\r\n            options=SIMILARITY_OPTIONS,\r\n            value=SIMILARITY_OPTIONS[0],\r\n            advanced=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"quantization\",\r\n            display_name=\"Quantization\",\r\n            options=QUANTIZATION_OPTIONS,\r\n            value=None,\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    @check_cached_vector_store\r\n    def build_vector_store(self) -> MongoDBAtlasVectorSearch:\r\n        # Configura cliente MongoDB, com mTLS se habilitado\r\n        client_cert_path = None\r\n        if self.enable_mtls and self.mongodb_atlas_client_cert:\r\n            pem = self.mongodb_atlas_client_cert.strip().replace(\" \", \"\\n\")\r\n            with tempfile.NamedTemporaryFile(delete=False) as tmp:\r\n                tmp.write(pem.encode(\"utf-8\"))\r\n                client_cert_path = tmp.name\r\n\r\n        client = (\r\n            MongoClient(\r\n                self.mongodb_atlas_cluster_uri,\r\n                tls=True,\r\n                tlsCertificateKeyFile=client_cert_path,\r\n                tlsCAFile=certifi.where(),\r\n            )\r\n            if self.enable_mtls\r\n            else MongoClient(self.mongodb_atlas_cluster_uri)\r\n        )\r\n        collection = client[self.db_name][self.collection_name]\r\n\r\n        # Prepara documentos\r\n        docs: List[Any] = []\r\n        for item in (self._prepare_ingest_data() or []):\r\n            docs.append(item.to_lc_document() if isinstance(item, Data) else item)\r\n\r\n        if docs:\r\n            if self.insert_mode == \"overwrite\":\r\n                collection.delete_many({})\r\n            return MongoDBAtlasVectorSearch.from_documents(\r\n                documents=docs,\r\n                embedding=self.embedding,\r\n                collection=collection,\r\n                index_name=self.index_name,\r\n            )\r\n\r\n        return MongoDBAtlasVectorSearch(\r\n            embedding=self.embedding,\r\n            collection=collection,\r\n            index_name=self.index_name,\r\n        )\r\n\r\n    def _parse_setores(self, raw: Optional[str]) -> Optional[List[str]]:\r\n        if not raw or not raw.strip():\r\n            return None\r\n        try:\r\n            import ast\r\n            raw = raw.strip()\r\n            if raw.startswith('[') and raw.endswith(']'):\r\n                parsed = ast.literal_eval(raw)\r\n                return [str(x) for x in parsed] if isinstance(parsed, list) else None\r\n            if ',' in raw:\r\n                return [x.strip().strip(\"'\\\"\") for x in raw.split(',')]\r\n            return [raw.strip().strip(\"'\\\"\")]\r\n        except Exception:\r\n            return None\r\n\r\n    def _create_setores_filter(self, setores: Optional[List[str]]) -> Optional[Dict[str, Any]]:\r\n        if not setores:\r\n            return None\r\n        return {\"setores\": {\"$in\": setores}}\r\n\r\n    def search_documents(self) -> List[Data]:\r\n        vs = self.build_vector_store()\r\n        self.verify_search_index(vs._collection)\r\n\r\n        if not isinstance(self.search_query, str) or not self.search_query:\r\n            return []\r\n\r\n        # Define número de resultados\r\n        k = self.number_of_results\r\n\r\n        setores_list = self._parse_setores(self.setores)\r\n        mongo_filter = self._create_setores_filter(setores_list)\r\n\r\n        try:\r\n            if mongo_filter:\r\n                docs_scores = vs.similarity_search_with_score(\r\n                    query=self.search_query,\r\n                    k=k,\r\n                    filter=mongo_filter,\r\n                )\r\n            else:\r\n                docs_scores = vs.similarity_search_with_score(\r\n                    query=self.search_query,\r\n                    k=k,\r\n                )\r\n        except TypeError:\r\n            # Fallback manual\r\n            all_scores = vs.similarity_search_with_score(query=self.search_query, k=k*3)\r\n            docs_scores = [item for item in all_scores if self._matches_setores(item[0], setores_list)][:k]\r\n\r\n        # Filtra por score mínimo\r\n        if self.min_similarity_score:\r\n            try:\r\n                min_s = float(self.min_similarity_score)\r\n                filtered = []\r\n                for doc, score in docs_scores:\r\n                    sim = (1/(1+score)) if self.similarity == \"euclidean\" else score\r\n                    if sim >= min_s:\r\n                        filtered.append((doc, score))\r\n                docs_scores = filtered\r\n            except ValueError:\r\n                pass\r\n\r\n        # Prepara dados de saída\r\n        processed = []\r\n        for entry in docs_scores:\r\n            doc, score = entry if isinstance(entry, tuple) else (entry, None)\r\n            if score is not None:\r\n                doc.metadata['similarity_score'] = float(score)\r\n            doc.metadata = {k: str(v) if isinstance(v, ObjectId) else v for k, v in doc.metadata.items()}\r\n            processed.append(doc)\r\n\r\n        data = docs_to_data(processed)\r\n        self.status = data\r\n        return data\r\n\r\n    def _matches_setores(self, doc: Data, setores_list: Optional[List[str]]) -> bool:\r\n        if not setores_list:\r\n            return True\r\n        val = doc.metadata.get('setores')\r\n        if isinstance(val, list):\r\n            return any(s in val for s in setores_list)\r\n        return isinstance(val, str) and val in setores_list\r\n\r\n    def verify_search_index(self, collection) -> None:\r\n        indexes = collection.list_search_indexes()\r\n        names = {idx['name']: idx['type'] for idx in indexes}\r\n        if self.index_name not in names or names[self.index_name] != 'vectorSearch':\r\n            fields = [\r\n                {\"type\": \"vector\", \"path\": self.index_field, \"numDimensions\": self.number_dimensions, \"similarity\": self.similarity, \"quantization\": self.quantization},\r\n                {\"type\": \"filter\", \"path\": \"setores\"},\r\n            ]\r\n            model = SearchIndexModel(definition={\"fields\": fields}, name=self.index_name, type=\"vectorSearch\")\r\n            collection.create_search_index(model)\r\n            time.sleep(20)\r\n"
              },
              "collection_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Collection Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "collection_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "knowledge_context"
              },
              "db_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Database Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "db_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "DeepContext"
              },
              "embedding": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_mtls": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Enable mTLS",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_mtls",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "index_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Index Name",
                "dynamic": false,
                "info": "Name of the Atlas Search vector index.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "index_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "vector_index_knowledge_context"
              },
              "ingest_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data",
                  "DataFrame"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "insert_mode": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Insert Mode",
                "dynamic": false,
                "info": "How to insert new documents (append or overwrite).",
                "name": "insert_mode",
                "options": [
                  "append",
                  "overwrite"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "append"
              },
              "min_similarity_score": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Score Mínimo de Similaridade",
                "dynamic": false,
                "info": "Filtra resultados abaixo deste score (0.0-1.0).",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "min_similarity_score",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "0.6"
              },
              "mongodb_atlas_client_cert": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "MongoDB Atlas Combined Client Certificate",
                "dynamic": false,
                "info": "Client certificate + private key PEM, if using mTLS.",
                "input_types": [],
                "load_from_db": false,
                "name": "mongodb_atlas_client_cert",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "mongodb_atlas_cluster_uri": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "MongoDB Atlas Cluster URI",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "mongodb_atlas_cluster_uri",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "number_dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Dimensions",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_dimensions",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1536
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "quantization": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Quantization",
                "dynamic": false,
                "info": "",
                "name": "quantization",
                "options": [
                  "scalar",
                  "binary"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str"
              },
              "search_query": {
                "_input_type": "QueryInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Enter a query to run a similarity search.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "search_query",
                "placeholder": "Enter a query...",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "query",
                "value": ""
              },
              "setores": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Filtro por Setores",
                "dynamic": false,
                "info": "Lista de setores para filtrar (ex: ['Risco', 'Operacional']).",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "setores",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "similarity": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Similarity",
                "dynamic": false,
                "info": "",
                "name": "similarity",
                "options": [
                  "cosine",
                  "euclidean",
                  "dotProduct"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "cosine"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "MongoDBAtlasVector"
        },
        "dragging": false,
        "id": "MongoDBAtlasVector-3QyXY",
        "measured": {
          "height": 960,
          "width": 320
        },
        "position": {
          "x": 7072.527427293065,
          "y": -3074.7846811450854
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "AzureOpenAIEmbeddings-SO8Kb",
          "node": {
            "base_classes": [
              "Embeddings"
            ],
            "beta": false,
            "category": "embeddings",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate embeddings using Azure OpenAI models.",
            "display_name": "Azure OpenAI Embeddings",
            "documentation": "https://python.langchain.com/docs/integrations/text_embedding/azureopenai",
            "edited": false,
            "field_order": [
              "model",
              "azure_endpoint",
              "azure_deployment",
              "api_version",
              "api_key",
              "dimensions"
            ],
            "frozen": false,
            "icon": "Azure",
            "key": "AzureOpenAIEmbeddings",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Embeddings",
                "hidden": false,
                "method": "build_embeddings",
                "name": "embeddings",
                "selected": "Embeddings",
                "tool_mode": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "api_version": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "API Version",
                "dynamic": false,
                "info": "",
                "name": "api_version",
                "options": [
                  "2022-12-01",
                  "2023-03-15-preview",
                  "2023-05-15",
                  "2023-06-01-preview",
                  "2023-07-01-preview",
                  "2023-08-01-preview"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "2023-08-01-preview"
              },
              "azure_deployment": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Deployment Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "azure_deployment",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text-embedding-3-small"
              },
              "azure_endpoint": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Azure Endpoint",
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "azure_endpoint",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://aion-ai-dev.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import AzureOpenAIEmbeddings\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import DropdownInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass AzureOpenAIEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI Embeddings\"\n    description: str = \"Generate embeddings using Azure OpenAI models.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/text_embedding/azureopenai\"\n    icon = \"Azure\"\n    name = \"AzureOpenAIEmbeddings\"\n\n    API_VERSION_OPTIONS = [\n        \"2022-12-01\",\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n    ]\n\n    inputs = [\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=OPENAI_EMBEDDING_MODEL_NAMES[0],\n        ),\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            required=True,\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n        ),\n        MessageTextInput(\n            name=\"azure_deployment\",\n            display_name=\"Deployment Name\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=API_VERSION_OPTIONS,\n            value=API_VERSION_OPTIONS[-1],\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"API Key\",\n            required=True,\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            embeddings = AzureOpenAIEmbeddings(\n                model=self.model,\n                azure_endpoint=self.azure_endpoint,\n                azure_deployment=self.azure_deployment,\n                api_version=self.api_version,\n                api_key=self.api_key,\n                dimensions=self.dimensions or None,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to AzureOpenAIEmbeddings API: {e}\"\n            raise ValueError(msg) from e\n\n        return embeddings\n"
              },
              "dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Dimensions",
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "list": false,
                "list_add_label": "Add More",
                "name": "dimensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "info": "",
                "name": "model",
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text-embedding-3-small"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AzureOpenAIEmbeddings"
        },
        "dragging": false,
        "id": "AzureOpenAIEmbeddings-SO8Kb",
        "measured": {
          "height": 496,
          "width": 320
        },
        "position": {
          "x": 6576.190317852015,
          "y": -2510.864970411395
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-3EZEi",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Rerank de chunks combinando resultados lexicais e semânticos usando um modelo LLM e pesos dinâmicos.",
            "display_name": "LLM Rerank (Lexical + Semântico + Pesos)",
            "documentation": "",
            "edited": true,
            "field_order": [
              "question",
              "rerank_pesos",
              "lexical_chunks",
              "semantic_chunks",
              "llm",
              "top_k",
              "score_final_min"
            ],
            "frozen": false,
            "icon": "Sort",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chunks Rerankeados",
                "hidden": null,
                "method": "rerank_chunks",
                "name": "reranked_chunks",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import List, Dict, Any\nfrom langflow.custom import Component\nfrom langflow.inputs import (\n    HandleInput,\n    IntInput,\n    FloatInput,\n    MultilineInput,\n)\nfrom langflow.schema import Data\nfrom langflow.template import Output\n\nclass LLMRerankComponent(Component):\n    display_name = \"LLM Rerank (Lexical + Semântico + Pesos)\"\n    icon = \"Sort\"\n    description = \"Rerank de chunks combinando resultados lexicais e semânticos usando um modelo LLM e pesos dinâmicos.\"\n\n    inputs = [\n        HandleInput(\n            name=\"question\",\n            display_name=\"Pergunta\",\n            input_types=[\"str\", \"Message\"],\n            required=True,\n        ),\n        HandleInput(\n            name=\"rerank_pesos\",\n            display_name=\"Rerank Pesos\",\n            input_types=[\"dict\", \"Data\", \"str\"],\n            required=True,\n        ),\n        HandleInput(\n            name=\"lexical_chunks\",\n            display_name=\"Chunks Lexicais\",\n            input_types=[\"list\", \"Data\"],\n            required=True,\n        ),\n        HandleInput(\n            name=\"semantic_chunks\",\n            display_name=\"Chunks Semânticos\",\n            input_types=[\"list\", \"Data\"],\n            required=True,\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"LLM Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            value=5,\n            info=\"Número máximo de chunks rerankeados a retornar.\",\n            required=False,\n        ),\n        MultilineInput(\n            name=\"score_final_min\",\n            display_name=\"Score Final Mínimo\",\n            value=\"2.0\",\n            info=\"Apenas chunks com rerank_score_final maior ou igual a este valor (de 0 a 5) serão retornados.\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            name=\"reranked_chunks\",\n            display_name=\"Chunks Rerankeados\",\n            method=\"rerank_chunks\",\n        ),\n    ]\n\n    def _extract_chunks(self, input_data):\n        if input_data is None:\n            return []\n        if isinstance(input_data, Data):\n            data = getattr(input_data, \"data\", None)\n            if isinstance(data, dict) and \"results\" in data:\n                return data[\"results\"]\n            if isinstance(data, dict) and \"reranked\" in data:\n                return data[\"reranked\"]\n            if isinstance(data, list):\n                return data\n            if isinstance(data, dict):\n                return list(data.values())\n            return []\n        if isinstance(input_data, dict):\n            if \"results\" in input_data:\n                return input_data[\"results\"]\n            if \"reranked\" in input_data:\n                return input_data[\"reranked\"]\n            return list(input_data.values())\n        if isinstance(input_data, list):\n            return input_data\n        return []\n\n    def _chunk_to_dict(self, chunk):\n        if isinstance(chunk, Data):\n            if hasattr(chunk, \"data\"):\n                return dict(chunk.data) if isinstance(chunk.data, dict) else {\"data\": chunk.data}\n            return {\"data\": chunk}\n        return dict(chunk) if not isinstance(chunk, dict) else chunk\n\n    def _call_llm(self, llm, prompt):\n        try:\n            return llm(prompt)\n        except Exception:\n            try:\n                return llm.invoke(prompt)\n            except Exception:\n                try:\n                    return llm.predict(prompt)\n                except Exception:\n                    return \"0\"\n\n    def _parse_pesos(self, pesos_input):\n        import json\n        if isinstance(pesos_input, dict):\n            return pesos_input\n        if isinstance(pesos_input, Data):\n            data = getattr(pesos_input, \"data\", None)\n            if isinstance(data, dict):\n                return data\n            if isinstance(data, str):\n                try:\n                    return json.loads(data)\n                except Exception:\n                    return {}\n        if isinstance(pesos_input, str):\n            try:\n                return json.loads(pesos_input)\n            except Exception:\n                return {}\n        return {}\n\n    def _parse_score_final_min(self, value):\n        try:\n            return float(str(value).replace(\",\", \".\"))\n        except Exception:\n            return 2.0\n\n    def rerank_chunks(self) -> Data:\n        import re\n        question = self.question.text if hasattr(self.question, 'text') else str(self.question)\n        pesos = self._parse_pesos(self.rerank_pesos)\n        lex_chunks = self._extract_chunks(self.lexical_chunks)\n        sem_chunks = self._extract_chunks(self.semantic_chunks)\n        llm = self.llm\n        top_k = self.top_k if hasattr(self, 'top_k') else 5\n        score_final_min = self._parse_score_final_min(getattr(self, 'score_final_min', 2.0))\n\n        peso_lexical = float(pesos.get('lexical', 0.5))\n        peso_semantic = float(pesos.get('semantic', 0.5))\n\n        # Junta e remove duplicados por _id\n        all_chunks = {}\n        for chunk in (lex_chunks or []):\n            chunk = self._chunk_to_dict(chunk)\n            _id = str(chunk.get('_id', id(chunk)))\n            chunk['source'] = 'lexical'\n            all_chunks[_id] = chunk\n        for chunk in (sem_chunks or []):\n            chunk = self._chunk_to_dict(chunk)\n            _id = str(chunk.get('_id', id(chunk)))\n            chunk['source'] = 'semantic'\n            all_chunks[_id] = chunk\n        chunks = list(all_chunks.values())\n\n        if not isinstance(chunks, list) or not chunks:\n            self.status = \"Nenhum chunk de entrada válido\"\n            return Data(data={\"reranked\": []})\n\n        # Prompt único para batch, agora incluindo a pergunta\n        prompt = f\"Pergunta: {question}\\nAvalie de 0 a 10 o quanto cada texto abaixo responde à pergunta. Responda apenas com uma lista de números, na mesma ordem dos textos.\\n\"\n        for idx, chunk in enumerate(chunks):\n            text = chunk.get('text', '') or chunk.get('page_content', '')\n            prompt += f\"\\nTexto {idx+1}: {text}\"\n\n        score_str = self._call_llm(llm, prompt)\n        print(f\"Prompt enviado ao LLM:\\n{prompt}\")\n        print(f\"Resposta bruta do LLM: {score_str}\")\n\n        # Extrai lista de scores\n        scores = re.findall(r\"[-+]?[0-9]*\\.?[0-9]+\", str(score_str))\n        scores = [float(s.replace(',', '.')) for s in scores][:len(chunks)]\n\n        # Atribui scores aos chunks e calcula score final com pesos\n        reranked = []\n        for chunk, score in zip(chunks, scores):\n            chunk['rerank_score_llm'] = score\n            # Score lexical e semântico (se existirem)\n            score_lexical = float(chunk.get('score', 0)) if chunk.get('source') == 'lexical' else 0.0\n            score_semantic = float(chunk.get('similarity_score', 0)) if chunk.get('source') == 'semantic' else 0.0\n            # Score final ponderado\n            chunk['rerank_score_final'] = (\n                peso_lexical * score_lexical + peso_semantic * score_semantic + score\n            ) / (1 + peso_lexical + peso_semantic)\n            reranked.append(chunk)\n\n        # Filtra apenas os chunks com score LLM > 0\n        reranked = [chunk for chunk in reranked if chunk.get('rerank_score_llm', 0) > 0]\n        # Filtra pelo score final mínimo\n        reranked = [chunk for chunk in reranked if chunk.get('rerank_score_final', 0) >= score_final_min]\n\n        reranked.sort(key=lambda x: x['rerank_score_final'], reverse=True)\n        reranked = reranked[:top_k]\n        self.status = f\"Rerank finalizado. Top {len(reranked)} retornados (score final >= {score_final_min}).\"\n        return Data(data={\"reranked\": reranked})\n"
              },
              "lexical_chunks": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Chunks Lexicais",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "list",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "lexical_chunks",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "llm": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "LLM Model",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "llm",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "question": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Pergunta",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "str",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "question",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "rerank_pesos": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Rerank Pesos",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "dict",
                  "Data",
                  "str"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "rerank_pesos",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "score_final_min": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Score Final Mínimo",
                "dynamic": false,
                "info": "Apenas chunks com rerank_score_final maior ou igual a este valor (de 0 a 5) serão retornados.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "score_final_min",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "3.0"
              },
              "semantic_chunks": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Chunks Semânticos",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "list",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "semantic_chunks",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Número máximo de chunks rerankeados a retornar.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "LLMRerankComponent"
        },
        "dragging": false,
        "id": "CustomComponent-3EZEi",
        "measured": {
          "height": 571,
          "width": 320
        },
        "position": {
          "x": 8985.53229415645,
          "y": -3592.440252500699
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "AzureOpenAIModel-UVu9j",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Azure OpenAI LLMs.",
            "display_name": "Azure OpenAI",
            "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "azure_endpoint",
              "azure_deployment",
              "api_key",
              "api_version",
              "temperature",
              "max_tokens"
            ],
            "frozen": false,
            "icon": "Azure",
            "key": "AzureOpenAIModel",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": false,
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [
                  "api_key",
                  "azure_deployment",
                  "azure_endpoint"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003924824467069744,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "api_version": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "API Version",
                "dynamic": false,
                "info": "",
                "name": "api_version",
                "options": [
                  "2024-10-01-preview",
                  "2024-09-01-preview",
                  "2024-08-01-preview",
                  "2024-07-01-preview",
                  "2024-06-01",
                  "2024-03-01-preview",
                  "2024-02-15-preview",
                  "2023-12-01-preview",
                  "2023-05-15"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "2024-06-01"
              },
              "azure_deployment": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Deployment Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "azure_deployment",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "name-gpt-4o-mini-aion"
              },
              "azure_endpoint": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Azure Endpoint",
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "azure_endpoint",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "endpoint-gpt-4o-mini-aion"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import AzureChatOpenAI\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import MessageTextInput\nfrom langflow.io import DropdownInput, IntInput, SecretStrInput, SliderInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2024-06-01\",\n        \"2024-07-01-preview\",\n        \"2024-08-01-preview\",\n        \"2024-09-01-preview\",\n        \"2024-10-01-preview\",\n        \"2023-05-15\",\n        \"2023-12-01-preview\",\n        \"2024-02-15-preview\",\n        \"2024-03-01-preview\",\n    ]\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\", required=True),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=sorted(AZURE_OPENAI_API_VERSIONS, reverse=True),\n            value=next(\n                (\n                    version\n                    for version in sorted(AZURE_OPENAI_API_VERSIONS, reverse=True)\n                    if not version.endswith(\"-preview\")\n                ),\n                AZURE_OPENAI_API_VERSIONS[0],\n            ),\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to AzureOpenAI API: {e}\"\n            raise ValueError(msg) from e\n\n        return output\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AzureOpenAIModel"
        },
        "dragging": false,
        "id": "AzureOpenAIModel-UVu9j",
        "measured": {
          "height": 688,
          "width": 320
        },
        "position": {
          "x": 8142.757212765977,
          "y": -2715.717740666496
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Pass-9TQz2",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Forwards the input message, unchanged.",
            "display_name": "Pass",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_message",
              "ignored_message"
            ],
            "frozen": false,
            "icon": "arrow-right",
            "key": "Pass",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "hidden": false,
                "method": "pass_message",
                "name": "output_message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 2.220446049250313e-16,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageInput\nfrom langflow.schema.message import Message\nfrom langflow.template import Output\n\n\nclass PassMessageComponent(Component):\n    display_name = \"Pass\"\n    description = \"Forwards the input message, unchanged.\"\n    name = \"Pass\"\n    icon = \"arrow-right\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_message\",\n            display_name=\"Input Message\",\n            info=\"The message to be passed forward.\",\n            required=True,\n        ),\n        MessageInput(\n            name=\"ignored_message\",\n            display_name=\"Ignored Message\",\n            info=\"A second message to be ignored. Used as a workaround for continuity.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output Message\", name=\"output_message\", method=\"pass_message\"),\n    ]\n\n    def pass_message(self) -> Message:\n        self.status = self.input_message\n        return self.input_message\n"
              },
              "ignored_message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Ignored Message",
                "dynamic": false,
                "info": "A second message to be ignored. Used as a workaround for continuity.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "ignored_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input_message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input Message",
                "dynamic": false,
                "info": "The message to be passed forward.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_message",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Analise a mensagem do usuário, o contexto da empresa, a persona, a **data atual fornecida** e o **mapeamento de campos do índice (`llm_field_mapping`)**. Retorne **exatamente** o seguinte JSON, sem comentários, sem explicações e sem campos extras: {   \"message\": \"<Pergunta reescrita, clara e objetiva>\",   \"classificador_pergunta\": [\"<Classificação da pergunta: 'corporativo_global', 'corporativo_local', 'casual', 'internet' ou 'requer_esclarecimento'. Se 'requer_esclarecimento', deve ser o único valor no array.>\"],   \"foco_analise\": \"<Opcional: palavras-chave ou frase curta para guiar a análise global>\",   \"rerank_pesos\": {     \"lexical\": 0.0,     \"semantic\": 0.0   },   \"search_instruction\": {      \"search_clause\": {       \"compound\": {         \"must\": [           {             \"compound\": {               \"should\": [                 { \"text\": { \"query\": \"<termo1_relevante>\", \"path\": [\"text\"] } },                 { \"text\": { \"query\": \"<termo2_relevante>\", \"path\": [\"text\"] } }               ],               \"minimumShouldMatch\": 1             }           },           {             \"equals\": {               \"path\": \"classificacao\",               \"value\": \"<valor_da_classificacao_inferida>\"             }           }         ]       }     },     \"limit\": 50,     \"sort_stage\": { \"atualizado_em\": -1 },     \"min_score\": 0.1   },   \"temporal_constraints\": \"<Texto descritivo detalhado sobre as restrições temporais da pergunta. Usar {data_atual} para contextualizar. Indicar 'Nenhuma restrição temporal específica identificada' se aplicável.>\" }  --- **Regras Gerais de Formatação JSON:** - Todos os campos do nível raiz (`message`, `classificador_pergunta`, `foco_analise`, `rerank_pesos`, `search_instruction`, `temporal_constraints`) são obrigatórios e devem ser irmãos. - Se `classificador_pergunta` contiver `\"requer_esclarecimento\"`:     - `classificador_pergunta` deve ser `[\"requer_esclarecimento\"]`. - `rerank_pesos` deve ser um objeto JSON simples apenas com `lexical` e `semantic`. - `search_instruction` deve ser um objeto JSON contendo `search_clause`, `limit`, `sort_stage`, e opcionalmente `min_score` como seus filhos diretos. - Dentro de `search_instruction.search_clause.compound`, o array `filter` (se presente) deve ser irmão de `must` e deve conter **apenas objetos JSON que representem cláusulas de filtro válidas do Atlas Search**. Não inclua strings literais ou placeholders textuais diretamente como elementos deste array. - O campo `path` em todas as cláusulas de busca (ex: `text`) deve ser um array de strings (ex: `[\"text\"]`, `[\"classificacao\"]`). - Use apenas aspas duplas e formatação JSON válida. Não adicione comentários ou campos não definidos no schema.   --- **Exemplo de Saída JSON Esperada (Data Atual para exemplos: 2024-08-22):**  // Exemplo 1: COM FILTRO DE CLASSIFICAÇÃO INFERIDO {   \"message\": \"Quais foram as ações discutidas na última ata da DNA Capital?\",   \"classificador_pergunta\": [\"corporativo_local\"],   \"foco_analise\": \"\",   \"rerank_pesos\": {     \"lexical\": 0.7,     \"semantic\": 0.3   },   \"search_instruction\": {     \"search_clause\": {       \"compound\": {         \"must\": [           {             \"compound\": {               \"should\": [                 { \"text\": { \"query\": \"ações\", \"path\": [\"text\"] } },                 { \"text\": { \"query\": \"DNA Capital\", \"path\": [\"text\"] } },                 { \"text\": { \"query\": \"ata\", \"path\": [\"text\"] } }               ],               \"minimumShouldMatch\": 1             }           },           {             \"equals\": {               \"path\": \"classificacao\",               \"value\": \"ata\"             }           }         ]       }     },     \"limit\": 50,     \"sort_stage\": { \"atualizado_em\": -1 },     \"min_score\": 0.1   },   \"temporal_constraints\": \"Contexto Temporal da Pergunta (Data Atual de Referência: 2024-08-22):\\n- Evento chave: 'última ata' da 'DNA Capital' sobre 'ações'.\\n- Objetivo da Filtragem Temporal: Dos chunks recuperados classificados como 'ata' e relacionados à 'DNA Capital', identificar o conjunto de chunks que pertencem ao evento (identificado pelo campo 'id') com a data 'atualizado_em' mais recente. Todos os chunks deste evento devem ser selecionados.\" }   // Exemplo 2: SEM FILTRO DE CLASSIFICAÇÃO (PERGUNTA GENÉRICA) {   \"message\": \"Resuma os principais pontos sobre IA da semana passada.\",   \"classificador_pergunta\": [\"corporativo_global\"],   \"foco_analise\": \"principais pontos IA\",   \"rerank_pesos\": {     \"lexical\": 0.2,     \"semantic\": 0.8   },   \"search_instruction\": {     \"search_clause\": {       \"compound\": {         \"must\": [           {             \"compound\": {               \"should\": [                 { \"text\": { \"query\": \"pontos\", \"path\": [\"text\"] } },                 { \"text\": { \"query\": \"IA\", \"path\": [\"text\"] } }               ],               \"minimumShouldMatch\": 1             }           }           // Sem filtro equals aqui pois não há classificação específica         ]       }     },     \"limit\": 50,     \"sort_stage\": { \"atualizado_em\": -1 },     \"min_score\": 0.1   },   \"temporal_constraints\": \"Contexto Temporal da Pergunta (Data Atual de Referência: 2024-08-22):\\n- Evento: 'principais pontos sobre IA'.\\n- Restrição temporal relativa: 'semana passada'. Considerando a data atual, isso corresponde ao período de 2024-08-12 a 2024-08-18.\\n- Objetivo da Filtragem Temporal: Selecionar chunks sobre 'IA' cuja 'atualizado_em' esteja dentro do período de 'semana passada' (2024-08-12 a 2024-08-18).\" }  // Exemplo 3: COM FILTRO DE CLASSIFICAÇÃO INFERIDO {   \"message\": \"Compare as estratégias das últimas duas reuniões de mercado.\",   \"classificador_pergunta\": [\"corporativo_global\"],   \"foco_analise\": \"comparação de estratégias de reuniões de mercado\",   \"rerank_pesos\": {     \"lexical\": 0.3,     \"semantic\": 0.7   },   \"search_instruction\": {     \"search_clause\": {       \"compound\": {         \"must\": [           {             \"compound\": {               \"should\": [                 { \"text\": { \"query\": \"estratégias\", \"path\": [\"text\"] } },                 { \"text\": { \"query\": \"mercado\", \"path\": [\"text\"] } }               ],               \"minimumShouldMatch\": 1             }           },           {             \"equals\": {               \"path\": \"classificacao\",               \"value\": \"reunião\"             }           }         ]       }     },     \"limit\": 70,     \"sort_stage\": { \"atualizado_em\": -1 },     \"min_score\": 0.1   },   \"temporal_constraints\": \"Contexto Temporal da Pergunta (Data Atual de Referência: 2024-08-22):\\n- Evento: 'últimas duas reuniões de mercado'.\\n- Objetivo da Filtragem Temporal: Identificar os dois eventos ('id') mais recentes classificados como 'reunião' e relacionados a 'mercado', ordenados por 'atualizado_em' descendente. Todos os chunks pertencentes a esses dois eventos devem ser selecionados.\" }  // Exemplo 4: PERGUNTA AMBÍGUA REQUERENDO ESCLARECIMENTO {   \"message\": \"Fale sobre aquilo que discutimos.\", // Pergunta original mantida   \"classificador_pergunta\": [\"requer_esclarecimento\"],   \"foco_analise\": \"aquilo que discutimos\", // LLM tentou extrair um foco   \"rerank_pesos\": {     \"lexical\": 0.5, // Pode usar pesos padrão ou baseados em leve inferência     \"semantic\": 0.5   },   \"search_instruction\": { // LLM pode tentar construir uma busca, mesmo que vaga     \"search_clause\": {       \"compound\": {         \"should\": [           { \"text\": { \"query\": \"aquilo\", \"path\": [\"text\"] } },           { \"text\": { \"query\": \"discutimos\", \"path\": [\"text\"] } }         ],         \"minimumShouldMatch\": 1       }     },     \"limit\": 50,     \"sort_stage\": { \"atualizado_em\": -1 },     \"min_score\": 0.1   },   \"temporal_constraints\": \"Nenhuma restrição temporal específica identificada com base na pergunta ambígua.\" } "
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Pass"
        },
        "dragging": false,
        "id": "Pass-9TQz2",
        "measured": {
          "height": 229,
          "width": 320
        },
        "position": {
          "x": -39.05309452073149,
          "y": 340.65524760542814
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CurrentDate-4E5Rw",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Returns the current date and time in the selected timezone.",
            "display_name": "Current Date",
            "documentation": "",
            "edited": true,
            "field_order": [
              "timezone"
            ],
            "frozen": false,
            "icon": "clock",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Current Date",
                "hidden": false,
                "method": "get_current_date",
                "name": "current_date",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from datetime import datetime\r\nfrom zoneinfo import ZoneInfo, available_timezones\r\n\r\nfrom loguru import logger\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import DropdownInput, Output\r\nfrom langflow.schema.message import Message\r\n\r\n\r\nclass CurrentDateComponent(Component):\r\n    display_name = \"Current Date\"\r\n    description = \"Returns the current date and time in the selected timezone.\"\r\n    icon = \"clock\"\r\n    name = \"CurrentDate\"\r\n\r\n    inputs = [\r\n        DropdownInput(\r\n            name=\"timezone\",\r\n            display_name=\"Timezone\",\r\n            options=list(available_timezones()),\r\n            value=\"UTC\",\r\n            info=\"Select the timezone for the current date and time.\",\r\n            tool_mode=True,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Current Date\", name=\"current_date\", method=\"get_current_date\"),\r\n    ]\r\n\r\n    def get_current_date(self) -> Message:\r\n        try:\r\n            tz = ZoneInfo(self.timezone)\r\n            current_date_str = datetime.now(tz).strftime(\"%Y-%m-%d\")\r\n            full_message_text = f\"Current date in {self.timezone}: {datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S %Z\")}\"\r\n            self.status = full_message_text\r\n            return Message(text=current_date_str, data={\"full_date_info\": full_message_text, \"date_simple\": current_date_str})\r\n        except Exception as e:  # noqa: BLE001\r\n            logger.opt(exception=True).debug(\"Error getting current date\")\r\n            error_message = f\"Error: {e}\"\r\n            self.status = error_message\r\n            return Message(text=error_message)\r\n"
              },
              "timezone": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Timezone",
                "dynamic": false,
                "info": "Select the timezone for the current date and time.",
                "load_from_db": false,
                "name": "timezone",
                "options": [
                  "Pacific/Kwajalein",
                  "US/Samoa",
                  "Etc/GMT-11",
                  "America/Araguaina",
                  "America/Bahia_Banderas",
                  "Africa/Windhoek",
                  "Iran",
                  "America/Tortola",
                  "Europe/Simferopol",
                  "Africa/Bujumbura",
                  "Africa/Mbabane",
                  "Asia/Ulan_Bator",
                  "Europe/Vienna",
                  "Asia/Karachi",
                  "Asia/Novosibirsk",
                  "Pacific/Guam",
                  "Asia/Macao",
                  "Asia/Pyongyang",
                  "Antarctica/Palmer",
                  "Asia/Kolkata",
                  "America/Argentina/Cordoba",
                  "America/Nassau",
                  "Etc/Zulu",
                  "Etc/UTC",
                  "Europe/Andorra",
                  "Asia/Tbilisi",
                  "Asia/Yekaterinburg",
                  "Europe/Tallinn",
                  "America/Menominee",
                  "Indian/Kerguelen",
                  "Asia/Jayapura",
                  "Europe/Vilnius",
                  "Jamaica",
                  "America/Yakutat",
                  "Canada/Mountain",
                  "Antarctica/DumontDUrville",
                  "Etc/GMT+7",
                  "America/Kentucky/Monticello",
                  "Etc/GMT+6",
                  "Europe/Podgorica",
                  "America/Cayenne",
                  "America/Port-au-Prince",
                  "America/Argentina/Ushuaia",
                  "America/Dominica",
                  "Pacific/Enderbury",
                  "Africa/Ouagadougou",
                  "America/Vancouver",
                  "Africa/Kampala",
                  "Pacific/Truk",
                  "Asia/Chongqing",
                  "America/Kentucky/Louisville",
                  "Europe/Belfast",
                  "Asia/Hebron",
                  "Australia/South",
                  "America/Rio_Branco",
                  "Asia/Ashkhabad",
                  "America/Matamoros",
                  "America/Caracas",
                  "Europe/Prague",
                  "US/Central",
                  "Asia/Taipei",
                  "Pacific/Norfolk",
                  "Europe/Samara",
                  "Canada/Saskatchewan",
                  "America/Jamaica",
                  "Atlantic/Bermuda",
                  "Africa/Abidjan",
                  "Pacific/Johnston",
                  "America/Argentina/La_Rioja",
                  "America/Montevideo",
                  "America/Campo_Grande",
                  "ROC",
                  "Europe/Kirov",
                  "America/Monterrey",
                  "Indian/Cocos",
                  "America/Anguilla",
                  "Etc/GMT-12",
                  "Europe/Oslo",
                  "Asia/Ujung_Pandang",
                  "Asia/Irkutsk",
                  "America/Buenos_Aires",
                  "America/Pangnirtung",
                  "Australia/North",
                  "America/Fort_Nelson",
                  "Europe/Dublin",
                  "Etc/GMT0",
                  "Pacific/Rarotonga",
                  "Pacific/Nauru",
                  "NZ",
                  "Indian/Mahe",
                  "Pacific/Chuuk",
                  "America/Resolute",
                  "America/Louisville",
                  "America/Indiana/Knox",
                  "Europe/Chisinau",
                  "Etc/GMT-7",
                  "Africa/Mogadishu",
                  "Antarctica/Syowa",
                  "Etc/GMT-14",
                  "America/Belem",
                  "America/Ciudad_Juarez",
                  "America/Indianapolis",
                  "Europe/Rome",
                  "Pacific/Tarawa",
                  "America/Creston",
                  "Europe/Nicosia",
                  "Etc/GMT+8",
                  "Australia/Lindeman",
                  "Africa/Brazzaville",
                  "America/Punta_Arenas",
                  "America/Atikokan",
                  "Australia/Broken_Hill",
                  "Europe/Astrakhan",
                  "America/Metlakatla",
                  "Australia/Brisbane",
                  "Asia/Yangon",
                  "Asia/Macau",
                  "America/Coral_Harbour",
                  "Pacific/Noumea",
                  "Europe/Uzhgorod",
                  "America/St_Thomas",
                  "Asia/Oral",
                  "Hongkong",
                  "America/Marigot",
                  "Etc/GMT-6",
                  "Europe/Copenhagen",
                  "America/Atka",
                  "US/Indiana-Starke",
                  "GMT-0",
                  "America/Argentina/Catamarca",
                  "Mexico/BajaSur",
                  "Pacific/Marquesas",
                  "Egypt",
                  "Pacific/Tongatapu",
                  "Mexico/BajaNorte",
                  "Asia/Novokuznetsk",
                  "Indian/Comoro",
                  "Europe/Busingen",
                  "America/Moncton",
                  "Navajo",
                  "Asia/Nicosia",
                  "Brazil/Acre",
                  "Europe/Volgograd",
                  "Indian/Reunion",
                  "Etc/GMT-5",
                  "US/East-Indiana",
                  "America/Tijuana",
                  "Antarctica/Troll",
                  "Europe/Tirane",
                  "America/Rankin_Inlet",
                  "America/Santo_Domingo",
                  "GMT",
                  "America/Phoenix",
                  "Pacific/Pago_Pago",
                  "GMT+0",
                  "GMT0",
                  "America/Detroit",
                  "Asia/Ashgabat",
                  "US/Arizona",
                  "America/Maceio",
                  "Africa/Maseru",
                  "Atlantic/Reykjavik",
                  "America/Shiprock",
                  "America/Argentina/Tucuman",
                  "Africa/Luanda",
                  "America/Boise",
                  "Asia/Qostanay",
                  "Pacific/Niue",
                  "Asia/Vientiane",
                  "Eire",
                  "America/Virgin",
                  "EET",
                  "Antarctica/Casey",
                  "CST6CDT",
                  "Asia/Qyzylorda",
                  "America/Cambridge_Bay",
                  "Europe/Kaliningrad",
                  "America/El_Salvador",
                  "Africa/Tunis",
                  "Asia/Baghdad",
                  "Asia/Kuwait",
                  "Greenwich",
                  "Atlantic/South_Georgia",
                  "Europe/Tiraspol",
                  "America/Puerto_Rico",
                  "Asia/Anadyr",
                  "America/Knox_IN",
                  "Asia/Tashkent",
                  "America/Cuiaba",
                  "Asia/Singapore",
                  "Europe/Paris",
                  "Africa/Ndjamena",
                  "Atlantic/Cape_Verde",
                  "Atlantic/Madeira",
                  "Asia/Yerevan",
                  "US/Hawaii",
                  "Etc/GMT-3",
                  "Asia/Dili",
                  "America/Aruba",
                  "Etc/GMT+5",
                  "Asia/Dacca",
                  "Chile/Continental",
                  "Europe/Budapest",
                  "Australia/Victoria",
                  "Europe/Skopje",
                  "America/Eirunepe",
                  "US/Pacific",
                  "Asia/Barnaul",
                  "Africa/Gaborone",
                  "America/Guyana",
                  "America/St_Barthelemy",
                  "Zulu",
                  "America/St_Lucia",
                  "Europe/Bratislava",
                  "Asia/Harbin",
                  "America/Thunder_Bay",
                  "America/Argentina/San_Juan",
                  "America/Goose_Bay",
                  "America/Manaus",
                  "Pacific/Gambier",
                  "America/Nome",
                  "Asia/Kabul",
                  "America/Curacao",
                  "Chile/EasterIsland",
                  "Pacific/Kiritimati",
                  "Brazil/East",
                  "Asia/Aden",
                  "America/Panama",
                  "America/Indiana/Marengo",
                  "PST8PDT",
                  "Pacific/Apia",
                  "America/North_Dakota/New_Salem",
                  "Canada/Eastern",
                  "Asia/Kathmandu",
                  "Africa/Djibouti",
                  "America/Yellowknife",
                  "Asia/Baku",
                  "America/Glace_Bay",
                  "America/La_Paz",
                  "Pacific/Palau",
                  "America/New_York",
                  "America/Paramaribo",
                  "Australia/Yancowinna",
                  "America/Miquelon",
                  "America/Danmarkshavn",
                  "America/Port_of_Spain",
                  "Israel",
                  "Europe/Warsaw",
                  "Europe/Belgrade",
                  "America/Mexico_City",
                  "Asia/Bahrain",
                  "Africa/Bamako",
                  "Europe/Zurich",
                  "America/Jujuy",
                  "Asia/Dubai",
                  "Africa/Libreville",
                  "Etc/GMT-10",
                  "America/Indiana/Vincennes",
                  "Africa/Bangui",
                  "Asia/Krasnoyarsk",
                  "Asia/Chita",
                  "Indian/Chagos",
                  "America/Anchorage",
                  "Asia/Katmandu",
                  "Asia/Phnom_Penh",
                  "HST",
                  "Pacific/Ponape",
                  "Pacific/Chatham",
                  "Indian/Mayotte",
                  "Asia/Aqtobe",
                  "America/Managua",
                  "Europe/London",
                  "Etc/GMT+1",
                  "Etc/GMT",
                  "Australia/Currie",
                  "America/Havana",
                  "America/Inuvik",
                  "Canada/Central",
                  "America/Guadeloupe",
                  "Europe/Minsk",
                  "Australia/Melbourne",
                  "Pacific/Yap",
                  "Europe/Malta",
                  "America/Indiana/Indianapolis",
                  "Singapore",
                  "Asia/Choibalsan",
                  "America/Porto_Velho",
                  "Africa/Banjul",
                  "Arctic/Longyearbyen",
                  "Portugal",
                  "Africa/Kigali",
                  "Asia/Sakhalin",
                  "Etc/GMT-9",
                  "Atlantic/Faeroe",
                  "Brazil/West",
                  "Australia/West",
                  "Australia/Lord_Howe",
                  "Africa/Niamey",
                  "Brazil/DeNoronha",
                  "America/Adak",
                  "Africa/Porto-Novo",
                  "GB-Eire",
                  "America/Catamarca",
                  "Etc/GMT+3",
                  "Pacific/Funafuti",
                  "America/Belize",
                  "Asia/Chungking",
                  "America/Blanc-Sablon",
                  "Etc/GMT+12",
                  "America/Sao_Paulo",
                  "Antarctica/South_Pole",
                  "Pacific/Fakaofo",
                  "America/Boa_Vista",
                  "Europe/Stockholm",
                  "ROK",
                  "Europe/Kiev",
                  "America/Ensenada",
                  "Asia/Hong_Kong",
                  "Europe/Mariehamn",
                  "America/Indiana/Tell_City",
                  "US/Mountain",
                  "Kwajalein",
                  "America/Lima",
                  "Africa/Juba",
                  "America/Edmonton",
                  "Europe/Guernsey",
                  "America/North_Dakota/Beulah",
                  "Asia/Urumqi",
                  "America/Argentina/Jujuy",
                  "Etc/GMT-4",
                  "Pacific/Easter",
                  "America/Whitehorse",
                  "Europe/Luxembourg",
                  "Asia/Thimphu",
                  "America/Antigua",
                  "America/Guayaquil",
                  "Pacific/Pitcairn",
                  "Japan",
                  "Asia/Vladivostok",
                  "America/Montreal",
                  "Europe/Sofia",
                  "Asia/Saigon",
                  "Pacific/Majuro",
                  "Pacific/Samoa",
                  "Etc/GMT-13",
                  "Asia/Ust-Nera",
                  "GB",
                  "Australia/NSW",
                  "Asia/Rangoon",
                  "America/Cordoba",
                  "Asia/Tomsk",
                  "Europe/Moscow",
                  "America/Costa_Rica",
                  "Africa/Lubumbashi",
                  "America/Indiana/Vevay",
                  "Asia/Yakutsk",
                  "Indian/Mauritius",
                  "Asia/Muscat",
                  "America/Lower_Princes",
                  "Pacific/Fiji",
                  "Atlantic/Stanley",
                  "MST7MDT",
                  "Cuba",
                  "Asia/Samarkand",
                  "Antarctica/Mawson",
                  "America/Winnipeg",
                  "America/Halifax",
                  "Asia/Amman",
                  "Australia/Perth",
                  "Canada/Yukon",
                  "Europe/Amsterdam",
                  "Asia/Qatar",
                  "Etc/GMT+0",
                  "Africa/Addis_Ababa",
                  "Europe/Ljubljana",
                  "Etc/GMT-1",
                  "America/Guatemala",
                  "America/Scoresbysund",
                  "Antarctica/Macquarie",
                  "Asia/Bangkok",
                  "WET",
                  "Europe/Saratov",
                  "Europe/Vatican",
                  "Indian/Antananarivo",
                  "Pacific/Port_Moresby",
                  "Europe/Jersey",
                  "Europe/Kyiv",
                  "Canada/Atlantic",
                  "Europe/Sarajevo",
                  "Asia/Bishkek",
                  "America/Godthab",
                  "UCT",
                  "Asia/Seoul",
                  "Australia/ACT",
                  "Asia/Brunei",
                  "Africa/Casablanca",
                  "Asia/Damascus",
                  "Australia/Hobart",
                  "Asia/Calcutta",
                  "Asia/Ho_Chi_Minh",
                  "Australia/Queensland",
                  "Europe/Helsinki",
                  "Etc/GMT-0",
                  "Asia/Shanghai",
                  "America/Denver",
                  "Europe/Zaporozhye",
                  "Africa/Johannesburg",
                  "America/Coyhaique",
                  "Africa/Kinshasa",
                  "Asia/Istanbul",
                  "America/Sitka",
                  "Europe/Ulyanovsk",
                  "Asia/Beirut",
                  "Africa/Dakar",
                  "America/Juneau",
                  "US/Aleutian",
                  "America/Argentina/Salta",
                  "Europe/Athens",
                  "Asia/Makassar",
                  "Asia/Magadan",
                  "Australia/LHI",
                  "Antarctica/Rothera",
                  "Africa/El_Aaiun",
                  "Europe/Bucharest",
                  "Asia/Tel_Aviv",
                  "Pacific/Saipan",
                  "Asia/Ulaanbaatar",
                  "Etc/GMT+10",
                  "America/Mendoza",
                  "Antarctica/McMurdo",
                  "Etc/GMT+4",
                  "Europe/Gibraltar",
                  "Antarctica/Vostok",
                  "Asia/Manila",
                  "America/Argentina/Buenos_Aires",
                  "Atlantic/Faroe",
                  "CET",
                  "Universal",
                  "Africa/Accra",
                  "PRC",
                  "Africa/Asmera",
                  "America/Indiana/Petersburg",
                  "America/St_Johns",
                  "Europe/San_Marino",
                  "Africa/Monrovia",
                  "Iceland",
                  "Pacific/Efate",
                  "America/Mazatlan",
                  "Africa/Bissau",
                  "Etc/GMT+11",
                  "Africa/Freetown",
                  "Pacific/Kosrae",
                  "Pacific/Midway",
                  "America/Tegucigalpa",
                  "Europe/Lisbon",
                  "Africa/Nouakchott",
                  "Africa/Douala",
                  "America/Cayman",
                  "Asia/Kashgar",
                  "Africa/Sao_Tome",
                  "Etc/GMT-8",
                  "Europe/Monaco",
                  "America/Fort_Wayne",
                  "Australia/Canberra",
                  "America/Hermosillo",
                  "America/Argentina/Rio_Gallegos",
                  "NZ-CHAT",
                  "Etc/GMT+9",
                  "Europe/Zagreb",
                  "Africa/Timbuktu",
                  "US/Eastern",
                  "Australia/Eucla",
                  "Africa/Nairobi",
                  "Atlantic/Jan_Mayen",
                  "MET",
                  "America/Santiago",
                  "America/Fortaleza",
                  "America/Ojinaga",
                  "Pacific/Wake",
                  "Europe/Brussels",
                  "Asia/Dhaka",
                  "America/Nuuk",
                  "Etc/GMT-2",
                  "America/Cancun",
                  "Asia/Srednekolymsk",
                  "Asia/Kuala_Lumpur",
                  "Europe/Madrid",
                  "America/Chihuahua",
                  "UTC",
                  "Pacific/Auckland",
                  "America/Bogota",
                  "Libya",
                  "Africa/Harare",
                  "America/Barbados",
                  "America/St_Vincent",
                  "America/Montserrat",
                  "America/North_Dakota/Center",
                  "Asia/Pontianak",
                  "America/Nipigon",
                  "America/Merida",
                  "Pacific/Kanton",
                  "Etc/Greenwich",
                  "Indian/Christmas",
                  "Asia/Famagusta",
                  "Australia/Sydney",
                  "EST",
                  "Africa/Tripoli",
                  "Asia/Colombo",
                  "Factory",
                  "Pacific/Bougainville",
                  "Europe/Isle_of_Man",
                  "America/Asuncion",
                  "Europe/Riga",
                  "Australia/Darwin",
                  "America/Argentina/Mendoza",
                  "America/Dawson_Creek",
                  "America/Bahia",
                  "Atlantic/Azores",
                  "Antarctica/Davis",
                  "Canada/Newfoundland",
                  "America/Recife",
                  "America/St_Kitts",
                  "Asia/Omsk",
                  "Africa/Algiers",
                  "W-SU",
                  "Pacific/Tahiti",
                  "Asia/Tehran",
                  "Australia/Adelaide",
                  "Asia/Kamchatka",
                  "Europe/Berlin",
                  "Atlantic/St_Helena",
                  "Pacific/Pohnpei",
                  "America/Porto_Acre",
                  "Africa/Lagos",
                  "Canada/Pacific",
                  "America/Kralendijk",
                  "America/Santarem",
                  "Asia/Hovd",
                  "America/Chicago",
                  "Asia/Atyrau",
                  "America/Argentina/ComodRivadavia",
                  "Africa/Conakry",
                  "Asia/Dushanbe",
                  "Asia/Gaza",
                  "Asia/Tokyo",
                  "Australia/Tasmania",
                  "Asia/Kuching",
                  "Pacific/Honolulu",
                  "Asia/Almaty",
                  "Etc/UCT",
                  "America/Rainy_River",
                  "America/Iqaluit",
                  "Indian/Maldives",
                  "Etc/Universal",
                  "America/Rosario",
                  "Poland",
                  "Europe/Istanbul",
                  "Asia/Riyadh",
                  "US/Alaska",
                  "MST",
                  "Asia/Jerusalem",
                  "Asia/Aqtau",
                  "America/Noronha",
                  "Pacific/Galapagos",
                  "Turkey",
                  "Africa/Ceuta",
                  "Africa/Maputo",
                  "America/Grenada",
                  "Africa/Asmara",
                  "Asia/Khandyga",
                  "localtime",
                  "America/Toronto",
                  "Africa/Blantyre",
                  "Pacific/Guadalcanal",
                  "Asia/Jakarta",
                  "Africa/Lome",
                  "Asia/Thimbu",
                  "America/Argentina/San_Luis",
                  "America/Dawson",
                  "America/Thule",
                  "Mexico/General",
                  "Africa/Malabo",
                  "America/Swift_Current",
                  "Africa/Lusaka",
                  "America/Regina",
                  "America/Martinique",
                  "America/Santa_Isabel",
                  "America/Indiana/Winamac",
                  "Atlantic/Canary",
                  "Etc/GMT+2",
                  "Africa/Cairo",
                  "America/Grand_Turk",
                  "Pacific/Wallis",
                  "EST5EDT",
                  "Africa/Khartoum",
                  "Africa/Dar_es_Salaam",
                  "US/Michigan",
                  "America/Los_Angeles",
                  "Europe/Vaduz"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "America/Sao_Paulo"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CurrentDate"
        },
        "dragging": false,
        "id": "CurrentDate-4E5Rw",
        "measured": {
          "height": 249,
          "width": 320
        },
        "position": {
          "x": -32.4949364923516,
          "y": -256.9048480072987
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-h2GUm",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert a DataFrame into plain text following a specified template. Each column in the DataFrame is treated as a possible template key, e.g. {col_name}.",
            "display_name": "Parse DataFrame",
            "documentation": "",
            "edited": true,
            "field_order": [
              "df",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Text",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import DataFrameInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataFrameComponent(Component):\n    display_name = \"Parse DataFrame\"\n    description = (\n        \"Convert a DataFrame into plain text following a specified template. \"\n        \"Each column in the DataFrame is treated as a possible template key, e.g. {col_name}.\"\n    )\n    icon = \"braces\"\n    name = \"ParseDataFrame\"\n    legacy = True\n\n    inputs = [\n        DataFrameInput(name=\"df\", display_name=\"DataFrame\", info=\"The DataFrame to convert to text rows.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=(\n                \"The template for formatting each row. \"\n                \"Use placeholders matching column names in the DataFrame, for example '{col1}', '{col2}'.\"\n            ),\n            value=\"{text}\",\n        ),\n        StrInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String that joins all row texts when building the single Text output.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Text\",\n            name=\"text\",\n            info=\"All rows combined into a single text, each row formatted by the template and separated by `sep`.\",\n            method=\"parse_data\",\n        ),\n    ]\n\n    def _clean_args(self):\n        dataframe = self.df\n        template = self.template or \"{text}\"\n        sep = self.sep or \"\\n\"\n        return dataframe, template, sep\n\n    def parse_data(self) -> Message:\n        \"\"\"Converts each row of the DataFrame into a formatted string using the template.\n\n        then joins them with `sep`. Returns a single combined string as a Message.\n        \"\"\"\n        dataframe, template, sep = self._clean_args()\n\n        lines = []\n        # For each row in the DataFrame, build a dict and format\n        for _, row in dataframe.iterrows():\n            row_dict = row.to_dict()\n            text_line = template.format(**row_dict)  # e.g. template=\"{text}\", row_dict={\"text\": \"Hello\"}\n            lines.append(text_line)\n\n        # Join all lines with the provided separator\n        result_string = sep.join(lines)\n        self.status = result_string  # store in self.status for UI logs\n        return Message(text=result_string)\n"
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The DataFrame to convert to text rows.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String that joins all row texts when building the single Text output.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template for formatting each row. Use placeholders matching column names in the DataFrame, for example '{col1}', '{col2}'.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{messages}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseDataFrame"
        },
        "dragging": false,
        "id": "CustomComponent-h2GUm",
        "measured": {
          "height": 333,
          "width": 320
        },
        "position": {
          "x": 1445.1034794535158,
          "y": -419.37151533957496
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "RegexExtractorComponent-Wj6qw",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extract patterns from text using regular expressions.",
            "display_name": "Regex Extractor",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_text",
              "pattern"
            ],
            "frozen": false,
            "icon": "regex",
            "key": "RegexExtractorComponent",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "hidden": false,
                "method": "extract_matches",
                "name": "data",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "get_matches_text",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass RegexExtractorComponent(Component):\n    display_name = \"Regex Extractor\"\n    description = \"Extract patterns from text using regular expressions.\"\n    icon = \"regex\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            info=\"The text to analyze\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"pattern\",\n            display_name=\"Regex Pattern\",\n            info=\"The regular expression pattern to match\",\n            value=r\"\",\n            required=True,\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"extract_matches\"),\n        Output(display_name=\"Message\", name=\"text\", method=\"get_matches_text\"),\n    ]\n\n    def extract_matches(self) -> list[Data]:\n        if not self.pattern or not self.input_text:\n            self.status = []\n            return []\n\n        try:\n            # Compile regex pattern\n            pattern = re.compile(self.pattern)\n\n            # Find all matches in the input text\n            matches = pattern.findall(self.input_text)\n\n            # Filter out empty matches\n            filtered_matches = [match for match in matches if match]  # Remove empty matches\n\n            # Return empty list for no matches, or list of matches if found\n            result: list = [] if not filtered_matches else [Data(data={\"match\": match}) for match in filtered_matches]\n\n        except re.error as e:\n            error_message = f\"Invalid regex pattern: {e!s}\"\n            result = [Data(data={\"error\": error_message})]\n        except ValueError as e:\n            error_message = f\"Error extracting matches: {e!s}\"\n            result = [Data(data={\"error\": error_message})]\n\n        self.status = result\n        return result\n\n    def get_matches_text(self) -> Message:\n        \"\"\"Get matches as a formatted text message.\"\"\"\n        matches = self.extract_matches()\n\n        if not matches:\n            message = Message(text=\"No matches found\")\n            self.status = message\n            return message\n\n        if \"error\" in matches[0].data:\n            message = Message(text=matches[0].data[\"error\"])\n            self.status = message\n            return message\n\n        result = \"\\n\".join(match.data[\"match\"] for match in matches)\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "The text to analyze",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "pattern": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Regex Pattern",
                "dynamic": false,
                "info": "The regular expression pattern to match",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "(?s)content='(.*?\\})'"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "RegexExtractorComponent"
        },
        "dragging": false,
        "id": "RegexExtractorComponent-Wj6qw",
        "measured": {
          "height": 380,
          "width": 320
        },
        "position": {
          "x": 1843.0677835794124,
          "y": -403.2722016897017
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-q4F9z",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_text",
              "match_text",
              "operator",
              "case_sensitive",
              "message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "hidden": false,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "hidden": null,
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Case Sensitive",
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "case_sensitive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"regex\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n        ),\n        DataInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Data:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"false_result\")\n            return self.message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Data:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if not result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.message\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n\n            # Ensure case_sensitive is present for all other operators\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "corporativo_local"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "message": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": false,
                "info": "The message to pass through either route.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "load_from_db": false,
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "contains"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-q4F9z",
        "measured": {
          "height": 548,
          "width": 320
        },
        "position": {
          "x": 4501.348502127832,
          "y": -3481.527111770387
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-65zBN",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Combina os dados de um JSON com um texto ou lista de textos em um único JSON de saída.",
            "display_name": "Combine JSON + Message",
            "documentation": "",
            "edited": true,
            "field_order": [
              "json_data",
              "message",
              "data_list"
            ],
            "frozen": false,
            "icon": "plus-square",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Combined JSON",
                "hidden": false,
                "method": "combine",
                "name": "combined_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\r\nfrom langflow.io import DataInput, MessageInput, Output\r\nfrom langflow.schema import Data, Message\r\n\r\n\r\nclass CombineJSONComponent(Component):\r\n    display_name = \"Combine JSON + Message\"\r\n    description = \"Combina os dados de um JSON com um texto ou lista de textos em um único JSON de saída.\"\r\n    icon = \"plus-square\"\r\n    name = \"CombineJSON\"\r\n    legacy = True\r\n\r\n    inputs = [\r\n        DataInput(\r\n            name=\"json_data\",\r\n            display_name=\"JSON Data\",\r\n            info=\"Dados JSON originais do componente Load JSON.\",\r\n            is_list=False,\r\n            required=True,\r\n        ),\r\n        MessageInput(\r\n            name=\"message\",\r\n            display_name=\"Message\",\r\n            info=\"Mensagem formatada a ser incorporada no JSON.\",\r\n            required=False,\r\n        ),\r\n        DataInput(\r\n            name=\"data_list\",\r\n            display_name=\"Data List\",\r\n            info=\"Lista de Data formatada a ser incorporada no JSON.\",\r\n            is_list=True,\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            name=\"combined_data\",\r\n            display_name=\"Combined JSON\",\r\n            method=\"combine\",\r\n            info=\"JSON unificado contendo dados originais + mensagem/lista.\",\r\n        )\r\n    ]\r\n\r\n    def combine(self) -> Data:\r\n        combined = self.json_data.data.copy()\r\n\r\n        if self.message:\r\n            combined[\"message_text\"] = self.message.text\r\n\r\n        if self.data_list:\r\n            combined[\"message_list\"] = [d.text for d in self.data_list if hasattr(d, \"text\") and d.text]\r\n\r\n        self.status = combined\r\n        return Data(data=combined)\r\n"
              },
              "data_list": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data List",
                "dynamic": false,
                "info": "Lista de Data formatada a ser incorporada no JSON.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data_list",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "json_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "JSON Data",
                "dynamic": false,
                "info": "Dados JSON originais do componente Load JSON.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "json_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": false,
                "info": "Mensagem formatada a ser incorporada no JSON.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CombineJSON"
        },
        "dragging": false,
        "id": "CustomComponent-65zBN",
        "measured": {
          "height": 337,
          "width": 320
        },
        "position": {
          "x": 2671.2663018749354,
          "y": -377.2303132196854
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseJSONData-MxMyx",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParseJSONData",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.06663667857965161,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom json import JSONDecodeError\n\nimport jq\nfrom json_repair import repair_json\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.inputs import HandleInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseJSONDataComponent(Component):\n    display_name = \"Parse JSON\"\n    description = \"Convert and extract JSON fields.\"\n    icon = \"braces\"\n    name = \"ParseJSONData\"\n    legacy: bool = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"Data object to filter.\",\n            required=True,\n            input_types=[\"Message\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"JQ Query\",\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def _parse_data(self, input_value) -> str:\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\n            return input_value.text\n        if isinstance(input_value, Data):\n            return json.dumps(input_value.data)\n        return str(input_value)\n\n    def filter_data(self) -> list[Data]:\n        to_filter = self.input_value\n        if not to_filter:\n            return []\n        # Check if input is a list\n        if isinstance(to_filter, list):\n            to_filter = [self._parse_data(f) for f in to_filter]\n        else:\n            to_filter = self._parse_data(to_filter)\n\n        # If input is not a list, don't wrap it in a list\n        if not isinstance(to_filter, list):\n            to_filter = repair_json(to_filter)\n            try:\n                to_filter_as_dict = json.loads(to_filter)\n            except JSONDecodeError:\n                try:\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\n                except JSONDecodeError as e:\n                    msg = f\"Invalid JSON: {e}\"\n                    raise ValueError(msg) from e\n        else:\n            to_filter = [repair_json(f) for f in to_filter]\n            to_filter_as_dict = []\n            for f in to_filter:\n                try:\n                    to_filter_as_dict.append(json.loads(f))\n                except JSONDecodeError:\n                    try:\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\n                    except JSONDecodeError as e:\n                        msg = f\"Invalid JSON: {e}\"\n                        raise ValueError(msg) from e\n            to_filter = to_filter_as_dict\n\n        full_filter_str = json.dumps(to_filter_as_dict)\n\n        logger.info(\"to_filter: \", to_filter)\n\n        results = jq.compile(self.query).input_text(full_filter_str).all()\n        logger.info(\"results: \", results)\n        return [Data(data=value) if isinstance(value, dict) else Data(text=str(value)) for value in results]\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ Query to filter the data. The input is always a JSON list.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".classificador_pergunta"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "ParseJSONData-MxMyx",
        "measured": {
          "height": 273,
          "width": 320
        },
        "position": {
          "x": 3080.09612875902,
          "y": -336.8323152627608
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseData-YKrQX",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "key": "ParseData",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "dragging": false,
        "id": "ParseData-YKrQX",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 3491.3461136561677,
          "y": -341.83231507913956
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseJSONData-Kuu6E",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom json import JSONDecodeError\n\nimport jq\nfrom json_repair import repair_json\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.inputs import HandleInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseJSONDataComponent(Component):\n    display_name = \"Parse JSON\"\n    description = \"Convert and extract JSON fields.\"\n    icon = \"braces\"\n    name = \"ParseJSONData\"\n    legacy: bool = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"Data object to filter.\",\n            required=True,\n            input_types=[\"Message\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"JQ Query\",\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def _parse_data(self, input_value) -> str:\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\n            return input_value.text\n        if isinstance(input_value, Data):\n            return json.dumps(input_value.data)\n        return str(input_value)\n\n    def filter_data(self) -> list[Data]:\n        to_filter = self.input_value\n        if not to_filter:\n            return []\n        # Check if input is a list\n        if isinstance(to_filter, list):\n            to_filter = [self._parse_data(f) for f in to_filter]\n        else:\n            to_filter = self._parse_data(to_filter)\n\n        # If input is not a list, don't wrap it in a list\n        if not isinstance(to_filter, list):\n            to_filter = repair_json(to_filter)\n            try:\n                to_filter_as_dict = json.loads(to_filter)\n            except JSONDecodeError:\n                try:\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\n                except JSONDecodeError as e:\n                    msg = f\"Invalid JSON: {e}\"\n                    raise ValueError(msg) from e\n        else:\n            to_filter = [repair_json(f) for f in to_filter]\n            to_filter_as_dict = []\n            for f in to_filter:\n                try:\n                    to_filter_as_dict.append(json.loads(f))\n                except JSONDecodeError:\n                    try:\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\n                    except JSONDecodeError as e:\n                        msg = f\"Invalid JSON: {e}\"\n                        raise ValueError(msg) from e\n            to_filter = to_filter_as_dict\n\n        full_filter_str = json.dumps(to_filter_as_dict)\n\n        logger.info(\"to_filter: \", to_filter)\n\n        results = jq.compile(self.query).input_text(full_filter_str).all()\n        logger.info(\"results: \", results)\n        return [Data(data=value) if isinstance(value, dict) else Data(text=str(value)) for value in results]\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ Query to filter the data. The input is always a JSON list.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".message"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "ParseJSONData-Kuu6E",
        "measured": {
          "height": 273,
          "width": 320
        },
        "position": {
          "x": 5333.060183545783,
          "y": -3502.311294241903
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseJSONData-dT6Xk",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom json import JSONDecodeError\n\nimport jq\nfrom json_repair import repair_json\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.inputs import HandleInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseJSONDataComponent(Component):\n    display_name = \"Parse JSON\"\n    description = \"Convert and extract JSON fields.\"\n    icon = \"braces\"\n    name = \"ParseJSONData\"\n    legacy: bool = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"Data object to filter.\",\n            required=True,\n            input_types=[\"Message\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"JQ Query\",\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def _parse_data(self, input_value) -> str:\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\n            return input_value.text\n        if isinstance(input_value, Data):\n            return json.dumps(input_value.data)\n        return str(input_value)\n\n    def filter_data(self) -> list[Data]:\n        to_filter = self.input_value\n        if not to_filter:\n            return []\n        # Check if input is a list\n        if isinstance(to_filter, list):\n            to_filter = [self._parse_data(f) for f in to_filter]\n        else:\n            to_filter = self._parse_data(to_filter)\n\n        # If input is not a list, don't wrap it in a list\n        if not isinstance(to_filter, list):\n            to_filter = repair_json(to_filter)\n            try:\n                to_filter_as_dict = json.loads(to_filter)\n            except JSONDecodeError:\n                try:\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\n                except JSONDecodeError as e:\n                    msg = f\"Invalid JSON: {e}\"\n                    raise ValueError(msg) from e\n        else:\n            to_filter = [repair_json(f) for f in to_filter]\n            to_filter_as_dict = []\n            for f in to_filter:\n                try:\n                    to_filter_as_dict.append(json.loads(f))\n                except JSONDecodeError:\n                    try:\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\n                    except JSONDecodeError as e:\n                        msg = f\"Invalid JSON: {e}\"\n                        raise ValueError(msg) from e\n            to_filter = to_filter_as_dict\n\n        full_filter_str = json.dumps(to_filter_as_dict)\n\n        logger.info(\"to_filter: \", to_filter)\n\n        results = jq.compile(self.query).input_text(full_filter_str).all()\n        logger.info(\"results: \", results)\n        return [Data(data=value) if isinstance(value, dict) else Data(text=str(value)) for value in results]\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ Query to filter the data. The input is always a JSON list.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".message_text"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "ParseJSONData-dT6Xk",
        "measured": {
          "height": 273,
          "width": 320
        },
        "position": {
          "x": 5319.487743935854,
          "y": -3171.5975264413046
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseData-flHTD",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "dragging": false,
        "id": "ParseData-flHTD",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 5770.923763237906,
          "y": -2959.0530125680143
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseData-UgBdh",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "dragging": false,
        "id": "ParseData-UgBdh",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 5795.946316529544,
          "y": -3628.7830886597685
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-H8pi8",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Busca em Atlas Search utilizando 'search_instruction' JSON, com filtros de governança por setor e status.",
            "display_name": "Mongo Atlas Search Avançado (com search_instruction, setor e status)",
            "documentation": "",
            "edited": true,
            "field_order": [
              "mongodb_uri",
              "db_name",
              "collection_name",
              "index_name",
              "search_instruction_data",
              "user_sector",
              "doc_status",
              "min_score_fallback",
              "limit_fallback"
            ],
            "frozen": false,
            "icon": "MongoDB",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "hidden": false,
                "method": "search_documents",
                "name": "results",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\r\nimport re\r\nfrom typing import List, Union, Dict, Any\r\n\r\nfrom pymongo import MongoClient\r\nfrom langflow.custom import Component\r\nfrom langflow.inputs import (\r\n    SecretStrInput,\r\n    StrInput,\r\n    IntInput,\r\n    MultilineInput,\r\n    HandleInput,\r\n    DataInput,\r\n)\r\nfrom langflow.schema import Data, Message\r\nfrom langflow.template import Output\r\n\r\n\r\nclass MongoAtlasSearchWithFilters(Component):\r\n    display_name = \"Mongo Atlas Search Avançado (com search_instruction, setor e status)\"\r\n    icon = \"MongoDB\"\r\n    description = \"Busca em Atlas Search utilizando 'search_instruction' JSON, com filtros de governança por setor e status.\"\r\n\r\n    inputs = [\r\n        SecretStrInput(\r\n            name=\"mongodb_uri\",\r\n            display_name=\"MongoDB URI\",\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"db_name\",\r\n            display_name=\"Database\",\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"collection_name\",\r\n            display_name=\"Collection\",\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"index_name\",\r\n            display_name=\"Atlas Index Name\",\r\n            value=\"default_knowledge_context\",\r\n            required=True,\r\n        ),\r\n        DataInput(\r\n            name=\"search_instruction_data\",\r\n            display_name=\"Search Instruction (Data Object)\",\r\n            info=\"Objeto Data contendo o JSON/dicionário com as instruções de busca.\",\r\n            input_types=[\"Data\"],\r\n            required=True,\r\n        ),\r\n        MultilineInput(\r\n            name=\"user_sector\",\r\n            display_name=\"Filtro de Setor do Usuário (Obrigatório)\",\r\n            value='[]',\r\n            info='Array JSON de setores permitidos. Ex.: [\"Risco\"]. Garante governança.',\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"doc_status\",\r\n            display_name=\"Filtro de Status do Documento\",\r\n            value='ativo',\r\n            info='Status do documento para filtrar (ex: \"ativo\", \"revisão\"). Deixe vazio para não filtrar por status.',\r\n            required=False,\r\n        ),\r\n        MultilineInput(\r\n            name=\"min_score_fallback\",\r\n            display_name=\"Score Mínimo (Fallback)\",\r\n            value=\"0.0\",\r\n            info=\"Score mínimo. Usado se não especificado em search_instruction.\",\r\n            required=False,\r\n        ),\r\n        IntInput(\r\n            name=\"limit_fallback\",\r\n            display_name=\"Result Limit (Fallback)\",\r\n            value=20,\r\n            info=\"Limite de resultados. Usado se não especificado em search_instruction.\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            name=\"results\",\r\n            display_name=\"Search Results\",\r\n            method=\"search_documents\",\r\n        ),\r\n    ]\r\n\r\n    def _parse_user_sector(self) -> List[str]:\r\n        \"\"\"Parse the user_sector input into a list of strings.\"\"\"\r\n        sectors = []\r\n        raw_sectors = self.user_sector\r\n        if isinstance(raw_sectors, str) and raw_sectors.strip():\r\n            try:\r\n                parsed_sectors = json.loads(raw_sectors)\r\n                if isinstance(parsed_sectors, list):\r\n                    sectors = [str(s).strip() for s in parsed_sectors if str(s).strip()]\r\n                elif isinstance(parsed_sectors, str) and parsed_sectors.strip():\r\n                    sectors = [parsed_sectors.strip()]\r\n            except json.JSONDecodeError:\r\n                sectors = [s.strip() for s in raw_sectors.split(',') if s.strip()]\r\n        elif isinstance(raw_sectors, list):\r\n            sectors = [str(s).strip() for s in raw_sectors if str(s).strip()]\r\n        \r\n        return sectors\r\n\r\n    def _parse_search_instruction_from_data(self) -> Dict[str, Any]:\r\n        \"\"\"Parse and validate the search_instruction from Data object.\"\"\"\r\n        raw_instruction = self.search_instruction_data\r\n\r\n        if not raw_instruction or not hasattr(raw_instruction, 'data'):\r\n            self.status = \"Search instruction Data object não recebido ou inválido.\"\r\n            return {}\r\n        \r\n        instruction_payload = raw_instruction.data\r\n\r\n        if isinstance(instruction_payload, dict):\r\n            return instruction_payload\r\n        elif isinstance(instruction_payload, str):\r\n            try:\r\n                loaded_instruction = json.loads(instruction_payload)\r\n                if isinstance(loaded_instruction, dict):\r\n                    return loaded_instruction\r\n                else:\r\n                    self.status = \"Search instruction (string JSON) não resultou em um dicionário.\"\r\n                    return {}\r\n            except json.JSONDecodeError as e:\r\n                self.status = f\"Falha ao decodificar string JSON da search_instruction: {e}\"\r\n                return {}\r\n        else:\r\n            self.status = f\"Conteúdo da search_instruction (Data.data) não é dict nem string JSON. Tipo: {type(instruction_payload)}\"\r\n            return {}\r\n\r\n    def _build_search_pipeline(self, instruction: Dict[str, Any], user_allowed_sectors: List[str], doc_status_filter: str) -> List[Dict[str, Any]]:\r\n        \"\"\"Builds the MongoDB aggregation pipeline with search_instruction, sector, and status filters.\"\"\"\r\n        pipeline: List[Dict[str, Any]] = []\r\n        \r\n        if \"search_clause\" not in instruction or not isinstance(instruction[\"search_clause\"], dict):\r\n            self.status = \"Erro: 'search_clause' não fornecida ou inválida.\"\r\n            raise ValueError(\"A 'search_clause' é obrigatória na search_instruction.\")\r\n\r\n        search_stage = {\r\n            \"$search\": {\r\n                \"index\": self.index_name,\r\n                **instruction[\"search_clause\"]\r\n            }\r\n        }\r\n        pipeline.append(search_stage)\r\n\r\n        pipeline.append({\r\n            \"$set\": {\r\n                \"search_score\": {\"$meta\": \"searchScore\"}\r\n            }\r\n        })\r\n\r\n        min_score_val = instruction.get(\"min_score\", self.min_score_fallback)\r\n        min_score = 0.0\r\n        if isinstance(min_score_val, (float, int)):\r\n            min_score = float(min_score_val)\r\n        elif isinstance(min_score_val, str):\r\n            try:\r\n                min_score = float(min_score_val.strip())\r\n            except ValueError:\r\n                self.status += \" Alerta: min_score inválido, usando 0.0.\"\r\n        \r\n        if min_score > 0:\r\n            pipeline.append({\"$match\": {\"search_score\": {\"$gte\": min_score}}})\r\n        \r\n        if user_allowed_sectors:\r\n            pipeline.append({\"$match\": {\"setores\": {\"$in\": user_allowed_sectors}}})\r\n\r\n        if doc_status_filter:\r\n            pipeline.append({\"$match\": {\"status\": doc_status_filter}})\r\n\r\n        if \"filter_stages\" in instruction and isinstance(instruction[\"filter_stages\"], list):\r\n            for match_filter in instruction[\"filter_stages\"]:\r\n                if isinstance(match_filter, dict) and match_filter: \r\n                    pipeline.append({\"$match\": match_filter})\r\n        \r\n        sort_stage_val = instruction.get(\"sort_stage\")\r\n        if isinstance(sort_stage_val, dict) and sort_stage_val:\r\n            pipeline.append({\"$sort\": sort_stage_val})\r\n        else: \r\n            pipeline.append({\"$sort\": {\"search_score\": -1}})\r\n\r\n        limit_val = instruction.get(\"limit\", self.limit_fallback)\r\n        limit = 0\r\n        if isinstance(limit_val, int) and limit_val > 0:\r\n            limit = limit_val\r\n        elif isinstance(limit_val, str):\r\n            try:\r\n                limit = int(limit_val.strip())\r\n            except ValueError:\r\n                self.status += f\" Alerta: limit inválido, usando fallback {self.limit_fallback} se positivo.\"\r\n                if self.limit_fallback > 0: limit = self.limit_fallback\r\n        \r\n        if limit > 0 :\r\n            pipeline.append({\"$limit\": limit})\r\n\r\n        projection = instruction.get(\"projection_stage\", {\r\n            \"_id\": 1, \"score\": \"$search_score\", \"text\": 1, \"resumo\": 1, \"descricao\": 1,\r\n            \"setores\": 1, \"status\": 1, \"classificacao\": 1, \"tipo\": 1, \"atualizado_em\": 1,\r\n            \"participantes_internos\": 1, \"participantes_externos\": 1, \"id_reuniao\": 1\r\n        })\r\n        if isinstance(projection, dict) and projection:\r\n            pipeline.append({\"$project\": projection})\r\n\r\n        return pipeline\r\n\r\n    def search_documents(self) -> Data:\r\n        parsed_instruction = self._parse_search_instruction_from_data()\r\n        if not parsed_instruction: \r\n            return Data(data={\"results\": [], \"error\": self.status or \"Invalid search_instruction Data object.\"})\r\n\r\n        user_sectors = self._parse_user_sector()\r\n        doc_status_to_filter = self.doc_status.strip() if self.doc_status else \"\"\r\n\r\n        try:\r\n            pipeline = self._build_search_pipeline(parsed_instruction, user_sectors, doc_status_to_filter)\r\n        except ValueError as e: \r\n             self.status = str(e)\r\n             return Data(data={\"results\": [], \"error\": str(e)})\r\n\r\n        if not pipeline: \r\n            self.status = \"Pipeline de busca não pôde ser construída.\"\r\n            return Data(data={\"results\": [], \"error\": self.status})\r\n        \r\n        collection = MongoClient(self.mongodb_uri)[self.db_name][self.collection_name]\r\n\r\n        try:\r\n            results = list(collection.aggregate(pipeline))\r\n            for doc in results:\r\n                doc[\"_id\"] = str(doc[\"_id\"])\r\n                if \"score\" in doc and doc[\"score\"] is not None:\r\n                    try:\r\n                        doc[\"score\"] = float(doc[\"score\"])\r\n                    except (ValueError, TypeError):\r\n                        doc[\"score\"] = 0.0 \r\n                else:\r\n                    doc[\"score\"] = 0.0\r\n            \r\n            self.status = f\"Encontrados {len(results)} resultado(s).\"\r\n            return Data(data={\"results\": results, \"pipeline_used\": pipeline})\r\n        except Exception as e:\r\n            self.status = f\"Erro na busca: {str(e)}\"\r\n            return Data(data={\"results\": [], \"error\": str(e), \"pipeline_attempted\": pipeline})"
              },
              "collection_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Collection",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "collection_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "knowledge_context"
              },
              "db_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Database",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "db_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "DeepContext"
              },
              "doc_status": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Filtro de Status do Documento",
                "dynamic": false,
                "info": "Status do documento para filtrar (ex: \"ativo\", \"revisão\"). Deixe vazio para não filtrar por status.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "doc_status",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "ativo"
              },
              "index_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Atlas Index Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "index_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "default_knowledge_context"
              },
              "limit_fallback": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Result Limit (Fallback)",
                "dynamic": false,
                "info": "Limite de resultados. Usado se não especificado em search_instruction.",
                "list": false,
                "list_add_label": "Add More",
                "name": "limit_fallback",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "min_score_fallback": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Score Mínimo (Fallback)",
                "dynamic": false,
                "info": "Score mínimo. Usado se não especificado em search_instruction.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "min_score_fallback",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "0.0"
              },
              "mongodb_uri": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "MongoDB URI",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "mongodb_uri",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "search_instruction_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Search Instruction (Data Object)",
                "dynamic": false,
                "info": "Objeto Data contendo o JSON/dicionário com as instruções de busca.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "search_instruction_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "user_sector": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Filtro de Setor do Usuário (Obrigatório)",
                "dynamic": false,
                "info": "Array JSON de setores permitidos. Ex.: [\"Risco\"]. Garante governança.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "user_sector",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "[]"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "MongoAtlasSearchWithFilters"
        },
        "dragging": false,
        "id": "CustomComponent-H8pi8",
        "measured": {
          "height": 888,
          "width": 320
        },
        "position": {
          "x": 7053.636763733473,
          "y": -4573.001936769494
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Pass-QARhb",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Forwards the input message, unchanged.",
            "display_name": "Pass",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_message",
              "ignored_message"
            ],
            "frozen": false,
            "icon": "arrow-right",
            "key": "Pass",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "hidden": false,
                "method": "pass_message",
                "name": "output_message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 2.220446049250313e-16,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageInput\nfrom langflow.schema.message import Message\nfrom langflow.template import Output\n\n\nclass PassMessageComponent(Component):\n    display_name = \"Pass\"\n    description = \"Forwards the input message, unchanged.\"\n    name = \"Pass\"\n    icon = \"arrow-right\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_message\",\n            display_name=\"Input Message\",\n            info=\"The message to be passed forward.\",\n            required=True,\n        ),\n        MessageInput(\n            name=\"ignored_message\",\n            display_name=\"Ignored Message\",\n            info=\"A second message to be ignored. Used as a workaround for continuity.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output Message\", name=\"output_message\", method=\"pass_message\"),\n    ]\n\n    def pass_message(self) -> Message:\n        self.status = self.input_message\n        return self.input_message\n"
              },
              "ignored_message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Ignored Message",
                "dynamic": false,
                "info": "A second message to be ignored. Used as a workaround for continuity.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "ignored_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input_message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input Message",
                "dynamic": false,
                "info": "The message to be passed forward.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_message",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Estrutura de um documento da coleção: knowledge_context (Banco de Dados: DeepContext)  - _id: ObjectId (Identificador único do MongoDB) - text: String (Trecho de texto, possivelmente parte de uma transcrição) - embedding: Array (Vetor de embedding, ex: 1536 dimensões, suprimido na visualização do script) - arquivo: String (URL do arquivo original) - classificacao: String (Categoria do documento, ex: \"reunião\", documento, ação, meta, objetivo estratégico...) - criado_em: ISODate (Data e hora de criação) - atualizado_em: ISODate (Data e hora de atualização) - gestor: Array de Strings (Nome do gestor ou gestores relacionados, ex: [\"Real Investors\"]) - id_entidades_participantes: Array de Strings (IDs de outras entidades/documentos relacionados) - id_reuniao: String (Identificador da reunião) - participantes_externos: Array de Strings (Nomes de participantes externos da reunião) - participantes_internos: Array de Strings (Nomes de participantes internos da reunião) - setores: Array de Strings (Setores relacionados, ex: [\"Risco\"]) - status: String (Status do documento, ex: \"ativo\") - tipo: String (Tipo de documento, ex: \"Fundos de investimentos\") - total_caracteres_documento: String (Contagem de caracteres do documento original) - id: String (Outro ID para o documento, possivelmente de origem)   Index: default_knowledge_context  ```json {   \"mappings\": {     \"dynamic\": false,     \"fields\": {       \"atualizado_em\": {         \"type\": \"date\"       },       \"classificacao\": {         \"type\": \"token\"       },             \"gestor\": {         \"type\": \"stringFacet\"       },       \"id_reuniao\": {         \"type\": \"token\"       },       \"participantes_externos\": {         \"type\": \"stringFacet\"       },       \"participantes_internos\": {         \"type\": \"stringFacet\"       },            \"setores\": {         \"type\": \"stringFacet\"       }       \"text\": {         \"analyzer\": \"lucene.portuguese\",         \"type\": \"string\"       },       \"tipo\": {         \"type\": \"token\"       }     }   } }"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Pass"
        },
        "dragging": false,
        "id": "Pass-QARhb",
        "measured": {
          "height": 229,
          "width": 320
        },
        "position": {
          "x": -29.654450069661664,
          "y": 15.680276911993957
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-eqGYB",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Converte uma string JSON com escapes literais (ex: \\n, \\\") para um objeto Data, preservando UTF-8.",
            "display_name": "Processar String JSON Escapada (Seguro)",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_message"
            ],
            "frozen": false,
            "icon": "JSON",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Saída de Dados (Data)",
                "hidden": false,
                "method": "process_string_to_data",
                "name": "data_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nimport ast # Importar ast\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\n\nclass ProcessEscapedJsonStringComponent(Component):\n    display_name = \"Processar String JSON Escapada (Seguro)\"\n    description = \"Converte uma string JSON com escapes literais (ex: \\\\n, \\\\\\\") para um objeto Data, preservando UTF-8.\"\n    icon = \"JSON\"\n    name = \"ProcessEscapedJsonSafe\" # Nome ligeiramente diferente para evitar conflitos se o antigo ainda estiver cacheado\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_message\",\n            display_name=\"Mensagem de Entrada com String JSON\",\n            info=\"String JSON com escapes literais (ex: de AIMessage.content via Regex Extractor).\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"data_output\", display_name=\"Saída de Dados (Data)\", method=\"process_string_to_data\"),\n    ]\n\n    def process_string_to_data(self) -> Data | list[Data]:\n        raw_json_string = self.input_message\n        \n        if not raw_json_string:\n            self.status = \"String JSON de entrada está vazia.\"\n            raise ValueError(\"String JSON de entrada está vazia.\")\n\n        # print(f\"DEBUG: String JSON recebida: >>>{raw_json_string}<<<\")\n        \n        processed_string = raw_json_string\n\n        try:\n            # A string raw_json_string é algo como: \"{\\\\n  \\\\\"key\\\\\": \\\\\"vÃ¡lue\\\\\", \\\\n ...}\"\n            # Onde \\\\n e \\\\\" são literais.\n            # ast.literal_eval pode decodificar isso para uma string Python normal\n            # se a string inteira for um literal de string Python válido.\n            # Para fazer isso, precisamos garantir que ela seja tratada como tal.\n            # Se a string já tem aspas corretas para ser um literal, não precisamos adicionar mais.\n            # No seu caso, a string é o *conteúdo* do JSON.\n\n            # Tentativa com ast.literal_eval, assumindo que a string é \"nua\"\n            # e precisa ser tratada como o conteúdo de uma string Python.\n            # Ex: se raw_json_string = \"{\\\\n \\\\\"foo\\\\\": \\\\\"bar\\\\\"}\",\n            # queremos que ast.literal_eval interprete isso.\n            # Para isso, a string que passamos para ast.literal_eval precisa ser\n            # uma representação de string: por exemplo, f\"'{raw_json_string}'\" faria\n            # raw_json_string o conteúdo de uma string Python delimitada por aspas simples.\n            #\n            # Se raw_json_string é:       \"{\\\\n  \\\\\"message\\\\\": \\\\\"Ol\\\\u00e1 mundo\\\\\"\\\\n}\"\n            # ast.literal_eval neste caso espera a string literal, não ela mesma.\n            #\n            # A string que você tem do RegexExtractor JÁ É uma string Python.\n            # Ela contém sequências literais '\\\\' e 'n'.\n            # Precisamos de um JSON onde esses se tornem caracteres REAIS de nova linha\n            # para formatação, e aspas REAIS. Mas os acentos devem ser preservados.\n\n            # O problema do `bytes(...).decode('unicode-escape')` era que ele também mexia\n            # com os acentos.\n            #\n            # Se a estrutura está OK com o código anterior (que usava unicode-escape),\n            # mas só os acentos estão errados, o `unicode-escape` está corrompendo o UTF-8.\n\n            # Vamos tentar uma abordagem de substituição controlada, focada\n            # nos escapes problemáticos, e esperando que o resto (UTF-8) passe intacto.\n            # Esta é a abordagem que falhou com \"Invalid control character\" porque\n            # transformou \\\\n em \\n literal dentro de strings JSON.\n\n            # A questão é: a string que você tem do RegexExtractor,\n            # `{\\n  \"message\": \"Quais foram as aÃ§Ãµes...\"}`\n            # já está com os acentos CORROMPIDOS ANTES de chegar neste componente?\n            # Se sim, este componente não pode consertar.\n            # Se os acentos estão CORRETOS na string que este componente recebe,\n            # e o `bytes.decode('unicode-escape')` os corrompe, então precisamos de outra\n            # forma de lidar com os \\\\n e \\\\\" literais.\n\n            # Revisitando: A string que o RegexExtractor produz (seu último log de erro do JSONToData)\n            # era: \"{\\\\n  \\\\\"message\\\\\": \\\\\"Quais foram as ações discutidas na última reunião?\\\\\", ... }\"\n            # Aqui, \"ações\" e \"reunião\" estão CORRETOS.\n            # O problema de \"aÃ§Ãµes\" surgiu DEPOIS do `bytes.decode('unicode-escape')`.\n\n            # Então, precisamos de um método que converta \\\\n para \\n e \\\\\" para \"\n            # SEM usar unicode-escape.\n            \n            temp_str = raw_json_string.replace('\\\\\"', '\"')\n            temp_str = temp_str.replace('\\\\n', '\\n') \n            # Cuidado: se você tiver \\\\\\\\n (querendo um \\n literal DENTRO de uma string JSON),\n            # a ordem dos replaces importa. Primeiro \\\\\\\\ para \\\\, depois \\\\n para \\n.\n            # Mas para o seu caso:\n            # raw_json_string = \"{\\\\n  \\\"key\\\": \\\"value\\\\\\\\nline2\\\" \\\\n}\"\n            # .replace('\\\\\"', '\"') -> \"{\\n  \"key\": \"value\\\\\\\\nline2\" \\n}\" (JSON inválido)\n            # .replace('\\\\n', '\\n') -> quebra.\n\n            # Acredito que `ast.literal_eval` é a ferramenta correta se a string\n            # de entrada é uma representação de string Python válida.\n            # `raw_json_string` do seu RegexExtractor é uma string Python.\n            # `ast.literal_eval` de uma string que contém `\\\\n` e `\\\\\"`\n            # irá produzir uma nova string com `\\n` (nova linha real) e `\"` (aspa real).\n            # Isso deve preservar os caracteres UTF-8 corretamente.\n            \n            # Vamos tentar ast.literal_eval, mas precisamos garantir que a string\n            # que ele recebe é uma representação de uma ÚNICA string Python.\n            # Como raw_json_string já é a string desejada, apenas precisamos\n            # garantir que ela não tem lixo no início/fim.\n            # O resultado de ast.literal_eval(SOME_PYTHON_STRING_REPR) é o objeto Python.\n            # Se SOME_PYTHON_STRING_REPR é \"'abc'\", o resultado é \"abc\".\n            # Se SOME_PYTHON_STRING_REPR é \"'{\\\\\\\"key\\\\\\\": \\\\\\\"value\\\\\"}'\", o resultado é \"{\\\"key\\\": \\\"value\\\"}\".\n            # Esta string resultante \"{\\\"key\\\": \\\"value\\\"}\" é o que o json.loads espera.\n\n            # No seu caso, raw_json_string já é a string que queremos que o json.loads processe,\n            # mas ela tem os \\\\n e \\\\\" literais.\n\n            # O que o `json_repair` faz? Ele provavelmente é a melhor aposta.\n            # Se o json_repair com a string original (com acentos corretos)\n            # produz o erro \"Expecting property name enclosed in double quotes\",\n            # então o json_repair não está conseguindo converter os \\\\n e \\\\\" literais\n            # de uma forma que o json.loads subsequente aceite.\n\n            # Vamos testar a hipótese: O `ProcessEscapedJsonString.py` que você disse que\n            # \"já está perfeito\" na estrutura (o da sua penúltima mensagem, que usa unicode-escape)\n            # produz o JSON com a estrutura correta, mas com encoding quebrado.\n\n            # Se usarmos `ast.literal_eval` na `raw_json_string` (que tem acentos corretos),\n            # o resultado será uma string com os `\\\\n` convertidos para `\\n` reais\n            # e `\\\\\"` para `\"` reais, e os acentos preservados.\n            # Ex: `s = \"{\\\\n  \\\\\"palavra\\\\\": \\\\\"a\\\\u00e7\\\\u00e3o\\\\\"\\\\n}\"` (representação de string Python)\n            #    `eval_s = ast.literal_eval(\"u'''\" + s + \"'''\")` # Força unicode e trata como string\n            #    `eval_s` será `{\\n  \"palavra\": \"ação\"\\n}` (string Python com chars reais)\n            # E `json.loads(eval_s)` deve funcionar.\n\n            # Tentativa com ast.literal_eval de forma mais robusta\n            # A string de entrada já é uma string Python, não uma representação de string.\n            # Precisamos que ast.literal_eval interprete os escapes *dentro* dela.\n            # Para isso, a string tem que ser *ela mesma* um literal string que ast.literal_eval processa.\n            \n            # A forma mais segura de converter \"Python string escapes\" para \"real characters\"\n            # sem corromper UTF-8 é, de fato, ast.literal_eval se a string for formatada como\n            # um literal de string Python.\n            # Sua `raw_json_string` é a string \"nua\".\n\n            # Se o `ProcessEscapedJsonString.py` anterior (o que você disse que \"já está perfeito\" na estrutura)\n            # funcionou para a estrutura, vamos usá-lo e focar SÓ no encoding DEPOIS.\n\n            # Código do componente que parseia a estrutura (mesmo que corrompa acentos temporariamente):\n            # Este é o código que você disse que funcionava para a ESTRUTURA.\n            processed_for_structure = bytes(raw_json_string, \"utf-8\").decode(\"unicode-escape\")\n            parsed_data_struct = json.loads(processed_for_structure)\n\n            # Agora, `parsed_data_struct` tem a estrutura correta, mas os acentos podem estar como \"aÃ§Ã£o\".\n            # Precisamos percorrer este dicionário/lista e corrigir o encoding das strings.\n\n            def fix_utf8_issues_in_obj(obj):\n                if isinstance(obj, dict):\n                    return {k: fix_utf8_issues_in_obj(v) for k, v in obj.items()}\n                elif isinstance(obj, list):\n                    return [fix_utf8_issues_in_obj(elem) for elem in obj]\n                elif isinstance(obj, str):\n                    try:\n                        # Tenta decodificar de Latin-1 (comum para \"mojibake\") e re-encodar para UTF-8\n                        # Isso assume que o \"aÃ§Ã£o\" é Latin-1 representando UTF-8.\n                        return obj.encode('latin-1').decode('utf-8')\n                    except UnicodeEncodeError: # Se já for UTF-8 ou algo que não pode ser latin-1\n                        return obj\n                    except UnicodeDecodeError: # Se não for Latin-1 válido\n                        return obj \n                else:\n                    return obj\n\n            parsed_data = fix_utf8_issues_in_obj(parsed_data_struct)\n            # print(f\"DEBUG: Dados após correção de UTF-8: {parsed_data}\")\n\n            if isinstance(parsed_data, list):\n                result = [Data(data=item) for item in parsed_data]\n            else:\n                result = Data(data=parsed_data)\n            \n            self.status = \"JSON processado e encoding corrigido (tentativa).\"\n            return result\n\n        except json.JSONDecodeError as e_json:\n            error_msg = f\"Erro ao decodificar JSON estrutural: {str(e_json)}. String após unicode-escape era: >>>{processed_for_structure if 'processed_for_structure' in locals() else 'N/A'}<<<\"\n            self.status = error_msg\n            raise ValueError(error_msg) from e_json\n        \n        except Exception as e_general: \n            error_msg = f\"Erro inesperado: {str(e_general)}. String original era: >>>{raw_json_string}<<<\"\n            self.status = error_msg\n            raise ValueError(error_msg) from e_general\n"
              },
              "input_message": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Mensagem de Entrada com String JSON",
                "dynamic": false,
                "info": "String JSON com escapes literais (ex: de AIMessage.content via Regex Extractor).",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_message",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ProcessEscapedJsonSafe"
        },
        "dragging": false,
        "id": "CustomComponent-eqGYB",
        "measured": {
          "height": 269,
          "width": 320
        },
        "position": {
          "x": 2278.4365431943047,
          "y": -302.093014914176
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-fDgbO",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extrai o dicionário 'search_instruction' de um objeto Data de entrada que contém o JSON completo do LLM.",
            "display_name": "Extrair Search Instruction",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_data_object"
            ],
            "frozen": false,
            "icon": "filter",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Instruction (Data)",
                "hidden": false,
                "method": "extract_instruction",
                "name": "search_instruction_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, Output\nfrom langflow.schema import Data # Certifique-se que Data está corretamente importado\n\nclass ExtractSearchInstructionComponent(Component):\n    display_name = \"Extrair Search Instruction\"\n    description = \"Extrai o dicionário 'search_instruction' de um objeto Data de entrada que contém o JSON completo do LLM.\"\n    icon = \"filter\" # Ícone sugerido, pode ser alterado\n    name = \"ExtractSearchInstruction\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data_object\", # Nome da entrada\n            display_name=\"Input Data Object\",\n            info=\"Objeto Data contendo o JSON completo do LLM (espera-se que input_data_object.data seja um dict).\",\n            input_types=[\"Data\"], # Aceita objetos do tipo Data\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"search_instruction_output\", display_name=\"Search Instruction (Data)\", method=\"extract_instruction\"),\n    ]\n\n    def extract_instruction(self) -> Data:\n        input_data = self.input_data_object # Usar o nome da entrada definido nos inputs\n\n        if not input_data or not isinstance(input_data, Data):\n            self.status = \"Objeto Data de entrada não recebido ou inválido.\"\n            # É importante retornar um objeto Data para compatibilidade com o fluxo\n            return Data(data={\"error\": self.status, \"results\": []}) \n\n        if not isinstance(input_data.data, dict):\n            self.status = f\"O atributo 'data' do objeto Data de entrada não é um dicionário. Tipo recebido: {type(input_data.data)}\"\n            return Data(data={\"error\": self.status, \"results\": []})\n\n        llm_output_dict = input_data.data\n        \n        if \"search_instruction\" not in llm_output_dict:\n            self.status = \"Chave 'search_instruction' não encontrada no dicionário de entrada (Data.data).\"\n            return Data(data={\"error\": self.status, \"results\": []})\n            \n        search_instruction_payload = llm_output_dict[\"search_instruction\"]\n        \n        if not isinstance(search_instruction_payload, dict):\n            self.status = \"O valor de 'search_instruction' não é um dicionário.\"\n            return Data(data={\"error\": self.status, \"results\": []})\n\n        self.status = \"Search instruction extraída com sucesso.\"\n        # Retorna um novo objeto Data contendo apenas o dicionário da search_instruction\n        return Data(data=search_instruction_payload)\n"
              },
              "input_data_object": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input Data Object",
                "dynamic": false,
                "info": "Objeto Data contendo o JSON completo do LLM (espera-se que input_data_object.data seja um dict).",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data_object",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ExtractSearchInstruction"
        },
        "dragging": false,
        "id": "CustomComponent-fDgbO",
        "measured": {
          "height": 231,
          "width": 320
        },
        "position": {
          "x": 5799.251329524269,
          "y": -4124.1504939328115
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseJSONData-D4BeZ",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom json import JSONDecodeError\n\nimport jq\nfrom json_repair import repair_json\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.inputs import HandleInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseJSONDataComponent(Component):\n    display_name = \"Parse JSON\"\n    description = \"Convert and extract JSON fields.\"\n    icon = \"braces\"\n    name = \"ParseJSONData\"\n    legacy: bool = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"Data object to filter.\",\n            required=True,\n            input_types=[\"Message\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"JQ Query\",\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def _parse_data(self, input_value) -> str:\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\n            return input_value.text\n        if isinstance(input_value, Data):\n            return json.dumps(input_value.data)\n        return str(input_value)\n\n    def filter_data(self) -> list[Data]:\n        to_filter = self.input_value\n        if not to_filter:\n            return []\n        # Check if input is a list\n        if isinstance(to_filter, list):\n            to_filter = [self._parse_data(f) for f in to_filter]\n        else:\n            to_filter = self._parse_data(to_filter)\n\n        # If input is not a list, don't wrap it in a list\n        if not isinstance(to_filter, list):\n            to_filter = repair_json(to_filter)\n            try:\n                to_filter_as_dict = json.loads(to_filter)\n            except JSONDecodeError:\n                try:\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\n                except JSONDecodeError as e:\n                    msg = f\"Invalid JSON: {e}\"\n                    raise ValueError(msg) from e\n        else:\n            to_filter = [repair_json(f) for f in to_filter]\n            to_filter_as_dict = []\n            for f in to_filter:\n                try:\n                    to_filter_as_dict.append(json.loads(f))\n                except JSONDecodeError:\n                    try:\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\n                    except JSONDecodeError as e:\n                        msg = f\"Invalid JSON: {e}\"\n                        raise ValueError(msg) from e\n            to_filter = to_filter_as_dict\n\n        full_filter_str = json.dumps(to_filter_as_dict)\n\n        logger.info(\"to_filter: \", to_filter)\n\n        results = jq.compile(self.query).input_text(full_filter_str).all()\n        logger.info(\"results: \", results)\n        return [Data(data=value) if isinstance(value, dict) else Data(text=str(value)) for value in results]\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ Query to filter the data. The input is always a JSON list.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".temporal_constraints"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "ParseJSONData-D4BeZ",
        "measured": {
          "height": 273,
          "width": 320
        },
        "position": {
          "x": 5321.270117210555,
          "y": -2774.236668040892
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-IzLd7",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Aplica filtragem temporal em chunks do MongoDB usando um LLM para interpretar restrições.",
            "display_name": "Filtro Temporal Inteligente com LLM",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_chunks",
              "temporal_constraints",
              "current_date",
              "llm_model"
            ],
            "frozen": false,
            "icon": "clock-play",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chunks Filtrados pelo LLM",
                "hidden": false,
                "method": "filter_chunks_with_llm",
                "name": "filtered_chunks",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Saída de Debug",
                "hidden": null,
                "method": "get_debug_info",
                "name": "debug_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from datetime import datetime, timedelta\r\nfrom typing import List, Dict, Any, Optional\r\nimport json\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, StrInput, Output, MessageTextInput\r\nfrom langflow.schema import Data\r\nfrom langflow.schema.message import Message\r\nfrom langflow.field_typing import LanguageModel\r\n\r\nclass TemporalFilterComponent(Component):\r\n    display_name = \"Filtro Temporal Inteligente com LLM\"\r\n    description = \"Aplica filtragem temporal em chunks do MongoDB usando um LLM para interpretar restrições.\"\r\n    icon = \"clock-play\"\r\n    name = \"TemporalFilterLLM\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"input_chunks\",\r\n            display_name=\"Chunks de Entrada\",\r\n            info=\"Lista de chunks retornados pela busca lexical (Data object)\",\r\n            input_types=[\"Data\"],\r\n            required=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"temporal_constraints\",\r\n            display_name=\"Restrições Temporais (Prompt para LLM)\",\r\n            info=\"Texto descritivo das restrições temporais, usado como prompt para o LLM (Data object ou string)\",\r\n            input_types=[\"Data\", \"str\"],\r\n            required=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"current_date\",\r\n            display_name=\"Data Atual\",\r\n            info=\"Data atual no formato YYYY-MM-DD. Pode ser uma variável como {{current_date_component.current_date}}.\",\r\n            required=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"llm_model\",\r\n            display_name=\"Modelo LLM para Filtragem\",\r\n            info=\"LLM configurado para realizar a filtragem temporal baseada nas constraints.\",\r\n            input_types=[\"LanguageModel\"],\r\n            required=True,\r\n        )\r\n    ]\r\n\r\n    outputs = [\r\n        Output(name=\"filtered_chunks\", display_name=\"Chunks Filtrados pelo LLM\", method=\"filter_chunks_with_llm\"),\r\n        Output(name=\"debug_output\", display_name=\"Saída de Debug\", method=\"get_debug_info\"),\r\n    ]\r\n\r\n    def __init__(self, **data: Any):\r\n        super().__init__(**data)\r\n        self._debug_info: Dict[str, Any] = {}\r\n\r\n    def _parse_date_expression(self, expr: str, current_date: datetime) -> Optional[Dict[str, datetime]]:\r\n        \"\"\"Interpreta expressões temporais relativas.\"\"\"\r\n        try:\r\n            if \"semana passada\" in expr.lower():\r\n                end = current_date - timedelta(days=current_date.weekday())\r\n                start = end - timedelta(days=7)\r\n                return {\"start\": start, \"end\": end}\r\n            \r\n            if \"últimos 2 meses\" in expr.lower():\r\n                end = current_date\r\n                start = current_date - timedelta(days=60)\r\n                return {\"start\": start, \"end\": end}\r\n            \r\n            if \"última\" in expr.lower():\r\n                # Para \"última reunião\", \"última ata\", etc., retornamos None\r\n                # pois precisaremos ordenar por data e pegar o mais recente\r\n                return None\r\n            \r\n            # Adicionar mais padrões conforme necessário\r\n            return None\r\n            \r\n        except Exception as e:\r\n            self.status = f\"Erro ao interpretar expressão temporal: {str(e)}\"\r\n            return None\r\n\r\n    def _group_by_event_id(self, chunks: List[Dict]) -> Dict[str, List[Dict]]:\r\n        \"\"\"Agrupa chunks pelo ID do evento/documento.\"\"\"\r\n        grouped = {}\r\n        for chunk in chunks:\r\n            event_id = chunk.get('id_reuniao') or chunk.get('id')  # Tenta ambos os campos\r\n            if event_id:\r\n                if event_id not in grouped:\r\n                    grouped[event_id] = []\r\n                grouped[event_id].append(chunk)\r\n        return grouped\r\n\r\n    def _call_llm(self, llm: LanguageModel, prompt: str) -> str:\r\n        \"\"\"Chama o modelo LLM com o prompt fornecido.\"\"\"\r\n        # Tenta diferentes métodos de chamada comuns em componentes Langflow LLM\r\n        try:\r\n            if hasattr(llm, 'invoke') and callable(llm.invoke):\r\n                response = llm.invoke(prompt)\r\n            elif hasattr(llm, 'predict') and callable(llm.predict):\r\n                response = llm.predict(prompt)\r\n            elif callable(llm):\r\n                response = llm(prompt)\r\n            else:\r\n                raise ValueError(\"Modelo LLM não possui um método de chamada reconhecido (invoke, predict ou __call__).\")\r\n            \r\n            if hasattr(response, 'content'): # Comum em modelos de chat (ex: AIMessage)\r\n                return str(response.content)\r\n            return str(response)\r\n            \r\n        except Exception as e:\r\n            self._debug_info[\"llm_call_error\"] = str(e)\r\n            self.status = f\"Erro ao chamar LLM: {str(e)}\"\r\n            # Retorna uma string vazia ou lança exceção para ser capturada acima\r\n            raise # Re-levanta a exceção para ser tratada no método principal\r\n\r\n    def _prepare_llm_input(self, chunks: List[Dict], constraints: str, current_date_str: str) -> str:\r\n        \"\"\"\r\n        Prepara o prompt para o LLM, combinando as restrições, a data atual e metadados dos chunks.\r\n        \"\"\"\r\n        \r\n        chunks_for_llm = []\r\n        for chunk in chunks:\r\n            resumo_text = chunk.get('resumo', '') \r\n            metadata_chunk = {\r\n                \"_id\": chunk.get('_id'),\r\n                \"atualizado_em\": chunk.get('atualizado_em'),\r\n                \"id_reuniao\": chunk.get('id_reuniao'),\r\n                \"id_documento\": chunk.get('id'),\r\n                \"classificacao\": chunk.get('classificacao'),\r\n                \"resumo_do_documento\": resumo_text\r\n            }\r\n            # Remover chaves com valor None para economizar tokens\r\n            chunks_for_llm.append({k: v for k, v in metadata_chunk.items() if v is not None})\r\n\r\n        chunks_json_for_llm = json.dumps(chunks_for_llm, indent=2, ensure_ascii=False)\r\n        \r\n        prompt = f\"\"\"Você é um especialista em análise temporal de documentos.\r\nSua tarefa é filtrar uma lista de METADADOS de 'chunks' de documentos com base em 'restrições temporais' e uma 'data atual de referência'.\r\n\r\nData Atual de Referência: {current_date_str}\r\n\r\nRestrições Temporais a serem aplicadas:\r\n{constraints}\r\n\r\nLista de METADADOS dos Chunks (em formato JSON) para análise:\r\nCada objeto na lista representa um chunk e contém os seguintes campos (alguns podem ser omitidos se não aplicáveis ao chunk):\r\n- _id: Identificador único do chunk (gerado pelo sistema).\r\n- atualizado_em: Data/hora da última atualização do chunk/documento (formato ISO).\r\n- id_reuniao: Identificador do evento de reunião ao qual o chunk pertence (se aplicável).\r\n- id_documento: Identificador principal do documento/evento ao qual o chunk pertence.\r\n- classificacao: Classificação do tipo de documento/evento (ex: 'ata', 'relatorio', 'documento').\r\n- resumo_do_documento: O resumo completo do documento ao qual o chunk pertence.\r\n\r\n{chunks_json_for_llm}\r\n\r\nInstruções:\r\n1. Analise CUIDADOSAMENTE as 'Restrições Temporais'.\r\n2. Utilize a 'Data Atual de Referência' para resolver quaisquer referências relativas (ex: \"semana passada\", \"últimos 3 meses\") e aplique-as ao campo 'atualizado_em' dos metadados dos chunks.\r\n3. Considere os campos 'id_documento' (ou 'id_reuniao') e 'classificacao' dos metadados para identificar e agrupar chunks que pertencem ao mesmo evento/documento, conforme as 'Restrições Temporais' (ex: \"última reunião com classificação 'ata'\").\r\n4. Se as restrições mencionam \"último evento\" ou similar, você deve identificar o evento (usando 'id_documento' ou 'id_reuniao', agrupando por características e 'atualizado_em') que é o mais recente e, então, selecionar TODOS os metadados de chunks que pertencem a ESSE evento específico.\r\n5. Sua saída deve ser EXCLUSIVAMENTE uma string JSON contendo a lista dos OBJETOS DE METADADOS (exatamente como fornecidos na entrada, mas apenas os selecionados) que satisfazem as restrições. Mantenha a estrutura dos objetos de metadados selecionados.\r\n   - Se nenhum chunk atender aos critérios, retorne uma lista JSON vazia: [].\r\n   - Não adicione nenhuma explicação, introdução, conclusão ou qualquer texto fora do JSON da lista de metadados.\r\n\r\nExemplo de Saída Esperada (somente a string JSON da lista de METADADOS de chunks filtrados):\r\n[\r\n  {{ \"_id\": \"chunk_xyz123\", \"atualizado_em\": \"2024-08-20T10:00:00Z\", \"id_documento\": \"doc_evento_A\", \"resumo_do_documento\": \"Este é o resumo do documento A...\" }},\r\n  {{ \"_id\": \"chunk_abc789\", \"atualizado_em\": \"2024-08-20T10:00:00Z\", \"id_documento\": \"doc_evento_A\", \"resumo_do_documento\": \"Este é o resumo do documento A...\" }}\r\n]\r\n\"\"\"\r\n        return prompt\r\n\r\n    def filter_chunks_with_llm(self) -> Data:\r\n        self._debug_info = {}\r\n        original_chunks_map: Dict[str, Dict[str, Any]] = {} # Para mapear IDs de volta para chunks completos\r\n\r\n        try:\r\n            input_data = self.input_chunks\r\n            if not isinstance(input_data, Data) or not isinstance(input_data.data, dict):\r\n                self.status = \"Erro: Input chunks deve ser um objeto Data contendo um dicionário.\"\r\n                self._debug_info[\"error\"] = self.status\r\n                return Data(data={\"results\": [], \"error\": self.status})\r\n            \r\n            raw_chunks: List[Dict[str, Any]] = input_data.data.get(\"results\", [])\r\n            if not raw_chunks:\r\n                self.status = \"Nenhum chunk para filtrar.\"\r\n                self._debug_info[\"message\"] = self.status\r\n                return Data(data={\"results\": [], \"message\": self.status})\r\n            \r\n            # Criar mapa dos chunks originais para fácil recuperação e garantir que _id seja string\r\n            for chunk_item in raw_chunks:\r\n                chunk_id = chunk_item.get('_id')\r\n                if chunk_id is not None:\r\n                    original_chunks_map[str(chunk_id)] = chunk_item \r\n                else:\r\n                    # Se não houver _id, não poderemos mapear de volta. Poderíamos gerar um ID temporário\r\n                    # ou alertar. Por ora, vamos pular chunks sem ID para a filtragem LLM.\r\n                    self._debug_info.setdefault(\"warnings\", []).append(f\"Chunk sem _id encontrado: {str(chunk_item)[:100]}...\")\r\n            \r\n            # Usar apenas os chunks que têm _id para a preparação do prompt\r\n            chunks_with_ids_for_prompt = [ch for ch in raw_chunks if ch.get('_id') is not None]\r\n            if not chunks_with_ids_for_prompt:\r\n                self.status = \"Nenhum chunk com _id encontrado para processamento.\"\r\n                return Data(data={\"results\": [], \"message\": self.status})\r\n\r\n            self._debug_info[\"original_chunk_count\"] = len(raw_chunks)\r\n            self._debug_info[\"chunks_sent_to_llm_preparation_count\"] = len(chunks_with_ids_for_prompt)\r\n\r\n            constraints_input = self.temporal_constraints\r\n            if isinstance(constraints_input, Data) and isinstance(constraints_input.data, dict):\r\n                constraints_text: str = constraints_input.data.get(\"temporal_constraints\", \"\")\r\n            elif isinstance(constraints_input, str):\r\n                constraints_text: str = constraints_input\r\n            else:\r\n                constraints_text: str = str(constraints_input.data if isinstance(constraints_input, Data) else constraints_input)\r\n\r\n            if not constraints_text or constraints_text.strip().lower() == \"nenhuma restrição temporal específica identificada\":\r\n                self.status = \"Nenhuma restrição temporal aplicável. Retornando todos os chunks originais.\"\r\n                self._debug_info[\"message\"] = self.status\r\n                return Data(data={\"results\": raw_chunks, \"message\": self.status})\r\n            self._debug_info[\"temporal_constraints_received\"] = constraints_text\r\n            \r\n            current_date_str: str = self.current_date \r\n            try:\r\n                datetime.strptime(current_date_str, \"%Y-%m-%d\")\r\n            except ValueError:\r\n                self.status = \"Erro: Data atual deve estar no formato YYYY-MM-DD.\"\r\n                self._debug_info[\"error\"] = self.status\r\n                return Data(data={\"results\": [], \"error\": self.status})\r\n            self._debug_info[\"current_date_received\"] = current_date_str\r\n\r\n            llm_prompt = self._prepare_llm_input(chunks_with_ids_for_prompt, constraints_text, current_date_str)\r\n            self._debug_info[\"llm_prompt\"] = llm_prompt\r\n            \r\n            # Chamar o LLM conectado\r\n            # self.llm_model é agora uma instância de LanguageModel\r\n            if not hasattr(self, 'llm_model') or self.llm_model is None:\r\n                self.status = \"Erro: Modelo LLM para Filtragem não foi fornecido ou não está conectado.\"\r\n                self._debug_info[\"error\"] = self.status\r\n                return Data(data={\"results\": [], \"error\": self.status})\r\n\r\n            llm_response_text = self._call_llm(self.llm_model, llm_prompt)\r\n            self._debug_info[\"llm_response_raw\"] = llm_response_text\r\n            \r\n            filtered_metadata_from_llm: List[Dict[str,Any]]\r\n            try:\r\n                raw_json_response = llm_response_text\r\n                if \"```json\" in raw_json_response:\r\n                    raw_json_response = raw_json_response.split(\"```json\")[1].split(\"```\")[0].strip()\r\n                elif \"```\" in raw_json_response: # Genérico para ``` .... ```\r\n                    raw_json_response = raw_json_response.split(\"```\")[1].strip()\r\n                \r\n                parsed_response = json.loads(raw_json_response)\r\n                if not isinstance(parsed_response, list):\r\n                    raise ValueError(\"LLM não retornou uma lista JSON.\")\r\n                filtered_metadata_from_llm = parsed_response\r\n\r\n            except json.JSONDecodeError as jde:\r\n                self.status = f\"Erro: LLM retornou uma resposta que não é JSON válido. Detalhes: {str(jde)}\"\r\n                self._debug_info[\"error\"] = self.status\r\n                self._debug_info[\"llm_response_error_details\"] = llm_response_text\r\n                return Data(data={\"results\": [], \"error\": self.status})\r\n            except ValueError as ve:\r\n                self.status = f\"Erro ao processar resposta do LLM: {str(ve)}\"\r\n                self._debug_info[\"error\"] = self.status\r\n                self._debug_info[\"llm_response_error_details\"] = llm_response_text\r\n                return Data(data={\"results\": [], \"error\": self.status})\r\n            \r\n            # Mapear os metadados filtrados de volta para os chunks originais completos\r\n            final_filtered_chunks: List[Dict[str, Any]] = []\r\n            processed_ids_from_llm = set()\r\n\r\n            for item_meta in filtered_metadata_from_llm:\r\n                if not isinstance(item_meta, dict):\r\n                    self._debug_info.setdefault(\"warnings\", []).append(f\"Item não-dicionário na resposta do LLM: {item_meta}\")\r\n                    continue\r\n                \r\n                llm_item_id = item_meta.get('_id')\r\n                if llm_item_id is not None:\r\n                    # Garantir que o ID seja string para correspondência com as chaves do mapa\r\n                    llm_item_id_str = str(llm_item_id)\r\n                    if llm_item_id_str in original_chunks_map and llm_item_id_str not in processed_ids_from_llm:\r\n                        final_filtered_chunks.append(original_chunks_map[llm_item_id_str])\r\n                        processed_ids_from_llm.add(llm_item_id_str)\r\n                    else:\r\n                        self._debug_info.setdefault(\"warnings\", []).append(f\"ID {llm_item_id_str} da resposta do LLM não encontrado nos chunks originais ou já processado.\")\r\n                else:\r\n                    self._debug_info.setdefault(\"warnings\", []).append(f\"Item da resposta do LLM sem _id: {item_meta}\")\r\n\r\n            self._debug_info[\"filtered_chunk_count_from_llm_metadata\"] = len(filtered_metadata_from_llm)\r\n            self._debug_info[\"final_mapped_chunk_count\"] = len(final_filtered_chunks)\r\n            \r\n            result_message = f\"Filtragem com LLM resultou em {len(final_filtered_chunks)} chunks.\"\r\n            self.status = result_message\r\n            self._debug_info[\"final_message\"] = result_message\r\n            \r\n            return Data(data={\r\n                \"results\": final_filtered_chunks, \r\n                \"message\": result_message,\r\n                \"applied_constraints_summary\": constraints_text[:200] + \"...\" if len(constraints_text) > 200 else constraints_text\r\n            })\r\n\r\n        except Exception as e:\r\n            error_msg = f\"Erro crítico no TemporalFilterComponent: {str(e)}\"\r\n            self.status = error_msg\r\n            self._debug_info[\"critical_error\"] = error_msg\r\n            import traceback\r\n            self._debug_info[\"traceback\"] = traceback.format_exc()\r\n            return Data(data={\"results\": [], \"error\": error_msg})\r\n\r\n    def get_debug_info(self) -> Data:\r\n        \"\"\"Retorna informações de debug da última execução.\"\"\"\r\n        return Data(data=self._debug_info, display=\"Debug Info\") "
              },
              "current_date": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Data Atual",
                "dynamic": false,
                "info": "Data atual no formato YYYY-MM-DD. Pode ser uma variável como {{current_date_component.current_date}}.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "current_date",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input_chunks": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Chunks de Entrada",
                "dynamic": false,
                "info": "Lista de chunks retornados pela busca lexical (Data object)",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_chunks",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "llm_model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Modelo LLM para Filtragem",
                "dynamic": false,
                "info": "LLM configurado para realizar a filtragem temporal baseada nas constraints.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "llm_model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "temporal_constraints": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Restrições Temporais (Prompt para LLM)",
                "dynamic": false,
                "info": "Texto descritivo das restrições temporais, usado como prompt para o LLM (Data object ou string)",
                "input_types": [
                  "Data",
                  "str"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "temporal_constraints",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TemporalFilterLLM"
        },
        "dragging": false,
        "id": "CustomComponent-IzLd7",
        "measured": {
          "height": 449,
          "width": 320
        },
        "position": {
          "x": 7895.008968214656,
          "y": -4243.1217388247005
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "AzureOpenAIModel-ivZA3",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Azure OpenAI LLMs.",
            "display_name": "Azure OpenAI",
            "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "azure_endpoint",
              "azure_deployment",
              "api_key",
              "api_version",
              "temperature",
              "max_tokens"
            ],
            "frozen": false,
            "icon": "Azure",
            "key": "AzureOpenAIModel",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": false,
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [
                  "api_key",
                  "azure_deployment",
                  "azure_endpoint"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003924824467069744,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "api_version": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "API Version",
                "dynamic": false,
                "info": "",
                "name": "api_version",
                "options": [
                  "2024-10-01-preview",
                  "2024-09-01-preview",
                  "2024-08-01-preview",
                  "2024-07-01-preview",
                  "2024-06-01",
                  "2024-03-01-preview",
                  "2024-02-15-preview",
                  "2023-12-01-preview",
                  "2023-05-15"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "2024-06-01"
              },
              "azure_deployment": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Deployment Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "azure_deployment",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "name-gpt-4o-mini-aion"
              },
              "azure_endpoint": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Azure Endpoint",
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "azure_endpoint",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "endpoint-gpt-4o-mini-aion"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import AzureChatOpenAI\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import MessageTextInput\nfrom langflow.io import DropdownInput, IntInput, SecretStrInput, SliderInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2024-06-01\",\n        \"2024-07-01-preview\",\n        \"2024-08-01-preview\",\n        \"2024-09-01-preview\",\n        \"2024-10-01-preview\",\n        \"2023-05-15\",\n        \"2023-12-01-preview\",\n        \"2024-02-15-preview\",\n        \"2024-03-01-preview\",\n    ]\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\", required=True),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=sorted(AZURE_OPENAI_API_VERSIONS, reverse=True),\n            value=next(\n                (\n                    version\n                    for version in sorted(AZURE_OPENAI_API_VERSIONS, reverse=True)\n                    if not version.endswith(\"-preview\")\n                ),\n                AZURE_OPENAI_API_VERSIONS[0],\n            ),\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to AzureOpenAI API: {e}\"\n            raise ValueError(msg) from e\n\n        return output\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AzureOpenAIModel"
        },
        "dragging": false,
        "id": "AzureOpenAIModel-ivZA3",
        "measured": {
          "height": 688,
          "width": 320
        },
        "position": {
          "x": 7435.787794559096,
          "y": -4794.13079668182
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseJSONData-hQK9Q",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom json import JSONDecodeError\n\nimport jq\nfrom json_repair import repair_json\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.inputs import HandleInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseJSONDataComponent(Component):\n    display_name = \"Parse JSON\"\n    description = \"Convert and extract JSON fields.\"\n    icon = \"braces\"\n    name = \"ParseJSONData\"\n    legacy: bool = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"Data object to filter.\",\n            required=True,\n            input_types=[\"Message\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"JQ Query\",\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def _parse_data(self, input_value) -> str:\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\n            return input_value.text\n        if isinstance(input_value, Data):\n            return json.dumps(input_value.data)\n        return str(input_value)\n\n    def filter_data(self) -> list[Data]:\n        to_filter = self.input_value\n        if not to_filter:\n            return []\n        # Check if input is a list\n        if isinstance(to_filter, list):\n            to_filter = [self._parse_data(f) for f in to_filter]\n        else:\n            to_filter = self._parse_data(to_filter)\n\n        # If input is not a list, don't wrap it in a list\n        if not isinstance(to_filter, list):\n            to_filter = repair_json(to_filter)\n            try:\n                to_filter_as_dict = json.loads(to_filter)\n            except JSONDecodeError:\n                try:\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\n                except JSONDecodeError as e:\n                    msg = f\"Invalid JSON: {e}\"\n                    raise ValueError(msg) from e\n        else:\n            to_filter = [repair_json(f) for f in to_filter]\n            to_filter_as_dict = []\n            for f in to_filter:\n                try:\n                    to_filter_as_dict.append(json.loads(f))\n                except JSONDecodeError:\n                    try:\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\n                    except JSONDecodeError as e:\n                        msg = f\"Invalid JSON: {e}\"\n                        raise ValueError(msg) from e\n            to_filter = to_filter_as_dict\n\n        full_filter_str = json.dumps(to_filter_as_dict)\n\n        logger.info(\"to_filter: \", to_filter)\n\n        results = jq.compile(self.query).input_text(full_filter_str).all()\n        logger.info(\"results: \", results)\n        return [Data(data=value) if isinstance(value, dict) else Data(text=str(value)) for value in results]\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ Query to filter the data. The input is always a JSON list.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".rerank_pesos"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "ParseJSONData-hQK9Q",
        "measured": {
          "height": 273,
          "width": 320
        },
        "position": {
          "x": 5321.619964569385,
          "y": -2447.572532801193
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-PZSld",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_text",
              "match_text",
              "operator",
              "case_sensitive",
              "message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "hidden": false,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "hidden": null,
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Case Sensitive",
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "case_sensitive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"regex\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n        ),\n        MessageTextInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Data:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"false_result\")\n            return self.message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Data:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if not result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.message\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n\n            # Ensure case_sensitive is present for all other operators\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "requer_esclarecimento"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": false,
                "info": "The message to pass through either route.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "load_from_db": false,
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "contains"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-PZSld",
        "measured": {
          "height": 586,
          "width": 320
        },
        "position": {
          "x": 4667.743510577447,
          "y": 3544.00385224376
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-Lys4Y",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_text",
              "match_text",
              "operator",
              "case_sensitive",
              "message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "hidden": false,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "hidden": null,
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Case Sensitive",
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "case_sensitive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"regex\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n        ),\n        DataInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Data:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"false_result\")\n            return self.message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Data:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if not result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.message\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n\n            # Ensure case_sensitive is present for all other operators\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "corporativo_global"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "message": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": false,
                "info": "The message to pass through either route.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "load_from_db": false,
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "contains"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-Lys4Y",
        "measured": {
          "height": 548,
          "width": 320
        },
        "position": {
          "x": 4703.401726956013,
          "y": -632.378556354411
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseJSONData-s00MM",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom json import JSONDecodeError\n\nimport jq\nfrom json_repair import repair_json\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.inputs import HandleInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseJSONDataComponent(Component):\n    display_name = \"Parse JSON\"\n    description = \"Convert and extract JSON fields.\"\n    icon = \"braces\"\n    name = \"ParseJSONData\"\n    legacy: bool = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"Data object to filter.\",\n            required=True,\n            input_types=[\"Message\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"JQ Query\",\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def _parse_data(self, input_value) -> str:\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\n            return input_value.text\n        if isinstance(input_value, Data):\n            return json.dumps(input_value.data)\n        return str(input_value)\n\n    def filter_data(self) -> list[Data]:\n        to_filter = self.input_value\n        if not to_filter:\n            return []\n        # Check if input is a list\n        if isinstance(to_filter, list):\n            to_filter = [self._parse_data(f) for f in to_filter]\n        else:\n            to_filter = self._parse_data(to_filter)\n\n        # If input is not a list, don't wrap it in a list\n        if not isinstance(to_filter, list):\n            to_filter = repair_json(to_filter)\n            try:\n                to_filter_as_dict = json.loads(to_filter)\n            except JSONDecodeError:\n                try:\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\n                except JSONDecodeError as e:\n                    msg = f\"Invalid JSON: {e}\"\n                    raise ValueError(msg) from e\n        else:\n            to_filter = [repair_json(f) for f in to_filter]\n            to_filter_as_dict = []\n            for f in to_filter:\n                try:\n                    to_filter_as_dict.append(json.loads(f))\n                except JSONDecodeError:\n                    try:\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\n                    except JSONDecodeError as e:\n                        msg = f\"Invalid JSON: {e}\"\n                        raise ValueError(msg) from e\n            to_filter = to_filter_as_dict\n\n        full_filter_str = json.dumps(to_filter_as_dict)\n\n        logger.info(\"to_filter: \", to_filter)\n\n        results = jq.compile(self.query).input_text(full_filter_str).all()\n        logger.info(\"results: \", results)\n        return [Data(data=value) if isinstance(value, dict) else Data(text=str(value)) for value in results]\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ Query to filter the data. The input is always a JSON list.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".rerank_pesos"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "ParseJSONData-s00MM",
        "measured": {
          "height": 273,
          "width": 320
        },
        "position": {
          "x": 5412.564554579978,
          "y": 97.49234353510957
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseJSONData-LerBu",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom json import JSONDecodeError\n\nimport jq\nfrom json_repair import repair_json\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.inputs import HandleInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseJSONDataComponent(Component):\n    display_name = \"Parse JSON\"\n    description = \"Convert and extract JSON fields.\"\n    icon = \"braces\"\n    name = \"ParseJSONData\"\n    legacy: bool = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"Data object to filter.\",\n            required=True,\n            input_types=[\"Message\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"JQ Query\",\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def _parse_data(self, input_value) -> str:\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\n            return input_value.text\n        if isinstance(input_value, Data):\n            return json.dumps(input_value.data)\n        return str(input_value)\n\n    def filter_data(self) -> list[Data]:\n        to_filter = self.input_value\n        if not to_filter:\n            return []\n        # Check if input is a list\n        if isinstance(to_filter, list):\n            to_filter = [self._parse_data(f) for f in to_filter]\n        else:\n            to_filter = self._parse_data(to_filter)\n\n        # If input is not a list, don't wrap it in a list\n        if not isinstance(to_filter, list):\n            to_filter = repair_json(to_filter)\n            try:\n                to_filter_as_dict = json.loads(to_filter)\n            except JSONDecodeError:\n                try:\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\n                except JSONDecodeError as e:\n                    msg = f\"Invalid JSON: {e}\"\n                    raise ValueError(msg) from e\n        else:\n            to_filter = [repair_json(f) for f in to_filter]\n            to_filter_as_dict = []\n            for f in to_filter:\n                try:\n                    to_filter_as_dict.append(json.loads(f))\n                except JSONDecodeError:\n                    try:\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\n                    except JSONDecodeError as e:\n                        msg = f\"Invalid JSON: {e}\"\n                        raise ValueError(msg) from e\n            to_filter = to_filter_as_dict\n\n        full_filter_str = json.dumps(to_filter_as_dict)\n\n        logger.info(\"to_filter: \", to_filter)\n\n        results = jq.compile(self.query).input_text(full_filter_str).all()\n        logger.info(\"results: \", results)\n        return [Data(data=value) if isinstance(value, dict) else Data(text=str(value)) for value in results]\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ Query to filter the data. The input is always a JSON list.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".message"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "ParseJSONData-LerBu",
        "measured": {
          "height": 273,
          "width": 320
        },
        "position": {
          "x": 5418.235094211927,
          "y": -1069.5598110566561
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseJSONData-4eZ9F",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom json import JSONDecodeError\n\nimport jq\nfrom json_repair import repair_json\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.inputs import HandleInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseJSONDataComponent(Component):\n    display_name = \"Parse JSON\"\n    description = \"Convert and extract JSON fields.\"\n    icon = \"braces\"\n    name = \"ParseJSONData\"\n    legacy: bool = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"Data object to filter.\",\n            required=True,\n            input_types=[\"Message\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"JQ Query\",\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def _parse_data(self, input_value) -> str:\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\n            return input_value.text\n        if isinstance(input_value, Data):\n            return json.dumps(input_value.data)\n        return str(input_value)\n\n    def filter_data(self) -> list[Data]:\n        to_filter = self.input_value\n        if not to_filter:\n            return []\n        # Check if input is a list\n        if isinstance(to_filter, list):\n            to_filter = [self._parse_data(f) for f in to_filter]\n        else:\n            to_filter = self._parse_data(to_filter)\n\n        # If input is not a list, don't wrap it in a list\n        if not isinstance(to_filter, list):\n            to_filter = repair_json(to_filter)\n            try:\n                to_filter_as_dict = json.loads(to_filter)\n            except JSONDecodeError:\n                try:\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\n                except JSONDecodeError as e:\n                    msg = f\"Invalid JSON: {e}\"\n                    raise ValueError(msg) from e\n        else:\n            to_filter = [repair_json(f) for f in to_filter]\n            to_filter_as_dict = []\n            for f in to_filter:\n                try:\n                    to_filter_as_dict.append(json.loads(f))\n                except JSONDecodeError:\n                    try:\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\n                    except JSONDecodeError as e:\n                        msg = f\"Invalid JSON: {e}\"\n                        raise ValueError(msg) from e\n            to_filter = to_filter_as_dict\n\n        full_filter_str = json.dumps(to_filter_as_dict)\n\n        logger.info(\"to_filter: \", to_filter)\n\n        results = jq.compile(self.query).input_text(full_filter_str).all()\n        logger.info(\"results: \", results)\n        return [Data(data=value) if isinstance(value, dict) else Data(text=str(value)) for value in results]\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ Query to filter the data. The input is always a JSON list.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".message_text"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "ParseJSONData-4eZ9F",
        "measured": {
          "height": 273,
          "width": 320
        },
        "position": {
          "x": 5404.662654601999,
          "y": -738.8460432560579
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseJSONData-bWJwa",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom json import JSONDecodeError\n\nimport jq\nfrom json_repair import repair_json\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.inputs import HandleInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseJSONDataComponent(Component):\n    display_name = \"Parse JSON\"\n    description = \"Convert and extract JSON fields.\"\n    icon = \"braces\"\n    name = \"ParseJSONData\"\n    legacy: bool = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"Data object to filter.\",\n            required=True,\n            input_types=[\"Message\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"JQ Query\",\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def _parse_data(self, input_value) -> str:\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\n            return input_value.text\n        if isinstance(input_value, Data):\n            return json.dumps(input_value.data)\n        return str(input_value)\n\n    def filter_data(self) -> list[Data]:\n        to_filter = self.input_value\n        if not to_filter:\n            return []\n        # Check if input is a list\n        if isinstance(to_filter, list):\n            to_filter = [self._parse_data(f) for f in to_filter]\n        else:\n            to_filter = self._parse_data(to_filter)\n\n        # If input is not a list, don't wrap it in a list\n        if not isinstance(to_filter, list):\n            to_filter = repair_json(to_filter)\n            try:\n                to_filter_as_dict = json.loads(to_filter)\n            except JSONDecodeError:\n                try:\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\n                except JSONDecodeError as e:\n                    msg = f\"Invalid JSON: {e}\"\n                    raise ValueError(msg) from e\n        else:\n            to_filter = [repair_json(f) for f in to_filter]\n            to_filter_as_dict = []\n            for f in to_filter:\n                try:\n                    to_filter_as_dict.append(json.loads(f))\n                except JSONDecodeError:\n                    try:\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\n                    except JSONDecodeError as e:\n                        msg = f\"Invalid JSON: {e}\"\n                        raise ValueError(msg) from e\n            to_filter = to_filter_as_dict\n\n        full_filter_str = json.dumps(to_filter_as_dict)\n\n        logger.info(\"to_filter: \", to_filter)\n\n        results = jq.compile(self.query).input_text(full_filter_str).all()\n        logger.info(\"results: \", results)\n        return [Data(data=value) if isinstance(value, dict) else Data(text=str(value)) for value in results]\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ Query to filter the data. The input is always a JSON list.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".temporal_constraints"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "ParseJSONData-bWJwa",
        "measured": {
          "height": 273,
          "width": 320
        },
        "position": {
          "x": 5406.445027876701,
          "y": -341.4851848556448
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "MongoDBAtlasVector-QN8Qg",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "MongoDB Atlas Vector Store with search capabilities",
            "display_name": "MongoDB Atlas",
            "documentation": "",
            "edited": true,
            "field_order": [
              "mongodb_atlas_cluster_uri",
              "enable_mtls",
              "mongodb_atlas_client_cert",
              "db_name",
              "collection_name",
              "index_name",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "insert_mode",
              "embedding",
              "number_of_results",
              "setores",
              "min_similarity_score",
              "number_dimensions",
              "similarity",
              "quantization"
            ],
            "frozen": false,
            "icon": "MongoDB",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "hidden": false,
                "method": "search_documents",
                "name": "search_results",
                "options": null,
                "required_inputs": [
                  "collection_name",
                  "db_name",
                  "enable_mtls",
                  "index_name",
                  "mongodb_atlas_cluster_uri",
                  "number_dimensions"
                ],
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "hidden": null,
                "method": "as_dataframe",
                "name": "dataframe",
                "options": null,
                "required_inputs": [],
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import tempfile\r\nimport time\r\nfrom typing import Any, Dict, List, Optional\r\n\r\nimport certifi\r\nfrom bson.objectid import ObjectId\r\nfrom pymongo import MongoClient\r\nfrom pymongo.operations import SearchIndexModel\r\nfrom langchain_community.vectorstores import MongoDBAtlasVectorSearch\r\n\r\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\r\nfrom langflow.helpers.data import docs_to_data\r\nfrom langflow.io import (\r\n    BoolInput,\r\n    DropdownInput,\r\n    HandleInput,\r\n    IntInput,\r\n    SecretStrInput,\r\n    StrInput,\r\n)\r\nfrom langflow.schema import Data\r\n\r\n\r\nclass MongoVectorStoreComponent(LCVectorStoreComponent):\r\n    display_name = \"MongoDB Atlas\"\r\n    description = \"MongoDB Atlas Vector Store with search capabilities\"\r\n    name = \"MongoDBAtlasVector\"\r\n    icon = \"MongoDB\"\r\n    INSERT_MODES = [\"append\", \"overwrite\"]\r\n    SIMILARITY_OPTIONS = [\"cosine\", \"euclidean\", \"dotProduct\"]\r\n    QUANTIZATION_OPTIONS = [\"scalar\", \"binary\"]\r\n\r\n    inputs = [\r\n        SecretStrInput(\r\n            name=\"mongodb_atlas_cluster_uri\",\r\n            display_name=\"MongoDB Atlas Cluster URI\",\r\n            required=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"enable_mtls\",\r\n            display_name=\"Enable mTLS\",\r\n            value=False,\r\n            advanced=True,\r\n            required=True,\r\n        ),\r\n        SecretStrInput(\r\n            name=\"mongodb_atlas_client_cert\",\r\n            display_name=\"MongoDB Atlas Combined Client Certificate\",\r\n            required=False,\r\n            advanced=True,\r\n            info=\"Client certificate + private key PEM, if using mTLS.\",\r\n        ),\r\n        StrInput(name=\"db_name\", display_name=\"Database Name\", required=True),\r\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", required=True),\r\n        StrInput(\r\n            name=\"index_name\",\r\n            display_name=\"Index Name\",\r\n            required=True,\r\n            info=\"Name of the Atlas Search vector index.\",\r\n        ),\r\n        *LCVectorStoreComponent.inputs,\r\n        DropdownInput(\r\n            name=\"insert_mode\",\r\n            display_name=\"Insert Mode\",\r\n            options=INSERT_MODES,\r\n            value=INSERT_MODES[0],\r\n            advanced=True,\r\n            info=\"How to insert new documents (append or overwrite).\",\r\n        ),\r\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\r\n        IntInput(\r\n            name=\"number_of_results\",\r\n            display_name=\"Number of Results\",\r\n            value=20,\r\n            advanced=True,\r\n        ),\r\n        MultilineInput(\r\n            name=\"setores\",\r\n            display_name=\"Filtro por Setores\",\r\n            info=\"Lista de setores para filtrar (ex: ['Risco', 'Operacional']).\",\r\n            advanced=True,\r\n            required=False,\r\n        ),\r\n        StrInput(\r\n            name=\"min_similarity_score\",\r\n            display_name=\"Score Mínimo de Similaridade\",\r\n            info=\"Filtra resultados abaixo deste score (0.0-1.0).\",\r\n            advanced=True,\r\n            required=False,\r\n        ),\r\n        IntInput(\r\n            name=\"number_dimensions\",\r\n            display_name=\"Number of Dimensions\",\r\n            value=1536,\r\n            advanced=True,\r\n            required=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"similarity\",\r\n            display_name=\"Similarity\",\r\n            options=SIMILARITY_OPTIONS,\r\n            value=SIMILARITY_OPTIONS[0],\r\n            advanced=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"quantization\",\r\n            display_name=\"Quantization\",\r\n            options=QUANTIZATION_OPTIONS,\r\n            value=None,\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    @check_cached_vector_store\r\n    def build_vector_store(self) -> MongoDBAtlasVectorSearch:\r\n        # Configura cliente MongoDB, com mTLS se habilitado\r\n        client_cert_path = None\r\n        if self.enable_mtls and self.mongodb_atlas_client_cert:\r\n            pem = self.mongodb_atlas_client_cert.strip().replace(\" \", \"\\n\")\r\n            with tempfile.NamedTemporaryFile(delete=False) as tmp:\r\n                tmp.write(pem.encode(\"utf-8\"))\r\n                client_cert_path = tmp.name\r\n\r\n        client = (\r\n            MongoClient(\r\n                self.mongodb_atlas_cluster_uri,\r\n                tls=True,\r\n                tlsCertificateKeyFile=client_cert_path,\r\n                tlsCAFile=certifi.where(),\r\n            )\r\n            if self.enable_mtls\r\n            else MongoClient(self.mongodb_atlas_cluster_uri)\r\n        )\r\n        collection = client[self.db_name][self.collection_name]\r\n\r\n        # Prepara documentos\r\n        docs: List[Any] = []\r\n        for item in (self._prepare_ingest_data() or []):\r\n            docs.append(item.to_lc_document() if isinstance(item, Data) else item)\r\n\r\n        if docs:\r\n            if self.insert_mode == \"overwrite\":\r\n                collection.delete_many({})\r\n            return MongoDBAtlasVectorSearch.from_documents(\r\n                documents=docs,\r\n                embedding=self.embedding,\r\n                collection=collection,\r\n                index_name=self.index_name,\r\n            )\r\n\r\n        return MongoDBAtlasVectorSearch(\r\n            embedding=self.embedding,\r\n            collection=collection,\r\n            index_name=self.index_name,\r\n        )\r\n\r\n    def _parse_setores(self, raw: Optional[str]) -> Optional[List[str]]:\r\n        if not raw or not raw.strip():\r\n            return None\r\n        try:\r\n            import ast\r\n            raw = raw.strip()\r\n            if raw.startswith('[') and raw.endswith(']'):\r\n                parsed = ast.literal_eval(raw)\r\n                return [str(x) for x in parsed] if isinstance(parsed, list) else None\r\n            if ',' in raw:\r\n                return [x.strip().strip(\"'\\\"\") for x in raw.split(',')]\r\n            return [raw.strip().strip(\"'\\\"\")]\r\n        except Exception:\r\n            return None\r\n\r\n    def _create_setores_filter(self, setores: Optional[List[str]]) -> Optional[Dict[str, Any]]:\r\n        if not setores:\r\n            return None\r\n        return {\"setores\": {\"$in\": setores}}\r\n\r\n    def search_documents(self) -> List[Data]:\r\n        vs = self.build_vector_store()\r\n        self.verify_search_index(vs._collection)\r\n\r\n        if not isinstance(self.search_query, str) or not self.search_query:\r\n            return []\r\n\r\n        # Define número de resultados\r\n        k = self.number_of_results\r\n\r\n        setores_list = self._parse_setores(self.setores)\r\n        mongo_filter = self._create_setores_filter(setores_list)\r\n\r\n        try:\r\n            if mongo_filter:\r\n                docs_scores = vs.similarity_search_with_score(\r\n                    query=self.search_query,\r\n                    k=k,\r\n                    filter=mongo_filter,\r\n                )\r\n            else:\r\n                docs_scores = vs.similarity_search_with_score(\r\n                    query=self.search_query,\r\n                    k=k,\r\n                )\r\n        except TypeError:\r\n            # Fallback manual\r\n            all_scores = vs.similarity_search_with_score(query=self.search_query, k=k*3)\r\n            docs_scores = [item for item in all_scores if self._matches_setores(item[0], setores_list)][:k]\r\n\r\n        # Filtra por score mínimo\r\n        if self.min_similarity_score:\r\n            try:\r\n                min_s = float(self.min_similarity_score)\r\n                filtered = []\r\n                for doc, score in docs_scores:\r\n                    sim = (1/(1+score)) if self.similarity == \"euclidean\" else score\r\n                    if sim >= min_s:\r\n                        filtered.append((doc, score))\r\n                docs_scores = filtered\r\n            except ValueError:\r\n                pass\r\n\r\n        # Prepara dados de saída\r\n        processed = []\r\n        for entry in docs_scores:\r\n            doc, score = entry if isinstance(entry, tuple) else (entry, None)\r\n            if score is not None:\r\n                doc.metadata['similarity_score'] = float(score)\r\n            doc.metadata = {k: str(v) if isinstance(v, ObjectId) else v for k, v in doc.metadata.items()}\r\n            processed.append(doc)\r\n\r\n        data = docs_to_data(processed)\r\n        self.status = data\r\n        return data\r\n\r\n    def _matches_setores(self, doc: Data, setores_list: Optional[List[str]]) -> bool:\r\n        if not setores_list:\r\n            return True\r\n        val = doc.metadata.get('setores')\r\n        if isinstance(val, list):\r\n            return any(s in val for s in setores_list)\r\n        return isinstance(val, str) and val in setores_list\r\n\r\n    def verify_search_index(self, collection) -> None:\r\n        indexes = collection.list_search_indexes()\r\n        names = {idx['name']: idx['type'] for idx in indexes}\r\n        if self.index_name not in names or names[self.index_name] != 'vectorSearch':\r\n            fields = [\r\n                {\"type\": \"vector\", \"path\": self.index_field, \"numDimensions\": self.number_dimensions, \"similarity\": self.similarity, \"quantization\": self.quantization},\r\n                {\"type\": \"filter\", \"path\": \"setores\"},\r\n            ]\r\n            model = SearchIndexModel(definition={\"fields\": fields}, name=self.index_name, type=\"vectorSearch\")\r\n            collection.create_search_index(model)\r\n            time.sleep(20)\r\n"
              },
              "collection_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Collection Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "collection_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "knowledge_documentation"
              },
              "db_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Database Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "db_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "DeepContext"
              },
              "embedding": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_mtls": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Enable mTLS",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_mtls",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "index_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Index Name",
                "dynamic": false,
                "info": "Name of the Atlas Search vector index.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "index_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "vector_index_knowledge_documentation"
              },
              "ingest_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data",
                  "DataFrame"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "insert_mode": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Insert Mode",
                "dynamic": false,
                "info": "How to insert new documents (append or overwrite).",
                "name": "insert_mode",
                "options": [
                  "append",
                  "overwrite"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "append"
              },
              "min_similarity_score": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Score Mínimo de Similaridade",
                "dynamic": false,
                "info": "Filtra resultados abaixo deste score (0.0-1.0).",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "min_similarity_score",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "0.6"
              },
              "mongodb_atlas_client_cert": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "MongoDB Atlas Combined Client Certificate",
                "dynamic": false,
                "info": "Client certificate + private key PEM, if using mTLS.",
                "input_types": [],
                "load_from_db": false,
                "name": "mongodb_atlas_client_cert",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "mongodb_atlas_cluster_uri": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "MongoDB Atlas Cluster URI",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "mongodb_atlas_cluster_uri",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "number_dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Dimensions",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_dimensions",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1536
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "quantization": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Quantization",
                "dynamic": false,
                "info": "",
                "name": "quantization",
                "options": [
                  "scalar",
                  "binary"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str"
              },
              "search_query": {
                "_input_type": "QueryInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Enter a query to run a similarity search.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "search_query",
                "placeholder": "Enter a query...",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "query",
                "value": ""
              },
              "setores": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Filtro por Setores",
                "dynamic": false,
                "info": "Lista de setores para filtrar (ex: ['Risco', 'Operacional']).",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "setores",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "similarity": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Similarity",
                "dynamic": false,
                "info": "",
                "name": "similarity",
                "options": [
                  "cosine",
                  "euclidean",
                  "dotProduct"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "cosine"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "MongoDBAtlasVector"
        },
        "dragging": false,
        "id": "MongoDBAtlasVector-QN8Qg",
        "measured": {
          "height": 960,
          "width": 320
        },
        "position": {
          "x": 7457.758464015841,
          "y": 234.24370442306736
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "AzureOpenAIEmbeddings-kd4A2",
          "node": {
            "base_classes": [
              "Embeddings"
            ],
            "beta": false,
            "category": "embeddings",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate embeddings using Azure OpenAI models.",
            "display_name": "Azure OpenAI Embeddings",
            "documentation": "https://python.langchain.com/docs/integrations/text_embedding/azureopenai",
            "edited": false,
            "field_order": [
              "model",
              "azure_endpoint",
              "azure_deployment",
              "api_version",
              "api_key",
              "dimensions"
            ],
            "frozen": false,
            "icon": "Azure",
            "key": "AzureOpenAIEmbeddings",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Embeddings",
                "hidden": false,
                "method": "build_embeddings",
                "name": "embeddings",
                "selected": "Embeddings",
                "tool_mode": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "api_version": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "API Version",
                "dynamic": false,
                "info": "",
                "name": "api_version",
                "options": [
                  "2022-12-01",
                  "2023-03-15-preview",
                  "2023-05-15",
                  "2023-06-01-preview",
                  "2023-07-01-preview",
                  "2023-08-01-preview"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "2023-08-01-preview"
              },
              "azure_deployment": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Deployment Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "azure_deployment",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text-embedding-3-small"
              },
              "azure_endpoint": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Azure Endpoint",
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "azure_endpoint",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://aion-ai-dev.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import AzureOpenAIEmbeddings\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import DropdownInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass AzureOpenAIEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI Embeddings\"\n    description: str = \"Generate embeddings using Azure OpenAI models.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/text_embedding/azureopenai\"\n    icon = \"Azure\"\n    name = \"AzureOpenAIEmbeddings\"\n\n    API_VERSION_OPTIONS = [\n        \"2022-12-01\",\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n    ]\n\n    inputs = [\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=OPENAI_EMBEDDING_MODEL_NAMES[0],\n        ),\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            required=True,\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n        ),\n        MessageTextInput(\n            name=\"azure_deployment\",\n            display_name=\"Deployment Name\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=API_VERSION_OPTIONS,\n            value=API_VERSION_OPTIONS[-1],\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"API Key\",\n            required=True,\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            embeddings = AzureOpenAIEmbeddings(\n                model=self.model,\n                azure_endpoint=self.azure_endpoint,\n                azure_deployment=self.azure_deployment,\n                api_version=self.api_version,\n                api_key=self.api_key,\n                dimensions=self.dimensions or None,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to AzureOpenAIEmbeddings API: {e}\"\n            raise ValueError(msg) from e\n\n        return embeddings\n"
              },
              "dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Dimensions",
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "list": false,
                "list_add_label": "Add More",
                "name": "dimensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "info": "",
                "name": "model",
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text-embedding-3-small"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AzureOpenAIEmbeddings"
        },
        "dragging": false,
        "id": "AzureOpenAIEmbeddings-kd4A2",
        "measured": {
          "height": 496,
          "width": 320
        },
        "position": {
          "x": 6961.421354574791,
          "y": 798.1634151567575
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LLMRerankComponent-oHU1v",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Rerank de chunks combinando resultados lexicais e semânticos usando um modelo LLM e pesos dinâmicos.",
            "display_name": "LLM Rerank (Lexical + Semântico + Pesos)",
            "documentation": "",
            "edited": true,
            "field_order": [
              "question",
              "rerank_pesos",
              "lexical_chunks",
              "semantic_chunks",
              "llm",
              "top_k",
              "score_final_min"
            ],
            "frozen": false,
            "icon": "Sort",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chunks Rerankeados",
                "hidden": null,
                "method": "rerank_chunks",
                "name": "reranked_chunks",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import List, Dict, Any\nfrom langflow.custom import Component\nfrom langflow.inputs import (\n    HandleInput,\n    IntInput,\n    FloatInput,\n    MultilineInput,\n)\nfrom langflow.schema import Data\nfrom langflow.template import Output\n\nclass LLMRerankComponent(Component):\n    display_name = \"LLM Rerank (Lexical + Semântico + Pesos)\"\n    icon = \"Sort\"\n    description = \"Rerank de chunks combinando resultados lexicais e semânticos usando um modelo LLM e pesos dinâmicos.\"\n\n    inputs = [\n        HandleInput(\n            name=\"question\",\n            display_name=\"Pergunta\",\n            input_types=[\"str\", \"Message\"],\n            required=True,\n        ),\n        HandleInput(\n            name=\"rerank_pesos\",\n            display_name=\"Rerank Pesos\",\n            input_types=[\"dict\", \"Data\", \"str\"],\n            required=True,\n        ),\n        HandleInput(\n            name=\"lexical_chunks\",\n            display_name=\"Chunks Lexicais\",\n            input_types=[\"list\", \"Data\"],\n            required=True,\n        ),\n        HandleInput(\n            name=\"semantic_chunks\",\n            display_name=\"Chunks Semânticos\",\n            input_types=[\"list\", \"Data\"],\n            required=True,\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"LLM Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            value=5,\n            info=\"Número máximo de chunks rerankeados a retornar.\",\n            required=False,\n        ),\n        MultilineInput(\n            name=\"score_final_min\",\n            display_name=\"Score Final Mínimo\",\n            value=\"2.0\",\n            info=\"Apenas chunks com rerank_score_final maior ou igual a este valor (de 0 a 5) serão retornados.\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            name=\"reranked_chunks\",\n            display_name=\"Chunks Rerankeados\",\n            method=\"rerank_chunks\",\n        ),\n    ]\n\n    def _extract_chunks(self, input_data):\n        if input_data is None:\n            return []\n        if isinstance(input_data, Data):\n            data = getattr(input_data, \"data\", None)\n            if isinstance(data, dict) and \"results\" in data:\n                return data[\"results\"]\n            if isinstance(data, dict) and \"reranked\" in data:\n                return data[\"reranked\"]\n            if isinstance(data, list):\n                return data\n            if isinstance(data, dict):\n                return list(data.values())\n            return []\n        if isinstance(input_data, dict):\n            if \"results\" in input_data:\n                return input_data[\"results\"]\n            if \"reranked\" in input_data:\n                return input_data[\"reranked\"]\n            return list(input_data.values())\n        if isinstance(input_data, list):\n            return input_data\n        return []\n\n    def _chunk_to_dict(self, chunk):\n        if isinstance(chunk, Data):\n            if hasattr(chunk, \"data\"):\n                return dict(chunk.data) if isinstance(chunk.data, dict) else {\"data\": chunk.data}\n            return {\"data\": chunk}\n        return dict(chunk) if not isinstance(chunk, dict) else chunk\n\n    def _call_llm(self, llm, prompt):\n        try:\n            return llm(prompt)\n        except Exception:\n            try:\n                return llm.invoke(prompt)\n            except Exception:\n                try:\n                    return llm.predict(prompt)\n                except Exception:\n                    return \"0\"\n\n    def _parse_pesos(self, pesos_input):\n        import json\n        if isinstance(pesos_input, dict):\n            return pesos_input\n        if isinstance(pesos_input, Data):\n            data = getattr(pesos_input, \"data\", None)\n            if isinstance(data, dict):\n                return data\n            if isinstance(data, str):\n                try:\n                    return json.loads(data)\n                except Exception:\n                    return {}\n        if isinstance(pesos_input, str):\n            try:\n                return json.loads(pesos_input)\n            except Exception:\n                return {}\n        return {}\n\n    def _parse_score_final_min(self, value):\n        try:\n            return float(str(value).replace(\",\", \".\"))\n        except Exception:\n            return 2.0\n\n    def rerank_chunks(self) -> Data:\n        import re\n        question = self.question.text if hasattr(self.question, 'text') else str(self.question)\n        pesos = self._parse_pesos(self.rerank_pesos)\n        lex_chunks = self._extract_chunks(self.lexical_chunks)\n        sem_chunks = self._extract_chunks(self.semantic_chunks)\n        llm = self.llm\n        top_k = self.top_k if hasattr(self, 'top_k') else 5\n        score_final_min = self._parse_score_final_min(getattr(self, 'score_final_min', 2.0))\n\n        peso_lexical = float(pesos.get('lexical', 0.5))\n        peso_semantic = float(pesos.get('semantic', 0.5))\n\n        # Junta e remove duplicados por _id\n        all_chunks = {}\n        for chunk in (lex_chunks or []):\n            chunk = self._chunk_to_dict(chunk)\n            _id = str(chunk.get('_id', id(chunk)))\n            chunk['source'] = 'lexical'\n            all_chunks[_id] = chunk\n        for chunk in (sem_chunks or []):\n            chunk = self._chunk_to_dict(chunk)\n            _id = str(chunk.get('_id', id(chunk)))\n            chunk['source'] = 'semantic'\n            all_chunks[_id] = chunk\n        chunks = list(all_chunks.values())\n\n        if not isinstance(chunks, list) or not chunks:\n            self.status = \"Nenhum chunk de entrada válido\"\n            return Data(data={\"reranked\": []})\n\n        # Prompt único para batch, agora incluindo a pergunta\n        prompt = f\"Pergunta: {question}\\nAvalie de 0 a 10 o quanto cada texto abaixo responde à pergunta. Responda apenas com uma lista de números, na mesma ordem dos textos.\\n\"\n        for idx, chunk in enumerate(chunks):\n            text = chunk.get('text', '') or chunk.get('page_content', '')\n            prompt += f\"\\nTexto {idx+1}: {text}\"\n\n        score_str = self._call_llm(llm, prompt)\n        print(f\"Prompt enviado ao LLM:\\n{prompt}\")\n        print(f\"Resposta bruta do LLM: {score_str}\")\n\n        # Extrai lista de scores\n        scores = re.findall(r\"[-+]?[0-9]*\\.?[0-9]+\", str(score_str))\n        scores = [float(s.replace(',', '.')) for s in scores][:len(chunks)]\n\n        # Atribui scores aos chunks e calcula score final com pesos\n        reranked = []\n        for chunk, score in zip(chunks, scores):\n            chunk['rerank_score_llm'] = score\n            # Score lexical e semântico (se existirem)\n            score_lexical = float(chunk.get('score', 0)) if chunk.get('source') == 'lexical' else 0.0\n            score_semantic = float(chunk.get('similarity_score', 0)) if chunk.get('source') == 'semantic' else 0.0\n            # Score final ponderado\n            chunk['rerank_score_final'] = (\n                peso_lexical * score_lexical + peso_semantic * score_semantic + score\n            ) / (1 + peso_lexical + peso_semantic)\n            reranked.append(chunk)\n\n        # Filtra apenas os chunks com score LLM > 0\n        reranked = [chunk for chunk in reranked if chunk.get('rerank_score_llm', 0) > 0]\n        # Filtra pelo score final mínimo\n        reranked = [chunk for chunk in reranked if chunk.get('rerank_score_final', 0) >= score_final_min]\n\n        reranked.sort(key=lambda x: x['rerank_score_final'], reverse=True)\n        reranked = reranked[:top_k]\n        self.status = f\"Rerank finalizado. Top {len(reranked)} retornados (score final >= {score_final_min}).\"\n        return Data(data={\"reranked\": reranked})\n"
              },
              "lexical_chunks": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Chunks Lexicais",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "list",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "lexical_chunks",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "llm": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "LLM Model",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "llm",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "question": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Pergunta",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "str",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "question",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "rerank_pesos": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Rerank Pesos",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "dict",
                  "Data",
                  "str"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "rerank_pesos",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "score_final_min": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Score Final Mínimo",
                "dynamic": false,
                "info": "Apenas chunks com rerank_score_final maior ou igual a este valor (de 0 a 5) serão retornados.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "score_final_min",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "3.0"
              },
              "semantic_chunks": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Chunks Semânticos",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "list",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "semantic_chunks",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Número máximo de chunks rerankeados a retornar.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "LLMRerankComponent"
        },
        "dragging": false,
        "id": "LLMRerankComponent-oHU1v",
        "measured": {
          "height": 571,
          "width": 320
        },
        "position": {
          "x": 9370.763330879225,
          "y": -283.4118669325462
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "AzureOpenAIModel-w8Sks",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Azure OpenAI LLMs.",
            "display_name": "Azure OpenAI",
            "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "azure_endpoint",
              "azure_deployment",
              "api_key",
              "api_version",
              "temperature",
              "max_tokens"
            ],
            "frozen": false,
            "icon": "Azure",
            "key": "AzureOpenAIModel",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": false,
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [
                  "api_key",
                  "azure_deployment",
                  "azure_endpoint"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003924824467069744,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "api_version": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "API Version",
                "dynamic": false,
                "info": "",
                "name": "api_version",
                "options": [
                  "2024-10-01-preview",
                  "2024-09-01-preview",
                  "2024-08-01-preview",
                  "2024-07-01-preview",
                  "2024-06-01",
                  "2024-03-01-preview",
                  "2024-02-15-preview",
                  "2023-12-01-preview",
                  "2023-05-15"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "2024-06-01"
              },
              "azure_deployment": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Deployment Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "azure_deployment",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "name-gpt-4o-mini-aion"
              },
              "azure_endpoint": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Azure Endpoint",
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "azure_endpoint",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "endpoint-gpt-4o-mini-aion"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import AzureChatOpenAI\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import MessageTextInput\nfrom langflow.io import DropdownInput, IntInput, SecretStrInput, SliderInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2024-06-01\",\n        \"2024-07-01-preview\",\n        \"2024-08-01-preview\",\n        \"2024-09-01-preview\",\n        \"2024-10-01-preview\",\n        \"2023-05-15\",\n        \"2023-12-01-preview\",\n        \"2024-02-15-preview\",\n        \"2024-03-01-preview\",\n    ]\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\", required=True),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=sorted(AZURE_OPENAI_API_VERSIONS, reverse=True),\n            value=next(\n                (\n                    version\n                    for version in sorted(AZURE_OPENAI_API_VERSIONS, reverse=True)\n                    if not version.endswith(\"-preview\")\n                ),\n                AZURE_OPENAI_API_VERSIONS[0],\n            ),\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to AzureOpenAI API: {e}\"\n            raise ValueError(msg) from e\n\n        return output\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AzureOpenAIModel"
        },
        "dragging": false,
        "id": "AzureOpenAIModel-w8Sks",
        "measured": {
          "height": 688,
          "width": 320
        },
        "position": {
          "x": 8527.988249488753,
          "y": 593.3106449016568
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseData-v6AgH",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "dragging": false,
        "id": "ParseData-v6AgH",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 6156.154799960682,
          "y": 349.97537300013846
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseData-oI0jS",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "dragging": false,
        "id": "ParseData-oI0jS",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 6181.177353252319,
          "y": -319.75470309161574
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "MongoAtlasSearchWithFilters-K0wOa",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Busca em Atlas Search utilizando 'search_instruction' JSON, com filtros de governança por setor e status.",
            "display_name": "Mongo Atlas Search Avançado (com search_instruction, setor e status)",
            "documentation": "",
            "edited": true,
            "field_order": [
              "mongodb_uri",
              "db_name",
              "collection_name",
              "index_name",
              "search_instruction_data",
              "user_sector",
              "doc_status",
              "min_score_fallback",
              "limit_fallback"
            ],
            "frozen": false,
            "icon": "MongoDB",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "hidden": false,
                "method": "search_documents",
                "name": "results",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\r\nimport re\r\nfrom typing import List, Union, Dict, Any\r\n\r\nfrom pymongo import MongoClient\r\nfrom langflow.custom import Component\r\nfrom langflow.inputs import (\r\n    SecretStrInput,\r\n    StrInput,\r\n    IntInput,\r\n    MultilineInput,\r\n    HandleInput,\r\n    DataInput,\r\n)\r\nfrom langflow.schema import Data, Message\r\nfrom langflow.template import Output\r\n\r\n\r\nclass MongoAtlasSearchWithFilters(Component):\r\n    display_name = \"Mongo Atlas Search Avançado (com search_instruction, setor e status)\"\r\n    icon = \"MongoDB\"\r\n    description = \"Busca em Atlas Search utilizando 'search_instruction' JSON, com filtros de governança por setor e status.\"\r\n\r\n    inputs = [\r\n        SecretStrInput(\r\n            name=\"mongodb_uri\",\r\n            display_name=\"MongoDB URI\",\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"db_name\",\r\n            display_name=\"Database\",\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"collection_name\",\r\n            display_name=\"Collection\",\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"index_name\",\r\n            display_name=\"Atlas Index Name\",\r\n            value=\"default_knowledge_context\",\r\n            required=True,\r\n        ),\r\n        DataInput(\r\n            name=\"search_instruction_data\",\r\n            display_name=\"Search Instruction (Data Object)\",\r\n            info=\"Objeto Data contendo o JSON/dicionário com as instruções de busca.\",\r\n            input_types=[\"Data\"],\r\n            required=True,\r\n        ),\r\n        MultilineInput(\r\n            name=\"user_sector\",\r\n            display_name=\"Filtro de Setor do Usuário (Obrigatório)\",\r\n            value='[]',\r\n            info='Array JSON de setores permitidos. Ex.: [\"Risco\"]. Garante governança.',\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"doc_status\",\r\n            display_name=\"Filtro de Status do Documento\",\r\n            value='ativo',\r\n            info='Status do documento para filtrar (ex: \"ativo\", \"revisão\"). Deixe vazio para não filtrar por status.',\r\n            required=False,\r\n        ),\r\n        MultilineInput(\r\n            name=\"min_score_fallback\",\r\n            display_name=\"Score Mínimo (Fallback)\",\r\n            value=\"0.0\",\r\n            info=\"Score mínimo. Usado se não especificado em search_instruction.\",\r\n            required=False,\r\n        ),\r\n        IntInput(\r\n            name=\"limit_fallback\",\r\n            display_name=\"Result Limit (Fallback)\",\r\n            value=20,\r\n            info=\"Limite de resultados. Usado se não especificado em search_instruction.\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            name=\"results\",\r\n            display_name=\"Search Results\",\r\n            method=\"search_documents\",\r\n        ),\r\n    ]\r\n\r\n    def _parse_user_sector(self) -> List[str]:\r\n        \"\"\"Parse the user_sector input into a list of strings.\"\"\"\r\n        sectors = []\r\n        raw_sectors = self.user_sector\r\n        if isinstance(raw_sectors, str) and raw_sectors.strip():\r\n            try:\r\n                parsed_sectors = json.loads(raw_sectors)\r\n                if isinstance(parsed_sectors, list):\r\n                    sectors = [str(s).strip() for s in parsed_sectors if str(s).strip()]\r\n                elif isinstance(parsed_sectors, str) and parsed_sectors.strip():\r\n                    sectors = [parsed_sectors.strip()]\r\n            except json.JSONDecodeError:\r\n                sectors = [s.strip() for s in raw_sectors.split(',') if s.strip()]\r\n        elif isinstance(raw_sectors, list):\r\n            sectors = [str(s).strip() for s in raw_sectors if str(s).strip()]\r\n        \r\n        return sectors\r\n\r\n    def _parse_search_instruction_from_data(self) -> Dict[str, Any]:\r\n        \"\"\"Parse and validate the search_instruction from Data object.\"\"\"\r\n        raw_instruction = self.search_instruction_data\r\n\r\n        if not raw_instruction or not hasattr(raw_instruction, 'data'):\r\n            self.status = \"Search instruction Data object não recebido ou inválido.\"\r\n            return {}\r\n        \r\n        instruction_payload = raw_instruction.data\r\n\r\n        if isinstance(instruction_payload, dict):\r\n            return instruction_payload\r\n        elif isinstance(instruction_payload, str):\r\n            try:\r\n                loaded_instruction = json.loads(instruction_payload)\r\n                if isinstance(loaded_instruction, dict):\r\n                    return loaded_instruction\r\n                else:\r\n                    self.status = \"Search instruction (string JSON) não resultou em um dicionário.\"\r\n                    return {}\r\n            except json.JSONDecodeError as e:\r\n                self.status = f\"Falha ao decodificar string JSON da search_instruction: {e}\"\r\n                return {}\r\n        else:\r\n            self.status = f\"Conteúdo da search_instruction (Data.data) não é dict nem string JSON. Tipo: {type(instruction_payload)}\"\r\n            return {}\r\n\r\n    def _build_search_pipeline(self, instruction: Dict[str, Any], user_allowed_sectors: List[str], doc_status_filter: str) -> List[Dict[str, Any]]:\r\n        \"\"\"Builds the MongoDB aggregation pipeline with search_instruction, sector, and status filters.\"\"\"\r\n        pipeline: List[Dict[str, Any]] = []\r\n        \r\n        if \"search_clause\" not in instruction or not isinstance(instruction[\"search_clause\"], dict):\r\n            self.status = \"Erro: 'search_clause' não fornecida ou inválida.\"\r\n            raise ValueError(\"A 'search_clause' é obrigatória na search_instruction.\")\r\n\r\n        search_stage = {\r\n            \"$search\": {\r\n                \"index\": self.index_name,\r\n                **instruction[\"search_clause\"]\r\n            }\r\n        }\r\n        pipeline.append(search_stage)\r\n\r\n        pipeline.append({\r\n            \"$set\": {\r\n                \"search_score\": {\"$meta\": \"searchScore\"}\r\n            }\r\n        })\r\n\r\n        min_score_val = instruction.get(\"min_score\", self.min_score_fallback)\r\n        min_score = 0.0\r\n        if isinstance(min_score_val, (float, int)):\r\n            min_score = float(min_score_val)\r\n        elif isinstance(min_score_val, str):\r\n            try:\r\n                min_score = float(min_score_val.strip())\r\n            except ValueError:\r\n                self.status += \" Alerta: min_score inválido, usando 0.0.\"\r\n        \r\n        if min_score > 0:\r\n            pipeline.append({\"$match\": {\"search_score\": {\"$gte\": min_score}}})\r\n        \r\n        if user_allowed_sectors:\r\n            pipeline.append({\"$match\": {\"setores\": {\"$in\": user_allowed_sectors}}})\r\n\r\n        if doc_status_filter:\r\n            pipeline.append({\"$match\": {\"status\": doc_status_filter}})\r\n\r\n        if \"filter_stages\" in instruction and isinstance(instruction[\"filter_stages\"], list):\r\n            for match_filter in instruction[\"filter_stages\"]:\r\n                if isinstance(match_filter, dict) and match_filter: \r\n                    pipeline.append({\"$match\": match_filter})\r\n        \r\n        sort_stage_val = instruction.get(\"sort_stage\")\r\n        if isinstance(sort_stage_val, dict) and sort_stage_val:\r\n            pipeline.append({\"$sort\": sort_stage_val})\r\n        else: \r\n            pipeline.append({\"$sort\": {\"search_score\": -1}})\r\n\r\n        limit_val = instruction.get(\"limit\", self.limit_fallback)\r\n        limit = 0\r\n        if isinstance(limit_val, int) and limit_val > 0:\r\n            limit = limit_val\r\n        elif isinstance(limit_val, str):\r\n            try:\r\n                limit = int(limit_val.strip())\r\n            except ValueError:\r\n                self.status += f\" Alerta: limit inválido, usando fallback {self.limit_fallback} se positivo.\"\r\n                if self.limit_fallback > 0: limit = self.limit_fallback\r\n        \r\n        if limit > 0 :\r\n            pipeline.append({\"$limit\": limit})\r\n\r\n        projection = instruction.get(\"projection_stage\", {\r\n            \"_id\": 1, \"score\": \"$search_score\", \"text\": 1, \"resumo\": 1, \"descricao\": 1,\r\n            \"setores\": 1, \"status\": 1, \"classificacao\": 1, \"tipo\": 1, \"atualizado_em\": 1,\r\n            \"participantes_internos\": 1, \"participantes_externos\": 1, \"id_reuniao\": 1\r\n        })\r\n        if isinstance(projection, dict) and projection:\r\n            pipeline.append({\"$project\": projection})\r\n\r\n        return pipeline\r\n\r\n    def search_documents(self) -> Data:\r\n        parsed_instruction = self._parse_search_instruction_from_data()\r\n        if not parsed_instruction: \r\n            return Data(data={\"results\": [], \"error\": self.status or \"Invalid search_instruction Data object.\"})\r\n\r\n        user_sectors = self._parse_user_sector()\r\n        doc_status_to_filter = self.doc_status.strip() if self.doc_status else \"\"\r\n\r\n        try:\r\n            pipeline = self._build_search_pipeline(parsed_instruction, user_sectors, doc_status_to_filter)\r\n        except ValueError as e: \r\n             self.status = str(e)\r\n             return Data(data={\"results\": [], \"error\": str(e)})\r\n\r\n        if not pipeline: \r\n            self.status = \"Pipeline de busca não pôde ser construída.\"\r\n            return Data(data={\"results\": [], \"error\": self.status})\r\n        \r\n        collection = MongoClient(self.mongodb_uri)[self.db_name][self.collection_name]\r\n\r\n        try:\r\n            results = list(collection.aggregate(pipeline))\r\n            for doc in results:\r\n                doc[\"_id\"] = str(doc[\"_id\"])\r\n                if \"score\" in doc and doc[\"score\"] is not None:\r\n                    try:\r\n                        doc[\"score\"] = float(doc[\"score\"])\r\n                    except (ValueError, TypeError):\r\n                        doc[\"score\"] = 0.0 \r\n                else:\r\n                    doc[\"score\"] = 0.0\r\n            \r\n            self.status = f\"Encontrados {len(results)} resultado(s).\"\r\n            return Data(data={\"results\": results, \"pipeline_used\": pipeline})\r\n        except Exception as e:\r\n            self.status = f\"Erro na busca: {str(e)}\"\r\n            return Data(data={\"results\": [], \"error\": str(e), \"pipeline_attempted\": pipeline})"
              },
              "collection_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Collection",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "collection_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "knowledge_documentation"
              },
              "db_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Database",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "db_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "DeepContext"
              },
              "doc_status": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Filtro de Status do Documento",
                "dynamic": false,
                "info": "Status do documento para filtrar (ex: \"ativo\", \"revisão\"). Deixe vazio para não filtrar por status.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "doc_status",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "ativo"
              },
              "index_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Atlas Index Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "index_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "default_knowledge_documentation"
              },
              "limit_fallback": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Result Limit (Fallback)",
                "dynamic": false,
                "info": "Limite de resultados. Usado se não especificado em search_instruction.",
                "list": false,
                "list_add_label": "Add More",
                "name": "limit_fallback",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 50
              },
              "min_score_fallback": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Score Mínimo (Fallback)",
                "dynamic": false,
                "info": "Score mínimo. Usado se não especificado em search_instruction.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "min_score_fallback",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "0.0"
              },
              "mongodb_uri": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "MongoDB URI",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "mongodb_uri",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "search_instruction_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Search Instruction (Data Object)",
                "dynamic": false,
                "info": "Objeto Data contendo o JSON/dicionário com as instruções de busca.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "search_instruction_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "user_sector": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Filtro de Setor do Usuário (Obrigatório)",
                "dynamic": false,
                "info": "Array JSON de setores permitidos. Ex.: [\"Risco\"]. Garante governança.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "user_sector",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "[]"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "MongoAtlasSearchWithFilters"
        },
        "dragging": false,
        "id": "MongoAtlasSearchWithFilters-K0wOa",
        "measured": {
          "height": 888,
          "width": 320
        },
        "position": {
          "x": 7438.867800456249,
          "y": -1263.9735512013413
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ExtractSearchInstruction-3iWsp",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extrai o dicionário 'search_instruction' de um objeto Data de entrada que contém o JSON completo do LLM.",
            "display_name": "Extrair Search Instruction",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_data_object"
            ],
            "frozen": false,
            "icon": "filter",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Instruction (Data)",
                "hidden": false,
                "method": "extract_instruction",
                "name": "search_instruction_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, Output\nfrom langflow.schema import Data # Certifique-se que Data está corretamente importado\n\nclass ExtractSearchInstructionComponent(Component):\n    display_name = \"Extrair Search Instruction\"\n    description = \"Extrai o dicionário 'search_instruction' de um objeto Data de entrada que contém o JSON completo do LLM.\"\n    icon = \"filter\" # Ícone sugerido, pode ser alterado\n    name = \"ExtractSearchInstruction\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data_object\", # Nome da entrada\n            display_name=\"Input Data Object\",\n            info=\"Objeto Data contendo o JSON completo do LLM (espera-se que input_data_object.data seja um dict).\",\n            input_types=[\"Data\"], # Aceita objetos do tipo Data\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"search_instruction_output\", display_name=\"Search Instruction (Data)\", method=\"extract_instruction\"),\n    ]\n\n    def extract_instruction(self) -> Data:\n        input_data = self.input_data_object # Usar o nome da entrada definido nos inputs\n\n        if not input_data or not isinstance(input_data, Data):\n            self.status = \"Objeto Data de entrada não recebido ou inválido.\"\n            # É importante retornar um objeto Data para compatibilidade com o fluxo\n            return Data(data={\"error\": self.status, \"results\": []}) \n\n        if not isinstance(input_data.data, dict):\n            self.status = f\"O atributo 'data' do objeto Data de entrada não é um dicionário. Tipo recebido: {type(input_data.data)}\"\n            return Data(data={\"error\": self.status, \"results\": []})\n\n        llm_output_dict = input_data.data\n        \n        if \"search_instruction\" not in llm_output_dict:\n            self.status = \"Chave 'search_instruction' não encontrada no dicionário de entrada (Data.data).\"\n            return Data(data={\"error\": self.status, \"results\": []})\n            \n        search_instruction_payload = llm_output_dict[\"search_instruction\"]\n        \n        if not isinstance(search_instruction_payload, dict):\n            self.status = \"O valor de 'search_instruction' não é um dicionário.\"\n            return Data(data={\"error\": self.status, \"results\": []})\n\n        self.status = \"Search instruction extraída com sucesso.\"\n        # Retorna um novo objeto Data contendo apenas o dicionário da search_instruction\n        return Data(data=search_instruction_payload)\n"
              },
              "input_data_object": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input Data Object",
                "dynamic": false,
                "info": "Objeto Data contendo o JSON completo do LLM (espera-se que input_data_object.data seja um dict).",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data_object",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ExtractSearchInstruction"
        },
        "dragging": false,
        "id": "ExtractSearchInstruction-3iWsp",
        "measured": {
          "height": 231,
          "width": 320
        },
        "position": {
          "x": 6184.4823662470435,
          "y": -815.1221083646587
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TemporalFilterLLM-IWHmL",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Aplica filtragem temporal em chunks do MongoDB usando um LLM para interpretar restrições.",
            "display_name": "Filtro Temporal Inteligente com LLM",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_chunks",
              "temporal_constraints",
              "current_date",
              "llm_model"
            ],
            "frozen": false,
            "icon": "clock-play",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chunks Filtrados pelo LLM",
                "hidden": false,
                "method": "filter_chunks_with_llm",
                "name": "filtered_chunks",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Saída de Debug",
                "hidden": null,
                "method": "get_debug_info",
                "name": "debug_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from datetime import datetime, timedelta\r\nfrom typing import List, Dict, Any, Optional\r\nimport json\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, StrInput, Output, MessageTextInput\r\nfrom langflow.schema import Data\r\nfrom langflow.schema.message import Message\r\nfrom langflow.field_typing import LanguageModel\r\n\r\nclass TemporalFilterComponent(Component):\r\n    display_name = \"Filtro Temporal Inteligente com LLM\"\r\n    description = \"Aplica filtragem temporal em chunks do MongoDB usando um LLM para interpretar restrições.\"\r\n    icon = \"clock-play\"\r\n    name = \"TemporalFilterLLM\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"input_chunks\",\r\n            display_name=\"Chunks de Entrada\",\r\n            info=\"Lista de chunks retornados pela busca lexical (Data object)\",\r\n            input_types=[\"Data\"],\r\n            required=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"temporal_constraints\",\r\n            display_name=\"Restrições Temporais (Prompt para LLM)\",\r\n            info=\"Texto descritivo das restrições temporais, usado como prompt para o LLM (Data object ou string)\",\r\n            input_types=[\"Data\", \"str\"],\r\n            required=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"current_date\",\r\n            display_name=\"Data Atual\",\r\n            info=\"Data atual no formato YYYY-MM-DD. Pode ser uma variável como {{current_date_component.current_date}}.\",\r\n            required=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"llm_model\",\r\n            display_name=\"Modelo LLM para Filtragem\",\r\n            info=\"LLM configurado para realizar a filtragem temporal baseada nas constraints.\",\r\n            input_types=[\"LanguageModel\"],\r\n            required=True,\r\n        )\r\n    ]\r\n\r\n    outputs = [\r\n        Output(name=\"filtered_chunks\", display_name=\"Chunks Filtrados pelo LLM\", method=\"filter_chunks_with_llm\"),\r\n        Output(name=\"debug_output\", display_name=\"Saída de Debug\", method=\"get_debug_info\"),\r\n    ]\r\n\r\n    def __init__(self, **data: Any):\r\n        super().__init__(**data)\r\n        self._debug_info: Dict[str, Any] = {}\r\n\r\n    def _parse_date_expression(self, expr: str, current_date: datetime) -> Optional[Dict[str, datetime]]:\r\n        \"\"\"Interpreta expressões temporais relativas.\"\"\"\r\n        try:\r\n            if \"semana passada\" in expr.lower():\r\n                end = current_date - timedelta(days=current_date.weekday())\r\n                start = end - timedelta(days=7)\r\n                return {\"start\": start, \"end\": end}\r\n            \r\n            if \"últimos 2 meses\" in expr.lower():\r\n                end = current_date\r\n                start = current_date - timedelta(days=60)\r\n                return {\"start\": start, \"end\": end}\r\n            \r\n            if \"última\" in expr.lower():\r\n                # Para \"última reunião\", \"última ata\", etc., retornamos None\r\n                # pois precisaremos ordenar por data e pegar o mais recente\r\n                return None\r\n            \r\n            # Adicionar mais padrões conforme necessário\r\n            return None\r\n            \r\n        except Exception as e:\r\n            self.status = f\"Erro ao interpretar expressão temporal: {str(e)}\"\r\n            return None\r\n\r\n    def _group_by_event_id(self, chunks: List[Dict]) -> Dict[str, List[Dict]]:\r\n        \"\"\"Agrupa chunks pelo ID do evento/documento.\"\"\"\r\n        grouped = {}\r\n        for chunk in chunks:\r\n            event_id = chunk.get('id_reuniao') or chunk.get('id')  # Tenta ambos os campos\r\n            if event_id:\r\n                if event_id not in grouped:\r\n                    grouped[event_id] = []\r\n                grouped[event_id].append(chunk)\r\n        return grouped\r\n\r\n    def _call_llm(self, llm: LanguageModel, prompt: str) -> str:\r\n        \"\"\"Chama o modelo LLM com o prompt fornecido.\"\"\"\r\n        # Tenta diferentes métodos de chamada comuns em componentes Langflow LLM\r\n        try:\r\n            if hasattr(llm, 'invoke') and callable(llm.invoke):\r\n                response = llm.invoke(prompt)\r\n            elif hasattr(llm, 'predict') and callable(llm.predict):\r\n                response = llm.predict(prompt)\r\n            elif callable(llm):\r\n                response = llm(prompt)\r\n            else:\r\n                raise ValueError(\"Modelo LLM não possui um método de chamada reconhecido (invoke, predict ou __call__).\")\r\n            \r\n            if hasattr(response, 'content'): # Comum em modelos de chat (ex: AIMessage)\r\n                return str(response.content)\r\n            return str(response)\r\n            \r\n        except Exception as e:\r\n            self._debug_info[\"llm_call_error\"] = str(e)\r\n            self.status = f\"Erro ao chamar LLM: {str(e)}\"\r\n            # Retorna uma string vazia ou lança exceção para ser capturada acima\r\n            raise # Re-levanta a exceção para ser tratada no método principal\r\n\r\n    def _prepare_llm_input(self, chunks: List[Dict], constraints: str, current_date_str: str) -> str:\r\n        \"\"\"\r\n        Prepara o prompt para o LLM, combinando as restrições, a data atual e metadados dos chunks.\r\n        \"\"\"\r\n        \r\n        chunks_for_llm = []\r\n        for chunk in chunks:\r\n            resumo_text = chunk.get('resumo', '') \r\n            metadata_chunk = {\r\n                \"_id\": chunk.get('_id'),\r\n                \"atualizado_em\": chunk.get('atualizado_em'),\r\n                \"id_reuniao\": chunk.get('id_reuniao'),\r\n                \"id_documento\": chunk.get('id'),\r\n                \"classificacao\": chunk.get('classificacao'),\r\n                \"resumo_do_documento\": resumo_text\r\n            }\r\n            # Remover chaves com valor None para economizar tokens\r\n            chunks_for_llm.append({k: v for k, v in metadata_chunk.items() if v is not None})\r\n\r\n        chunks_json_for_llm = json.dumps(chunks_for_llm, indent=2, ensure_ascii=False)\r\n        \r\n        prompt = f\"\"\"Você é um especialista em análise temporal de documentos.\r\nSua tarefa é filtrar uma lista de METADADOS de 'chunks' de documentos com base em 'restrições temporais' e uma 'data atual de referência'.\r\n\r\nData Atual de Referência: {current_date_str}\r\n\r\nRestrições Temporais a serem aplicadas:\r\n{constraints}\r\n\r\nLista de METADADOS dos Chunks (em formato JSON) para análise:\r\nCada objeto na lista representa um chunk e contém os seguintes campos (alguns podem ser omitidos se não aplicáveis ao chunk):\r\n- _id: Identificador único do chunk (gerado pelo sistema).\r\n- atualizado_em: Data/hora da última atualização do chunk/documento (formato ISO).\r\n- id_reuniao: Identificador do evento de reunião ao qual o chunk pertence (se aplicável).\r\n- id_documento: Identificador principal do documento/evento ao qual o chunk pertence.\r\n- classificacao: Classificação do tipo de documento/evento (ex: 'ata', 'relatorio', 'documento').\r\n- resumo_do_documento: O resumo completo do documento ao qual o chunk pertence.\r\n\r\n{chunks_json_for_llm}\r\n\r\nInstruções:\r\n1. Analise CUIDADOSAMENTE as 'Restrições Temporais'.\r\n2. Utilize a 'Data Atual de Referência' para resolver quaisquer referências relativas (ex: \"semana passada\", \"últimos 3 meses\") e aplique-as ao campo 'atualizado_em' dos metadados dos chunks.\r\n3. Considere os campos 'id_documento' (ou 'id_reuniao') e 'classificacao' dos metadados para identificar e agrupar chunks que pertencem ao mesmo evento/documento, conforme as 'Restrições Temporais' (ex: \"última reunião com classificação 'ata'\").\r\n4. Se as restrições mencionam \"último evento\" ou similar, você deve identificar o evento (usando 'id_documento' ou 'id_reuniao', agrupando por características e 'atualizado_em') que é o mais recente e, então, selecionar TODOS os metadados de chunks que pertencem a ESSE evento específico.\r\n5. Sua saída deve ser EXCLUSIVAMENTE uma string JSON contendo a lista dos OBJETOS DE METADADOS (exatamente como fornecidos na entrada, mas apenas os selecionados) que satisfazem as restrições. Mantenha a estrutura dos objetos de metadados selecionados.\r\n   - Se nenhum chunk atender aos critérios, retorne uma lista JSON vazia: [].\r\n   - Não adicione nenhuma explicação, introdução, conclusão ou qualquer texto fora do JSON da lista de metadados.\r\n\r\nExemplo de Saída Esperada (somente a string JSON da lista de METADADOS de chunks filtrados):\r\n[\r\n  {{ \"_id\": \"chunk_xyz123\", \"atualizado_em\": \"2024-08-20T10:00:00Z\", \"id_documento\": \"doc_evento_A\", \"resumo_do_documento\": \"Este é o resumo do documento A...\" }},\r\n  {{ \"_id\": \"chunk_abc789\", \"atualizado_em\": \"2024-08-20T10:00:00Z\", \"id_documento\": \"doc_evento_A\", \"resumo_do_documento\": \"Este é o resumo do documento A...\" }}\r\n]\r\n\"\"\"\r\n        return prompt\r\n\r\n    def filter_chunks_with_llm(self) -> Data:\r\n        self._debug_info = {}\r\n        original_chunks_map: Dict[str, Dict[str, Any]] = {} # Para mapear IDs de volta para chunks completos\r\n\r\n        try:\r\n            input_data = self.input_chunks\r\n            if not isinstance(input_data, Data) or not isinstance(input_data.data, dict):\r\n                self.status = \"Erro: Input chunks deve ser um objeto Data contendo um dicionário.\"\r\n                self._debug_info[\"error\"] = self.status\r\n                return Data(data={\"results\": [], \"error\": self.status})\r\n            \r\n            raw_chunks: List[Dict[str, Any]] = input_data.data.get(\"results\", [])\r\n            if not raw_chunks:\r\n                self.status = \"Nenhum chunk para filtrar.\"\r\n                self._debug_info[\"message\"] = self.status\r\n                return Data(data={\"results\": [], \"message\": self.status})\r\n            \r\n            # Criar mapa dos chunks originais para fácil recuperação e garantir que _id seja string\r\n            for chunk_item in raw_chunks:\r\n                chunk_id = chunk_item.get('_id')\r\n                if chunk_id is not None:\r\n                    original_chunks_map[str(chunk_id)] = chunk_item \r\n                else:\r\n                    # Se não houver _id, não poderemos mapear de volta. Poderíamos gerar um ID temporário\r\n                    # ou alertar. Por ora, vamos pular chunks sem ID para a filtragem LLM.\r\n                    self._debug_info.setdefault(\"warnings\", []).append(f\"Chunk sem _id encontrado: {str(chunk_item)[:100]}...\")\r\n            \r\n            # Usar apenas os chunks que têm _id para a preparação do prompt\r\n            chunks_with_ids_for_prompt = [ch for ch in raw_chunks if ch.get('_id') is not None]\r\n            if not chunks_with_ids_for_prompt:\r\n                self.status = \"Nenhum chunk com _id encontrado para processamento.\"\r\n                return Data(data={\"results\": [], \"message\": self.status})\r\n\r\n            self._debug_info[\"original_chunk_count\"] = len(raw_chunks)\r\n            self._debug_info[\"chunks_sent_to_llm_preparation_count\"] = len(chunks_with_ids_for_prompt)\r\n\r\n            constraints_input = self.temporal_constraints\r\n            if isinstance(constraints_input, Data) and isinstance(constraints_input.data, dict):\r\n                constraints_text: str = constraints_input.data.get(\"temporal_constraints\", \"\")\r\n            elif isinstance(constraints_input, str):\r\n                constraints_text: str = constraints_input\r\n            else:\r\n                constraints_text: str = str(constraints_input.data if isinstance(constraints_input, Data) else constraints_input)\r\n\r\n            if not constraints_text or constraints_text.strip().lower() == \"nenhuma restrição temporal específica identificada\":\r\n                self.status = \"Nenhuma restrição temporal aplicável. Retornando todos os chunks originais.\"\r\n                self._debug_info[\"message\"] = self.status\r\n                return Data(data={\"results\": raw_chunks, \"message\": self.status})\r\n            self._debug_info[\"temporal_constraints_received\"] = constraints_text\r\n            \r\n            current_date_str: str = self.current_date \r\n            try:\r\n                datetime.strptime(current_date_str, \"%Y-%m-%d\")\r\n            except ValueError:\r\n                self.status = \"Erro: Data atual deve estar no formato YYYY-MM-DD.\"\r\n                self._debug_info[\"error\"] = self.status\r\n                return Data(data={\"results\": [], \"error\": self.status})\r\n            self._debug_info[\"current_date_received\"] = current_date_str\r\n\r\n            llm_prompt = self._prepare_llm_input(chunks_with_ids_for_prompt, constraints_text, current_date_str)\r\n            self._debug_info[\"llm_prompt\"] = llm_prompt\r\n            \r\n            # Chamar o LLM conectado\r\n            # self.llm_model é agora uma instância de LanguageModel\r\n            if not hasattr(self, 'llm_model') or self.llm_model is None:\r\n                self.status = \"Erro: Modelo LLM para Filtragem não foi fornecido ou não está conectado.\"\r\n                self._debug_info[\"error\"] = self.status\r\n                return Data(data={\"results\": [], \"error\": self.status})\r\n\r\n            llm_response_text = self._call_llm(self.llm_model, llm_prompt)\r\n            self._debug_info[\"llm_response_raw\"] = llm_response_text\r\n            \r\n            filtered_metadata_from_llm: List[Dict[str,Any]]\r\n            try:\r\n                raw_json_response = llm_response_text\r\n                if \"```json\" in raw_json_response:\r\n                    raw_json_response = raw_json_response.split(\"```json\")[1].split(\"```\")[0].strip()\r\n                elif \"```\" in raw_json_response: # Genérico para ``` .... ```\r\n                    raw_json_response = raw_json_response.split(\"```\")[1].strip()\r\n                \r\n                parsed_response = json.loads(raw_json_response)\r\n                if not isinstance(parsed_response, list):\r\n                    raise ValueError(\"LLM não retornou uma lista JSON.\")\r\n                filtered_metadata_from_llm = parsed_response\r\n\r\n            except json.JSONDecodeError as jde:\r\n                self.status = f\"Erro: LLM retornou uma resposta que não é JSON válido. Detalhes: {str(jde)}\"\r\n                self._debug_info[\"error\"] = self.status\r\n                self._debug_info[\"llm_response_error_details\"] = llm_response_text\r\n                return Data(data={\"results\": [], \"error\": self.status})\r\n            except ValueError as ve:\r\n                self.status = f\"Erro ao processar resposta do LLM: {str(ve)}\"\r\n                self._debug_info[\"error\"] = self.status\r\n                self._debug_info[\"llm_response_error_details\"] = llm_response_text\r\n                return Data(data={\"results\": [], \"error\": self.status})\r\n            \r\n            # Mapear os metadados filtrados de volta para os chunks originais completos\r\n            final_filtered_chunks: List[Dict[str, Any]] = []\r\n            processed_ids_from_llm = set()\r\n\r\n            for item_meta in filtered_metadata_from_llm:\r\n                if not isinstance(item_meta, dict):\r\n                    self._debug_info.setdefault(\"warnings\", []).append(f\"Item não-dicionário na resposta do LLM: {item_meta}\")\r\n                    continue\r\n                \r\n                llm_item_id = item_meta.get('_id')\r\n                if llm_item_id is not None:\r\n                    # Garantir que o ID seja string para correspondência com as chaves do mapa\r\n                    llm_item_id_str = str(llm_item_id)\r\n                    if llm_item_id_str in original_chunks_map and llm_item_id_str not in processed_ids_from_llm:\r\n                        final_filtered_chunks.append(original_chunks_map[llm_item_id_str])\r\n                        processed_ids_from_llm.add(llm_item_id_str)\r\n                    else:\r\n                        self._debug_info.setdefault(\"warnings\", []).append(f\"ID {llm_item_id_str} da resposta do LLM não encontrado nos chunks originais ou já processado.\")\r\n                else:\r\n                    self._debug_info.setdefault(\"warnings\", []).append(f\"Item da resposta do LLM sem _id: {item_meta}\")\r\n\r\n            self._debug_info[\"filtered_chunk_count_from_llm_metadata\"] = len(filtered_metadata_from_llm)\r\n            self._debug_info[\"final_mapped_chunk_count\"] = len(final_filtered_chunks)\r\n            \r\n            result_message = f\"Filtragem com LLM resultou em {len(final_filtered_chunks)} chunks.\"\r\n            self.status = result_message\r\n            self._debug_info[\"final_message\"] = result_message\r\n            \r\n            return Data(data={\r\n                \"results\": final_filtered_chunks, \r\n                \"message\": result_message,\r\n                \"applied_constraints_summary\": constraints_text[:200] + \"...\" if len(constraints_text) > 200 else constraints_text\r\n            })\r\n\r\n        except Exception as e:\r\n            error_msg = f\"Erro crítico no TemporalFilterComponent: {str(e)}\"\r\n            self.status = error_msg\r\n            self._debug_info[\"critical_error\"] = error_msg\r\n            import traceback\r\n            self._debug_info[\"traceback\"] = traceback.format_exc()\r\n            return Data(data={\"results\": [], \"error\": error_msg})\r\n\r\n    def get_debug_info(self) -> Data:\r\n        \"\"\"Retorna informações de debug da última execução.\"\"\"\r\n        return Data(data=self._debug_info, display=\"Debug Info\") "
              },
              "current_date": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Data Atual",
                "dynamic": false,
                "info": "Data atual no formato YYYY-MM-DD. Pode ser uma variável como {{current_date_component.current_date}}.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "current_date",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input_chunks": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Chunks de Entrada",
                "dynamic": false,
                "info": "Lista de chunks retornados pela busca lexical (Data object)",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_chunks",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "llm_model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Modelo LLM para Filtragem",
                "dynamic": false,
                "info": "LLM configurado para realizar a filtragem temporal baseada nas constraints.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "llm_model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "temporal_constraints": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Restrições Temporais (Prompt para LLM)",
                "dynamic": false,
                "info": "Texto descritivo das restrições temporais, usado como prompt para o LLM (Data object ou string)",
                "input_types": [
                  "Data",
                  "str"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "temporal_constraints",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TemporalFilterLLM"
        },
        "dragging": false,
        "id": "TemporalFilterLLM-IWHmL",
        "measured": {
          "height": 449,
          "width": 320
        },
        "position": {
          "x": 8280.240004937434,
          "y": -934.0933532565477
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "AzureOpenAIModel-PWCK6",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Azure OpenAI LLMs.",
            "display_name": "Azure OpenAI",
            "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "azure_endpoint",
              "azure_deployment",
              "api_key",
              "api_version",
              "temperature",
              "max_tokens"
            ],
            "frozen": false,
            "icon": "Azure",
            "key": "AzureOpenAIModel",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": false,
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [
                  "api_key",
                  "azure_deployment",
                  "azure_endpoint"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003924824467069744,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "api_version": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "API Version",
                "dynamic": false,
                "info": "",
                "name": "api_version",
                "options": [
                  "2024-10-01-preview",
                  "2024-09-01-preview",
                  "2024-08-01-preview",
                  "2024-07-01-preview",
                  "2024-06-01",
                  "2024-03-01-preview",
                  "2024-02-15-preview",
                  "2023-12-01-preview",
                  "2023-05-15"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "2024-06-01"
              },
              "azure_deployment": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Deployment Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "azure_deployment",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "name-gpt-4o-mini-aion"
              },
              "azure_endpoint": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Azure Endpoint",
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "azure_endpoint",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "endpoint-gpt-4o-mini-aion"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import AzureChatOpenAI\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import MessageTextInput\nfrom langflow.io import DropdownInput, IntInput, SecretStrInput, SliderInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2024-06-01\",\n        \"2024-07-01-preview\",\n        \"2024-08-01-preview\",\n        \"2024-09-01-preview\",\n        \"2024-10-01-preview\",\n        \"2023-05-15\",\n        \"2023-12-01-preview\",\n        \"2024-02-15-preview\",\n        \"2024-03-01-preview\",\n    ]\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\", required=True),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=sorted(AZURE_OPENAI_API_VERSIONS, reverse=True),\n            value=next(\n                (\n                    version\n                    for version in sorted(AZURE_OPENAI_API_VERSIONS, reverse=True)\n                    if not version.endswith(\"-preview\")\n                ),\n                AZURE_OPENAI_API_VERSIONS[0],\n            ),\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to AzureOpenAI API: {e}\"\n            raise ValueError(msg) from e\n\n        return output\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AzureOpenAIModel"
        },
        "dragging": false,
        "id": "AzureOpenAIModel-PWCK6",
        "measured": {
          "height": 688,
          "width": 320
        },
        "position": {
          "x": 7821.018831281871,
          "y": -1485.1024111136676
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-xDxHu",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_text",
              "match_text",
              "operator",
              "case_sensitive",
              "message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "hidden": null,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "hidden": null,
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Case Sensitive",
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "case_sensitive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"regex\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n        ),\n        MessageTextInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Data:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"false_result\")\n            return self.message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Data:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if not result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.message\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n\n            # Ensure case_sensitive is present for all other operators\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "casual"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": false,
                "info": "The message to pass through either route.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "load_from_db": false,
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "contains"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-xDxHu",
        "measured": {
          "height": 586,
          "width": 320
        },
        "position": {
          "x": 4660.965941998949,
          "y": 1412.2030350449006
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-7VfJ6",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_text",
              "match_text",
              "operator",
              "case_sensitive",
              "message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "hidden": null,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "hidden": null,
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Case Sensitive",
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "case_sensitive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"regex\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n        ),\n        MessageTextInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Data:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"false_result\")\n            return self.message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Data:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if not result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.message\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n\n            # Ensure case_sensitive is present for all other operators\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "casual"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": false,
                "info": "The message to pass through either route.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "load_from_db": false,
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "contains"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-7VfJ6",
        "measured": {
          "height": 586,
          "width": 320
        },
        "position": {
          "x": 4673.579409810216,
          "y": 2532.6870016366847
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-IcIBA",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "user_name",
                "message"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": false,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "message": {
                "advanced": false,
                "display_name": "message",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "## Instruções para o Agente de Esclarecimento ##\n\n**Contexto:**\nVocê é um assistente de IA. O usuário, {user_name}, enviou uma mensagem que não foi compreendida claramente. A mensagem original é:\n\n---\n\n\n \"{message}\".\n\n\n---\n\n**Sua Tarefa:**\nSeu objetivo é contata-lo de forma cordial, informar que a mensagem dele não foi totalmente compreendida e solicitar esclarecimentos para que você possa ajudá-lo da melhor maneira.\n\n**Diretrizes para sua resposta ao usuário:**\n\n1.  **Saudação Personalizada:** Comece cumprimentando o usuário: \"Olá, 'user_name'!\"\n2.  **Informe a Ambiguidade:** De forma educada, explique que a última mensagem dele (\"message\") não foi totalmente clara para você.\n3.  **Peça Esclarecimento:** Solicite que ele reformule a pergunta ou forneça mais detalhes sobre o que precisa.\n4.  **Sugira Alternativas (Opcional e Cauteloso):**\n    *   Se, com base na mensagem original \"message\", você puder inferir 1 ou 2 interpretações *plausíveis e distintas* do que o usuário *poderia* estar querendo dizer, ofereça-as como exemplos. Use frases como: \"Para que eu possa entender melhor, você quis dizer algo como...?\" ou \"Você estaria se referindo a X ou talvez a Y?\".\n    *   **Importante:** Não invente alternativas se a mensagem for muito vaga. Se não for possível sugerir alternativas razoáveis, simplesmente peça para ele elaborar mais sobre o tópico ou o que gostaria de alcançar.\n5.  **Reforce o Objetivo:** Termine explicando que, com mais informações, você poderá fornecer uma resposta mais precisa e útil.\n6.  **Tom:** Mantenha um tom prestativo, amigável e colaborativo.\n\n**Exemplo de como NÃO fazer (não ofereça alternativas se não tiver base):**\nSe a mensagem for \"fale sobre aquilo\", não sugira \"Você quis dizer sobre o relatório financeiro ou sobre o projeto X?\" a menos que haja algum contexto prévio para isso. É melhor perguntar de forma mais aberta.\n\n**Estruture sua resposta final diretamente para o usuário, seguindo estas diretrizes.** "
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "user_name": {
                "advanced": false,
                "display_name": "user_name",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "user_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-IcIBA",
        "measured": {
          "height": 494,
          "width": 320
        },
        "position": {
          "x": 6137.313693468771,
          "y": 3559.8958778944034
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseJSONData-dspQ7",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom json import JSONDecodeError\n\nimport jq\nfrom json_repair import repair_json\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.inputs import HandleInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseJSONDataComponent(Component):\n    display_name = \"Parse JSON\"\n    description = \"Convert and extract JSON fields.\"\n    icon = \"braces\"\n    name = \"ParseJSONData\"\n    legacy: bool = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"Data object to filter.\",\n            required=True,\n            input_types=[\"Message\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"JQ Query\",\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def _parse_data(self, input_value) -> str:\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\n            return input_value.text\n        if isinstance(input_value, Data):\n            return json.dumps(input_value.data)\n        return str(input_value)\n\n    def filter_data(self) -> list[Data]:\n        to_filter = self.input_value\n        if not to_filter:\n            return []\n        # Check if input is a list\n        if isinstance(to_filter, list):\n            to_filter = [self._parse_data(f) for f in to_filter]\n        else:\n            to_filter = self._parse_data(to_filter)\n\n        # If input is not a list, don't wrap it in a list\n        if not isinstance(to_filter, list):\n            to_filter = repair_json(to_filter)\n            try:\n                to_filter_as_dict = json.loads(to_filter)\n            except JSONDecodeError:\n                try:\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\n                except JSONDecodeError as e:\n                    msg = f\"Invalid JSON: {e}\"\n                    raise ValueError(msg) from e\n        else:\n            to_filter = [repair_json(f) for f in to_filter]\n            to_filter_as_dict = []\n            for f in to_filter:\n                try:\n                    to_filter_as_dict.append(json.loads(f))\n                except JSONDecodeError:\n                    try:\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\n                    except JSONDecodeError as e:\n                        msg = f\"Invalid JSON: {e}\"\n                        raise ValueError(msg) from e\n            to_filter = to_filter_as_dict\n\n        full_filter_str = json.dumps(to_filter_as_dict)\n\n        logger.info(\"to_filter: \", to_filter)\n\n        results = jq.compile(self.query).input_text(full_filter_str).all()\n        logger.info(\"results: \", results)\n        return [Data(data=value) if isinstance(value, dict) else Data(text=str(value)) for value in results]\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ Query to filter the data. The input is always a JSON list.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".message"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "ParseJSONData-dspQ7",
        "measured": {
          "height": 273,
          "width": 320
        },
        "position": {
          "x": 5174.13696444582,
          "y": 3545.6644562212805
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseData-2davv",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "dragging": false,
        "id": "ParseData-2davv",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": 5676.584971258392,
          "y": 3554.5940001544586
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseJSONData-E1SZh",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields using jq queries.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\r\nfrom json import JSONDecodeError\r\n\r\nimport jq\r\nfrom json_repair import repair_json\r\nfrom loguru import logger\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.inputs import HandleInput, MessageTextInput\r\nfrom langflow.io import Output\r\nfrom langflow.schema import Data\r\nfrom langflow.schema.message import Message\r\n\r\n\r\nclass ParseJSONDataComponent(Component):\r\n    display_name = \"Parse JSON\"\r\n    description = \"Convert and extract JSON fields using jq queries.\"\r\n    icon = \"braces\"\r\n    name = \"ParseJSONData\"\r\n    legacy: bool = True\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"input_value\",\r\n            display_name=\"Input\",\r\n            info=\"Data object to filter.\",\r\n            required=True,\r\n            input_types=[\"Message\", \"Data\"],\r\n        ),\r\n        MessageTextInput(\r\n            name=\"query\",\r\n            display_name=\"JQ Query\",\r\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\r\n            required=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\r\n    ]\r\n\r\n    def _parse_data(self, input_value) -> str:\r\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\r\n            return input_value.text\r\n        if isinstance(input_value, Data):\r\n            return json.dumps(input_value.data, default=str)\r\n        return str(input_value)\r\n\r\n    def filter_data(self) -> list[Data]:\r\n        to_filter = self.input_value\r\n        if not to_filter:\r\n            return []\r\n\r\n        if isinstance(to_filter, list):\r\n            to_filter = [self._parse_data(f) for f in to_filter]\r\n        else:\r\n            to_filter = self._parse_data(to_filter)\r\n\r\n        if not isinstance(to_filter, list):\r\n            to_filter = repair_json(to_filter)\r\n            try:\r\n                to_filter_as_dict = json.loads(to_filter)\r\n            except JSONDecodeError:\r\n                try:\r\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\r\n                except JSONDecodeError as e:\r\n                    msg = f\"Invalid JSON: {e}\"\r\n                    raise ValueError(msg) from e\r\n        else:\r\n            to_filter = [repair_json(f) for f in to_filter]\r\n            to_filter_as_dict = []\r\n            for f in to_filter:\r\n                try:\r\n                    to_filter_as_dict.append(json.loads(f))\r\n                except JSONDecodeError:\r\n                    try:\r\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\r\n                    except JSONDecodeError as e:\r\n                        msg = f\"Invalid JSON: {e}\"\r\n                        raise ValueError(msg) from e\r\n            to_filter = to_filter_as_dict\r\n\r\n        full_filter_str = json.dumps(to_filter_as_dict, default=str)\r\n\r\n        logger.info(f\"to_filter: {full_filter_str}\")\r\n\r\n        results = jq.compile(self.query).input_text(full_filter_str).all()\r\n        logger.info(f\"results: {results}\")\r\n\r\n        return [\r\n            Data(data=value) if isinstance(value, dict) else Data(text=str(value))\r\n            for value in results\r\n        ]\r\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ Query to filter the data. The input is always a JSON list.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".results[].nome"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "ParseJSONData-E1SZh",
        "measured": {
          "height": 293,
          "width": 320
        },
        "position": {
          "x": -1587.334171263947,
          "y": 1578.0900296302145
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseData-cR2Fj",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "key": "ParseData",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "dragging": false,
        "id": "ParseData-cR2Fj",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": -1207.9319300290879,
          "y": 1575.4097564787542
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseJSONData-qsUmc",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert and extract JSON fields.",
            "display_name": "Parse JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value",
              "query"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Filtered Data",
                "hidden": false,
                "method": "filter_data",
                "name": "filtered_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom json import JSONDecodeError\n\nimport jq\nfrom json_repair import repair_json\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.inputs import HandleInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseJSONDataComponent(Component):\n    display_name = \"Parse JSON\"\n    description = \"Convert and extract JSON fields.\"\n    icon = \"braces\"\n    name = \"ParseJSONData\"\n    legacy: bool = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"Data object to filter.\",\n            required=True,\n            input_types=[\"Message\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"JQ Query\",\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def _parse_data(self, input_value) -> str:\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\n            return input_value.text\n        if isinstance(input_value, Data):\n            return json.dumps(input_value.data)\n        return str(input_value)\n\n    def filter_data(self) -> list[Data]:\n        to_filter = self.input_value\n        if not to_filter:\n            return []\n        # Check if input is a list\n        if isinstance(to_filter, list):\n            to_filter = [self._parse_data(f) for f in to_filter]\n        else:\n            to_filter = self._parse_data(to_filter)\n\n        # If input is not a list, don't wrap it in a list\n        if not isinstance(to_filter, list):\n            to_filter = repair_json(to_filter)\n            try:\n                to_filter_as_dict = json.loads(to_filter)\n            except JSONDecodeError:\n                try:\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\n                except JSONDecodeError as e:\n                    msg = f\"Invalid JSON: {e}\"\n                    raise ValueError(msg) from e\n        else:\n            to_filter = [repair_json(f) for f in to_filter]\n            to_filter_as_dict = []\n            for f in to_filter:\n                try:\n                    to_filter_as_dict.append(json.loads(f))\n                except JSONDecodeError:\n                    try:\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\n                    except JSONDecodeError as e:\n                        msg = f\"Invalid JSON: {e}\"\n                        raise ValueError(msg) from e\n            to_filter = to_filter_as_dict\n\n        full_filter_str = json.dumps(to_filter_as_dict)\n\n        logger.info(\"to_filter: \", to_filter)\n\n        results = jq.compile(self.query).input_text(full_filter_str).all()\n        logger.info(\"results: \", results)\n        return [Data(data=value) if isinstance(value, dict) else Data(text=str(value)) for value in results]\n"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Data object to filter.",
                "input_types": [
                  "Message",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JQ Query",
                "dynamic": false,
                "info": "JQ Query to filter the data. The input is always a JSON list.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".message"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseJSONData"
        },
        "dragging": false,
        "id": "ParseJSONData-qsUmc",
        "measured": {
          "height": 273,
          "width": 320
        },
        "position": {
          "x": 5159.020891479864,
          "y": 2839.9460171235733
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-J1ln2",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "user_name",
                "message"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": false,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "message": {
                "advanced": false,
                "display_name": "message",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "## Instruções para o Agente de Esclarecimento ##\n\n**Contexto:**\nVocê é um assistente de IA. O usuário, {user_name}, enviou uma mensagem que não foi compreendida claramente. A mensagem original é:\n\n---\n\n\n \"{message}\".\n\n\n---\n\n**Sua Tarefa:**\nSeu objetivo é contata-lo de forma cordial, informar que a mensagem dele não foi totalmente compreendida e solicitar esclarecimentos para que você possa ajudá-lo da melhor maneira.\n\n**Diretrizes para sua resposta ao usuário:**\n\n1.  **Saudação Personalizada:** Comece cumprimentando o usuário: \"Olá, 'user_name'!\"\n2.  **Informe a Ambiguidade:** De forma educada, explique que a última mensagem dele (\"message\") não foi totalmente clara para você.\n3.  **Peça Esclarecimento:** Solicite que ele reformule a pergunta ou forneça mais detalhes sobre o que precisa.\n4.  **Sugira Alternativas (Opcional e Cauteloso):**\n    *   Se, com base na mensagem original \"message\", você puder inferir 1 ou 2 interpretações *plausíveis e distintas* do que o usuário *poderia* estar querendo dizer, ofereça-as como exemplos. Use frases como: \"Para que eu possa entender melhor, você quis dizer algo como...?\" ou \"Você estaria se referindo a X ou talvez a Y?\".\n    *   **Importante:** Não invente alternativas se a mensagem for muito vaga. Se não for possível sugerir alternativas razoáveis, simplesmente peça para ele elaborar mais sobre o tópico ou o que gostaria de alcançar.\n5.  **Reforce o Objetivo:** Termine explicando que, com mais informações, você poderá fornecer uma resposta mais precisa e útil.\n6.  **Tom:** Mantenha um tom prestativo, amigável e colaborativo.\n\n**Exemplo de como NÃO fazer (não ofereça alternativas se não tiver base):**\nSe a mensagem for \"fale sobre aquilo\", não sugira \"Você quis dizer sobre o relatório financeiro ou sobre o projeto X?\" a menos que haja algum contexto prévio para isso. É melhor perguntar de forma mais aberta.\n\n**Estruture sua resposta final diretamente para o usuário, seguindo estas diretrizes.** "
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "user_name": {
                "advanced": false,
                "display_name": "user_name",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "user_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-J1ln2",
        "measured": {
          "height": 494,
          "width": 320
        },
        "position": {
          "x": 6117.249910417985,
          "y": 2746.8596653683035
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-kQVkH",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "agents",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "key": "Agent",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "hidden": false,
                "method": "message_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 1.1732828199964098e-19,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "input_types": [],
                "name": "agent_llm",
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Google Generative AI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "SambaNova",
                  "Custom"
                ],
                "options_metadata": [
                  {
                    "icon": "Amazon"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "Azure"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "Groq"
                  },
                  {
                    "icon": "NVIDIA"
                  },
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "SambaNova"
                  },
                  {
                    "icon": "brain"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Azure OpenAI"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "api_version": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "API Version",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "name": "api_version",
                "options": [
                  "2024-10-01-preview",
                  "2024-09-01-preview",
                  "2024-08-01-preview",
                  "2024-07-01-preview",
                  "2024-06-01",
                  "2024-03-01-preview",
                  "2024-02-15-preview",
                  "2023-12-01-preview",
                  "2023-05-15"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "2024-06-01"
              },
              "azure_deployment": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Deployment Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "azure_deployment",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "name-gpt-4o-mini-aion"
              },
              "azure_endpoint": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Azure Endpoint",
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "azure_endpoint",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "endpoint-gpt-4o-mini-aion"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())] + [{\"icon\": \"brain\"}],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n\n            # Validate tools\n            if not self.tools:\n                msg = \"Tools are required to run the agent. Please add at least one tool.\"\n                raise ValueError(msg)\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools,\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]\n                    + [{\"icon\": \"brain\"}],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n"
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "input_types": [],
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "input_types": [],
                "name": "sender",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "input_types": [],
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.7
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-kQVkH",
        "measured": {
          "height": 786,
          "width": 320
        },
        "position": {
          "x": 5844.611066133604,
          "y": 2783.650467898219
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-1DgFg",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "icon": "prompts",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "name": "prompt",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": ""
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-1DgFg",
        "measured": {
          "height": 256,
          "width": 320
        },
        "position": {
          "x": 5018.780374585883,
          "y": 3200.581522227751
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-awk0s",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": true,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.3.4",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "hidden": false,
                "method": "parse_data_as_list",
                "name": "data_list",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{anexo}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "dragging": false,
        "id": "CustomComponent-awk0s",
        "measured": {
          "height": 341,
          "width": 320
        },
        "position": {
          "x": -961.2346940557765,
          "y": -203.69997453002986
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-e0Euw",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Adiciona um prefixo (multilinha) à mensagem (se não estiver vazia) e envia debug como segunda saída.",
            "display_name": "Prefixo Condicional",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_message",
              "prefix"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": false,
            "lf_version": "1.3.4",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Mensagem Final",
                "hidden": false,
                "method": "process_message",
                "name": "output_message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Debug",
                "hidden": null,
                "method": "debug_info",
                "name": "debug_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\r\nfrom langflow.io import MessageInput, Output, MessageTextInput\r\nfrom langflow.schema.message import Message\r\n\r\n\r\nclass ConditionalPrefixMessage(Component):\r\n    \"\"\"\r\n    Adiciona um prefixo multilinha à mensagem se ela não estiver vazia e envia um debug separado.\r\n    \"\"\"\r\n\r\n    display_name = \"Prefixo Condicional\"\r\n    description = \"Adiciona um prefixo (multilinha) à mensagem (se não estiver vazia) e envia debug como segunda saída.\"\r\n    icon = \"message-square\"\r\n    name = \"ConditionalPrefix\"\r\n\r\n    inputs = [\r\n        MessageInput(\r\n            name=\"input_message\",\r\n            display_name=\"Mensagem\",\r\n            info=\"A mensagem a ser processada.\",\r\n            required=True,\r\n        ),\r\n        MultilineInput(\r\n            name=\"prefix\",\r\n            display_name=\"Prefixo\",\r\n            info=\"Texto (pode ser multilinha) adicionado antes da mensagem.\",\r\n            value=\"\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Mensagem Final\",\r\n            name=\"output_message\",\r\n            info=\"Mensagem com prefixo (se aplicável).\",\r\n            method=\"process_message\",\r\n        ),\r\n        Output(\r\n            display_name=\"Debug\",\r\n            name=\"debug_output\",\r\n            info=\"Saída com informações de depuração.\",\r\n            method=\"debug_info\",\r\n        ),\r\n    ]\r\n\r\n    def process_message(self) -> Message:\r\n        input_message: Message = self.input_message\r\n        prefix: str = self.prefix or \"\"\r\n\r\n        # Armazena para debug\r\n        self._prefix_used = prefix\r\n        message_text = input_message.text.strip() if hasattr(input_message, 'text') and input_message.text else \"\"\r\n\r\n        self._debug_log = f\"Mensagem recebida: '{message_text}'\\n\"\r\n        self._debug_log += f\"Prefixo recebido: '{prefix}'\\n\"\r\n\r\n        if not message_text:\r\n            self.status = \"Mensagem vazia recebida\"\r\n            self._debug_log += \"Mensagem está vazia. Retornando texto vazio.\\n\"\r\n            return Message(text=\"\")\r\n\r\n        final_text = f\"{prefix}{message_text}\"\r\n        self.status = f\"Mensagem processada com prefixo\"\r\n        self._debug_log += f\"Resultado final: '{final_text}'\"\r\n\r\n        return Message(text=final_text)\r\n\r\n    def debug_info(self) -> Message:\r\n        return Message(text=self._debug_log.strip() if hasattr(self, \"_debug_log\") else \"Nenhuma informação de debug.\")\r\n"
              },
              "input_message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Mensagem",
                "dynamic": false,
                "info": "A mensagem a ser processada.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_message",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "prefix": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Prefixo",
                "dynamic": false,
                "info": "Texto (pode ser multilinha) adicionado antes da mensagem.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "prefix",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Anexo: \n\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalPrefix"
        },
        "dragging": false,
        "id": "CustomComponent-e0Euw",
        "measured": {
          "height": 400,
          "width": 320
        },
        "position": {
          "x": -536.6275479808712,
          "y": -190.2974638596956
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 287.21439408237177,
      "y": 539.627187274485,
      "zoom": 0.2
    }
  },
  "description": "Connect the Dots, Craft Language.",
  "endpoint_name": null,
  "id": "59253a7f-b13e-42e6-a7d1-0e1e470f9f9c",
  "is_component": false,
  "last_tested_version": "1.3.4",
  "name": "Chat",
  "tags": []
}